<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Joseph Salmon">
<meta name="dcterms.date" content="2024-11-10">
<meta name="description" content="Iso, Iso, Iso … Tonic! Or how to fit a non-decreasing signal.">

<title>Isotonic regression – Joseph Salmon</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../..//img/Flag_of_Occitania.svg" rel="icon" type="image/svg+xml">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-25d362aa3afec45ecf1ae134bfa15e67.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-27741747c7e800ef03c20cefdd1ad89e.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-12a31f434ccf002d554196a069361be1.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-8199f10e9e0ee5dfe1384397268b16b0.min.css" rel="prefetch" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script src="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.js"></script>
<link href="../../site_libs/quarto-contrib/pseudocode-2.4.1/pseudocode.min.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/all.css" rel="stylesheet">
<link href="../../site_libs/quarto-contrib/fontawesome6-0.1.0/latex-fontsize.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(../../img/bg_pine_trees.jpg);
background-size: cover;
      }
</style>
<meta name="author" content="Joseph Salmon">
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script type="text/javascript">
window.PlotlyConfig = {MathJaxConfig: 'local'};
if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}
if (typeof require !== 'undefined') {
require.undef("plotly");
requirejs.config({
    paths: {
        'plotly': ['https://cdn.plot.ly/plotly-2.35.2.min']
    }
});
require(['plotly'], function(Plotly) {
    window._Plotly = Plotly;
});
}
</script>


  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="citation_title" content="Isotonic regression">
<meta name="citation_author" content="Joseph Salmon">
<meta name="citation_publication_date" content="2024-11-10">
<meta name="citation_cover_date" content="2024-11-10">
<meta name="citation_year" content="2024">
<meta name="citation_online_date" content="2024-11-10">
<meta name="citation_fulltext_html_url" content="https://josephsalmon.eu/blog/isotonic/">
<meta name="citation_language" content="en">
<meta name="citation_reference" content="citation_title=Structure and interpretation of computer programs;,citation_author=H. Abelson;,citation_author=G. J. Sussman;,citation_author=J. Sussman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Multitask learning with expert advice;,citation_author=J. Abernethy;,citation_author=P. Bartlett;,citation_author=A. Rakhlin;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Convergence of the iterates of descent methods for analytic cost functions;,citation_author=P. Absil;,citation_author=R. Mahony;,citation_author=B. Andrews;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=16;,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Database-friendly random projections: Johnson-lindenstrauss with binary coins;,citation_author=D. Achlioptas;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=4;,citation_volume=66;,citation_journal_title=Journal of computer and System Sciences;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Fast high-dimensional filtering using the permutohedral lattice;,citation_author=A. Adams;,citation_author=J. Baek;,citation_author=A. Davis;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=SIGGRAPH;">
<meta name="citation_reference" content="citation_title=Gaussian KD-trees for fast high-dimensional filtering;,citation_author=A. Adams;,citation_author=N. Gelfand;,citation_author=J. Dolson;,citation_author=M. Levoy;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=SIGGRAPH;">
<meta name="citation_reference" content="citation_title=An introduction to continuity, extrema, and related topics for general Gaussian processes;,citation_author=R. J. Adler;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_series_title=Institute of mathematical statistics lecture notes—monograph series, 12;">
<meta name="citation_reference" content="citation_title=An augmented lagrangian approach to the constrained optimization formulation of imaging inverse problems;,citation_author=M. V. Afonso;,citation_author=J. M. Bioucas-Dias;,citation_author=M. A. T. Figueiredo;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=20;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation;,citation_author=M. Aharon;,citation_author=M. Elad;,citation_author=A. Bruckstein;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=11;,citation_volume=54;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Sparse and redundant modeling of image content using an image-signature-dictionary;,citation_author=M. Aharon;,citation_author=M. Elad;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=1;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Strong converse for identification via quantum channels;,citation_author=R. Ahlswede;,citation_author=A. Winter;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=3;,citation_volume=48;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=The fast Johnson-Lindenstrauss transform and approximate nearest neighbors;,citation_author=N. Ailon;,citation_author=B. Chazelle;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=39;,citation_journal_title=SIAM J. Comput.;">
<meta name="citation_reference" content="citation_title=On Bernoulli’s numerical solution of algebraic equations;,citation_author=A. Aitken;,citation_publication_date=1926;,citation_cover_date=1926;,citation_year=1926;,citation_volume=46;,citation_journal_title=Proceedings of the Royal Society of Edinburgh;">
<meta name="citation_reference" content="citation_title=A new look at the statistical model identification;,citation_author=H. Akaike;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_volume=AC-19;,citation_journal_title=IEEE Trans. Automat. Control;">
<meta name="citation_reference" content="citation_title=Sparsity driven people localization with a heterogeneous network of cameras;,citation_author=A. Alahi;,citation_author=L. Jacques;,citation_author=Y. Boursier;,citation_author=P. Vandergheynst;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=41;,citation_journal_title=J. Math. Imaging Vis.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Multiscale methods in image modelling and image processing;,citation_author=S. K. Alexander;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=University of Waterloo;">
<meta name="citation_reference" content="citation_title=A simple, general model for the affine self-similarity of images;,citation_author=S. K. Alexander;,citation_author=E. R. Vrscay;,citation_author=S. Tsurumi;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICIAR;">
<meta name="citation_reference" content="citation_title=Sparse least trimmed squares regression for analyzing high-dimensional large data sets;,citation_author=A. Alfons;,citation_author=C. Croux;,citation_author=S. Gelper;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=7;,citation_journal_title=Ann. Appl. Stat.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=PAC-bayesian bounds for sparse regression estimation with exponential weights;,citation_author=P. Alquier;,citation_author=K. Lounici;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=5;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=PAC-Bayesian bounds for randomized empirical risk minimizers;,citation_author=P. Alquier;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=17;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=Axioms and fundamental equations of image processing;,citation_author=L. Alvarez;,citation_author=F. Guichard;,citation_author=undefined Lions;,citation_author=undefined Morel;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_issue=3;,citation_volume=123;,citation_journal_title=Arch. Rational Mech. Anal.;">
<meta name="citation_reference" content="citation_title=Signal and image restoration using shock filters and anisotropic diffusion;,citation_author=L. Alvarez;,citation_author=L. Mazorra;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=31;,citation_journal_title=SIAM J. Numer. Anal.;">
<meta name="citation_reference" content="citation_title=Differential geometry in statistical inference;,citation_author=S-I. Amari;,citation_author=O. E. Barndorff-Nielsen;,citation_author=R. E. Kass;,citation_author=S. L. Lauritzen;,citation_author=C. R. Rao;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_series_title=Institute of mathematical statistics lecture notes—monograph series, 10;">
<meta name="citation_reference" content="citation_title=Shape quantization and recognition with randomized trees;,citation_author=Y. Amit;,citation_author=D. Geman;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_volume=9;,citation_journal_title=Neural Comput.;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Iterative procedures for nonlinear integral equations;,citation_author=D. G. Anderson;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_journal_title=Journal of the ACM;">
<meta name="citation_reference" content="citation_title=The transformation of Poisson, binomial and negative-binomial data;,citation_author=F. J. Anscombe;,citation_publication_date=1948;,citation_cover_date=1948;,citation_year=1948;,citation_volume=35;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Comments on: $\ell_1$-penalization for mixture regression models;,citation_author=A. Antoniadis;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=19;,citation_journal_title=TEST;">
<meta name="citation_reference" content="citation_title=A SMART stochastic algorithm for nonconvex optimization with applications to robust machine learning;,citation_author=A. Aravkin;,citation_author=D. Davis;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=arXiv preprint arXiv:1610.01101;">
<meta name="citation_reference" content="citation_title=Multi-task feature learning;,citation_author=A. Argyriou;,citation_author=T. Evgeniou;,citation_author=M. Pontil;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Convex multi-task feature learning;,citation_author=A. Argyriou;,citation_author=T. Evgeniou;,citation_author=M. Pontil;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=73;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Does median filtering truly preserve edges better than linear filtering?;,citation_author=E. Arias-Castro;,citation_author=D. L. Donoho;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=37;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Variable selection with exponential weights and $l\_0$-penalization;,citation_author=E. Arias-Castro;,citation_author=K. Lounici;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=arXiv preprint arXiv:1208.2635;">
<meta name="citation_reference" content="citation_title=Oracle inequalities and minimax rates for non-local means and related adaptive kernel-based methods;,citation_author=E. Arias-Castro;,citation_author=J. Salmon;,citation_author=R. Willett;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=5;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Data-driven calibration of linear estimators with minimal penalties;,citation_author=S. Arlot;,citation_author=F. Bach;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=A survey of cross-validation procedures for model selection;,citation_author=S. Arlot;,citation_author=A. Celisse;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=4;,citation_journal_title=Statistics surveys;">
<meta name="citation_reference" content="citation_title=Efficient implementations of the generalized lasso dual path algorithm;,citation_author=T. Arnold;,citation_author=R. Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1405.3222;">
<meta name="citation_reference" content="citation_title=K-means++: The advantages of careful seeding;,citation_author=D. Arthur;,citation_author=S. Vassilvitskii;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Proceedings of the eighteenth annual ACM-SIAM symposium on discrete algorithms;">
<meta name="citation_reference" content="citation_title=Coherent measures of risk;,citation_author=P. Artzner;,citation_author=F. Delbaen;,citation_author=undefined Eber;,citation_author=D. Heath;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=3;,citation_volume=9;,citation_journal_title=Mathematical Finance;">
<meta name="citation_reference" content="citation_title=Fast learning rates for plug-in classifiers;,citation_author=J-Y. Audibert;,citation_author=A. B. Tsybakov;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Aggregated estimators and empirical complexity for least square regression;,citation_author=J-Y. Audibert;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=6;,citation_volume=40;,citation_journal_title=Ann. Inst. H. Poincaré Probab. Statist.;">
<meta name="citation_reference" content="citation_title=Progressive mixture rules are deviation suboptimal;,citation_author=J-Y. Audibert;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Fast learning rates in statistical inference through aggregation;,citation_author=J-Y. Audibert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=4;,citation_volume=37;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Robust and consistent variable selection in high-dimensional generalized linear models;,citation_author=M. Avella-Medina;,citation_author=E. M. Ronchetti;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=1;,citation_volume=105;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Unsupervised, information-theoretic, adaptive image filtering for image restoration;,citation_author=S. P. Awate;,citation_author=R. T. Whitaker;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=28;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Spike detection from inaccurate samplings;,citation_author=undefined Azaïs;,citation_author=Y. De Castro;,citation_author=F. Gamboa;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=2;,citation_volume=38;,citation_journal_title=Appl. Comput. Harmon. Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Variable bandwidth image models for texture-preserving enhancement of natural images;,citation_author=N. Azzabou;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_dissertation_institution=École des Ponts;">
<meta name="citation_reference" content="citation_title=Image denoising based on adapted dictionary computation;,citation_author=N. Azzabou;,citation_author=N. Paragios;,citation_author=F. Guichard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Optimization with sparsity-inducing penalties;,citation_author=F. Bach;,citation_author=R. Jenatton;,citation_author=J. Mairal;,citation_author=G. Obozinski;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=4;,citation_journal_title=Foundations and Trends in Machine Learning;">
<meta name="citation_reference" content="citation_title=Consistency of the group Lasso and multiple kernel learning;,citation_author=F. Bach;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Bolasso: Model consistent Lasso estimation through the bootstrap;,citation_author=F. Bach;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Consistency of trace norm minimization;,citation_author=F. Bach;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=Jun;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Sparsity-regularized born iterations for electromagnetic inverse scattering;,citation_author=H. Bagci;,citation_author=R. Raich;,citation_author=A. O. Hero III;,citation_author=E. Michielssen;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=Antennas and propagation society international symposium, 2008. AP-s 2008. IEEE;">
<meta name="citation_reference" content="citation_title=Adaptive regression and model selection in data mining problems;,citation_author=S. Bakin;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_dissertation_institution=The Australian National University;">
<meta name="citation_reference" content="citation_title=A cookbook of self-supervised learning;,citation_author=Randall Balestriero;,citation_author=Mark Ibrahim;,citation_author=Vlad Sobal;,citation_author=Ari Morcos;,citation_author=Shashank Shekhar;,citation_author=Tom Goldstein;,citation_author=Florian Bordes;,citation_author=Adrien Bardes;,citation_author=Gregoire Mialon;,citation_author=Yuandong Tian;,citation_author=Avi Schwarzschild;,citation_author=Andrew Gordon Wilson;,citation_author=Jonas Geiping;,citation_author=Quentin Garrido;,citation_author=Pierre Fernandez;,citation_author=Amir Bar;,citation_author=Hamed Pirsiavash;,citation_author=Yann LeCun;,citation_author=Micah Goldblum;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://arxiv.org/abs/2304.12210;">
<meta name="citation_reference" content="citation_title=On estimation of the diagonal elements of a sparse precision matrix;,citation_author=S. Balmand;,citation_author=A. S. Dalalyan;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=10;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Online identification and tracking of subspaces from highly incomplete information;,citation_author=L. Balzano;,citation_author=R. D. Nowak;,citation_author=B. Recht;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=Communication, control, and computing (allerton), 2010 48th annual allerton conference on;">
<meta name="citation_reference" content="citation_title=Efficient particle filtering via sparse kernel density estimation;,citation_author=A. Banerjee;,citation_author=P. Burlina;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=9;,citation_volume=19;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Clustering with Bregman divergences;,citation_author=A. Banerjee;,citation_author=S. Merugu;,citation_author=I. S. Dhillon;,citation_author=J. Ghosh;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=6;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Electromagnetic neural source imaging under sparsity constraints with SURE-based hyperparameter tuning;,citation_author=P.-A. Bannier;,citation_author=Q. Bertrand;,citation_author=J. Salmon;,citation_author=A. Gramfort;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=Medical imaging meets NeurIPS (workshop);">
<meta name="citation_reference" content="citation_title=A common framework for nonlinear diffusion, adaptive smoothing, bilateral filtering and mean shift;,citation_author=D. Barash;,citation_author=D. Comaniciu;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=1;,citation_volume=22;,citation_journal_title=Image Video Comput.;">
<meta name="citation_reference" content="citation_title=A fundamental relationship between bilateral filtering, adaptive smoothing, and the nonlinear diffusion equation;,citation_author=D. Barash;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=6;,citation_volume=24;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Gaussian model selection with an unknown variance;,citation_author=Y. Baraud;,citation_author=C. Giraud;,citation_author=S. Huet;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=37;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Estimator selection in the gaussian setting;,citation_author=Y. Baraud;,citation_author=C. Giraud;,citation_author=S. Huet;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=submitted;">
<meta name="citation_reference" content="citation_title=Probabilités;,citation_author=Philippe Barbe;,citation_author=Michel Ledoux;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=A knockoff filter for high-dimensional selective inference;,citation_author=R. F. Barber;,citation_author=E. J. Candès;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=5;,citation_volume=47;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Risk bounds for model selection via penalization;,citation_author=A. R. Barron;,citation_author=L. Birgé;,citation_author=P. Massart;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=3;,citation_volume=113;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=Approximation and learning by greedy algorithms;,citation_author=A. R. Barron;,citation_author=A. Cohen;,citation_author=W. Dahmen;,citation_author=R. A. DeVore;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=1;,citation_volume=36;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Rademacher and Gaussian complexities: Risk bounds and structural results;,citation_author=P. L. Bartlett;,citation_author=S. Mendelson;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=Spec. Issue Comput. Learn. Theory;,citation_volume=3;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Convex analysis and monotone operator theory in Hilbert spaces;,citation_author=H. H. Bauschke;,citation_author=P. L. Combettes;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Sparsity constrained nonlinear optimization: Optimality conditions and algorithms;,citation_author=A. Beck;,citation_author=Y. C. Eldar;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=23;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=The cyclic block conditional gradient method for convex optimization problems;,citation_author=A. Beck;,citation_author=E. Pauwels;,citation_author=S. Sabach;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=25;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Mirror descent and nonlinear projected subgradient methods for convex optimization;,citation_author=A. Beck;,citation_author=M. Teboulle;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=31;,citation_journal_title=Operations Research Letters;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A fast iterative shrinkage-thresholding algorithm for linear inverse problems;,citation_author=A. Beck;,citation_author=M. Teboulle;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=2;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Gradient-based algorithms with applications to signal-recovery problems;,citation_author=A. Beck;,citation_author=M. Teboulle;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_inbook_title=Convex optimization in signal processing and communications;">
<meta name="citation_reference" content="citation_title=Smoothing and first order methods: A unified framework;,citation_author=A. Beck;,citation_author=M. Teboulle;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=22;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=On the convergence of block coordinate type methods;,citation_author=A. Beck;,citation_author=L. Tetruashvili;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=23;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=First-order methods in optimization;,citation_author=A. Beck;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=25;">
<meta name="citation_reference" content="citation_title=Templates for convex cone problems with applications to sparse signal recovery;,citation_author=S. R. Becker;,citation_author=E. J. Candès;,citation_author=M. C. Grant;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=3;,citation_journal_title=Math. Program. Comput.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Cython: The best of both worlds;,citation_author=S. Behnel;,citation_author=R. Bradshaw;,citation_author=C. Citro;,citation_author=L. Dalcin;,citation_author=D. S. Seljebotn;,citation_author=K. Smith;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=13;,citation_journal_title=Computing in Science Engineering;">
<meta name="citation_reference" content="citation_title=A hierarchical bayesian perspective on majorization-minimization for non-convex sparse regression: Application to M/EEG source imaging;,citation_author=Y. Bekhti;,citation_author=F. Lucka;,citation_author=J. Salmon;,citation_author=undefined A.Gramfort;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=8;,citation_volume=34;,citation_journal_title=Inverse Problems;">
<meta name="citation_reference" content="citation_title=Slope meets lasso: Improved oracle bounds and optimality;,citation_author=P. C. Bellec;,citation_author=G. Lecué;,citation_author=A. B. Tsybakov;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=arXiv preprint arXiv:1605.08651;">
<meta name="citation_reference" content="citation_title=A sharp oracle inequality for Graph-Slope;,citation_author=P. C. Bellec;,citation_author=J. Salmon;,citation_author=S. Vaiter;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=https://arxiv.org/pdf/1706.06977.pdf;,citation_issue=2;,citation_volume=11;,citation_journal_title=Electron. J. Statist.;">
<meta name="citation_reference" content="citation_title=Who started this rumor? Quantifying the natural differential privacy guarantees of gossip protocols;,citation_author=A. Bellet;,citation_author=R. Guerraoui;,citation_author=H. Hendrikx;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_technical_report_institution=arXiv preprint arXiv:1902.07138;">
<meta name="citation_reference" content="citation_title=A Survey on Metric Learning for Feature Vectors and Structured Data;,citation_author=A. Bellet;,citation_author=A. Habrard;,citation_author=M. Sebban;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_technical_report_institution=arXiv:1306.6709;">
<meta name="citation_reference" content="citation_title=Metric Learning;,citation_author=A. Bellet;,citation_author=A. Habrard;,citation_author=M. Sebban;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=The theory of dynamic programming;,citation_author=R. Bellman;,citation_publication_date=1954-11;,citation_cover_date=1954-11;,citation_year=1954;,citation_issue=6;,citation_volume=60;,citation_journal_title=Bull. Amer. Math. Soc.;,citation_publisher=American Mathematical Society;">
<meta name="citation_reference" content="citation_title=Square-root Lasso: Pivotal recovery of sparse signals via conic programming;,citation_author=A. Belloni;,citation_author=V. Chernozhukov;,citation_author=L. Wang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=98;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Least squares after model selection in high-dimensional sparse models;,citation_author=A. Belloni;,citation_author=V. Chernozhukov;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=19;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Linear and conic programming estimators in high-dimensional errors-in-variables models;,citation_author=A. Belloni;,citation_author=M. Rosenbaum;,citation_author=A. B. Tsybakov;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1408.0241;">
<meta name="citation_reference" content="citation_title=An $\{ l_1, l_2, l_{\infty}\}$-regularization approach to high-dimensional errors-in-variables models;,citation_author=A. Belloni;,citation_author=M. Rosenbaum;,citation_author=A. B. Tsybakov;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1412.7216;">
<meta name="citation_reference" content="citation_title=Agnostic online learning;,citation_author=S. Ben-David;,citation_author=D. Pal;,citation_author=S. Shalev-Shwartz;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Exploiting task relatedness for multiple task learning;,citation_author=S. Ben-David;,citation_author=R. Schuller;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Generalized inverses;,citation_author=A. Ben-Israel;,citation_author=T. N. E. Greville;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_series_title=CMS books in mathematics/ouvrages de mathématiques de la SMC, 15;">
<meta name="citation_reference" content="citation_title=Robust optimization;,citation_author=A. Ben-Tal;,citation_author=L. El Ghaoui;,citation_author=A. Nemirovski;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_series_title=Princeton series in applied mathematics;">
<meta name="citation_reference" content="citation_title=An old-new concept of convex risk measures: The optimized certainty equivalent;,citation_author=A. Ben-Tal;,citation_author=M. Teboulle;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=3;,citation_volume=17;,citation_journal_title=Math. Finance;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Expected utility, penalty functions, and duality in stochastic nonlinear programming;,citation_author=A. Ben-Tal;,citation_author=M. Teboulle;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=11;,citation_volume=32;,citation_journal_title=Management Sci.;">
<meta name="citation_reference" content="citation_title=Exact recovery of Dirac ensembles from the projection onto spaces of spherical harmonics;,citation_author=T. Bendory;,citation_author=S. Dekel;,citation_author=A. Feuer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=Constr. Approx.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Exact recovery of non-uniform splines from the projection onto spaces of algebraic polynomials;,citation_author=T. Bendory;,citation_author=S. Dekel;,citation_author=A. Feuer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=182;,citation_journal_title=J. Approx. Theory;">
<meta name="citation_reference" content="citation_title=Robust recovery of stream of pulses using convex optimization;,citation_author=T. Bendory;,citation_author=S. Dekel;,citation_author=A. Feuer;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_volume=442;,citation_journal_title=J. Math. Anal. Appl.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Super-resolution on the sphere using convex optimization;,citation_author=T. Bendory;,citation_author=S. Dekel;,citation_author=A. Feuer;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=9;,citation_volume=63;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=On the nonparametric estimation of regression functions;,citation_author=J. K. Benedetti;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=2;,citation_volume=39;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Representation learning: A review and new perspectives;,citation_author=Y. Bengio;,citation_author=A. Courville;,citation_author=P. Vincent;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=8;,citation_volume=35;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Gradient-based optimization of hyperparameters;,citation_author=Y. Bengio;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=8;,citation_volume=12;,citation_journal_title=Neural comput.;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Seven proofs of the pearson chi-squared independence test and its graphical interpretation;,citation_author=E. Benhamou;,citation_author=V. Melot;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_technical_report_institution=Arxiv preprint arXiv:1808.09171;">
<meta name="citation_reference" content="citation_title=Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing;,citation_author=Y. Benjamini;,citation_author=Y. Hochberg;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=1;,citation_volume=57;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Sparse image representation with epitomes;,citation_author=L. Benoit;,citation_author=J. Mairal;,citation_author=F. Bach;,citation_author=J. Ponce;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Matching pursuit of images;,citation_author=F. Bergeaud;,citation_author=S. Mallat;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Über das elektroenkephalogramm des menschen;,citation_author=H. Berger;,citation_publication_date=1929;,citation_cover_date=1929;,citation_year=1929;,citation_journal_title=Archiv für psychiatrie und nervenkrankheiten;">
<meta name="citation_reference" content="citation_title=Interpolation spaces. An introduction;,citation_author=J. Bergh;,citation_author=J. Löfström;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;">
<meta name="citation_reference" content="citation_title=Random search for hyper-parameter optimization;,citation_author=J. Bergstra;,citation_author=Y. Bengio;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=13;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Nonnegative matrices in the mathematical sciences;,citation_author=A. Berman;,citation_author=R. J. Plemmons;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=9;,citation_series_title=Classics in applied mathematics;">
<meta name="citation_reference" content="citation_title=Limit theorems for the maximum term in stationary sequences;,citation_author=S. M. Berman;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_volume=35;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=Smooth loss functions for deep top-k classification;,citation_author=L. Berrada;,citation_author=A. Zisserman;,citation_author=M. P. Kumar;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=ICLR;">
<meta name="citation_reference" content="citation_title=Rethinking early stopping: Refine, then calibrate;,citation_author=E. Berta;,citation_author=D. Holzmüller;,citation_author=M. I. Jordan;,citation_author=F. Bach;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2501.19195;">
<meta name="citation_reference" content="citation_title=Learning with differentiable perturbed optimizers;,citation_author=Q. Berthet;,citation_author=M. Blondel;,citation_author=O. Teboul;,citation_author=M. Cuturi;,citation_author=undefined Vert;,citation_author=F. Bach;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_journal_title=arXiv preprint arXiv:2002.08676;">
<meta name="citation_reference" content="citation_title=Implicit differentiation of lasso-type models for hyperparameter optimization;,citation_author=Q. Bertrand;,citation_author=Q. Klopfenstein;,citation_author=M. Blondel;,citation_author=S. Vaiter;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Implicit differentiation for fast hyperparameter selection in non-smooth convex learning;,citation_author=Q. Bertrand;,citation_author=Q. Klopfenstein;,citation_author=M. Massias;,citation_author=M. Blondel;,citation_author=S. Vaiter;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_journal_title=Submitted to JMLR;">
<meta name="citation_reference" content="citation_title=Handling correlated and repeated measurements with the smoothed multivariate square-root lasso;,citation_author=Q. Bertrand;,citation_author=M. Massias;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=NeurIPS;">
<meta name="citation_reference" content="citation_title=Anderson acceleration of coordinate descent;,citation_author=Q. Bertrand;,citation_author=M. Massias;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Convex optimization algorithms;,citation_author=D. P. Bertsekas;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Theory and applications of robust optimization;,citation_author=D. Bertsimas;,citation_author=D. B. Brown;,citation_author=C. Caramanis;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=53;,citation_journal_title=SIAM Rev.;">
<meta name="citation_reference" content="citation_title=Best subset selection via a modern optimization lens;,citation_author=D. Bertsimas;,citation_author=A. King;,citation_author=R. Mazumder;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_volume=44;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Probing instructions for expression regulation in gene nucleotide compositions;,citation_author=C. Bessière;,citation_author=M. Taha;,citation_author=F. Petitprez;,citation_author=J. Vandel;,citation_author=J.-M. Marin;,citation_author=L. Bréhélin;,citation_author=S. Lèbre;,citation_author=C.-H. Lecellier;,citation_publication_date=2018-01;,citation_cover_date=2018-01;,citation_year=2018;,citation_issue=1;,citation_volume=14;,citation_journal_title=PLOS Computational Biology;,citation_publisher=Public Library of Science;">
<meta name="citation_reference" content="citation_title=Active set algorithms for isotonic regression; a unifying framework;,citation_author=M. J. Best;,citation_author=N. Chakravarti;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=3;,citation_volume=47;,citation_journal_title=Math. Programming;">
<meta name="citation_reference" content="citation_title=Atomic norm denoising with applications to line spectral estimation;,citation_author=B. N. Bhaskar;,citation_author=G. Tang;,citation_author=B. Recht;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=abs/1204.0562;,citation_technical_report_institution=University of Wisconsin-Madison;">
<meta name="citation_reference" content="citation_title=Matrix analysis;,citation_author=R. Bhatia;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_volume=169;,citation_series_title=Graduate texts in mathematics;">
<meta name="citation_reference" content="citation_title=A stochastic coordinate descent primal-dual algorithm and applications to large-scale composite optimization;,citation_author=P. Bianchi;,citation_author=W. Hachem;,citation_author=F. Iutzeler;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1407.0898;">
<meta name="citation_reference" content="citation_title=Convergence of a multi-agent projected stochastic gradient algorithm for non-convex optimization;,citation_author=P. Bianchi;,citation_author=J. Jakubowicz;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=58;,citation_journal_title=IEEE Trans. Autom. Control;">
<meta name="citation_reference" content="citation_title=Statistical inference on graphs;,citation_author=G. Biau;,citation_author=K. Bleakley;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=24;,citation_journal_title=Statistics &amp;amp;amp; Decisions;">
<meta name="citation_reference" content="citation_title=Consistency of random forests and other averaging classifiers;,citation_author=G. Biau;,citation_author=L. Devroye;,citation_author=G. Lugosi;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=COBRA: A nonlinear aggregation strategy;,citation_author=G. Biau;,citation_author=A. Fischer;,citation_author=B. Guedj;,citation_author=J. D. Malley;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1303.2236;">
<meta name="citation_reference" content="citation_title=Mathematical statistics;,citation_author=P. J. Bickel;,citation_author=K. A. Doksum;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;">
<meta name="citation_reference" content="citation_title=Simultaneous analysis of Lasso and Dantzig selector;,citation_author=P. J. Bickel;,citation_author=Y. Ritov;,citation_author=A. B. Tsybakov;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=4;,citation_volume=37;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=A lasso for hierarchical interactions;,citation_author=J. Bien;,citation_author=J. Taylor;,citation_author=R. Tibshirani;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=41;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Fast nonlocal means for image denoising;,citation_author=R. C. Bilcu;,citation_author=M. Vehvilainen;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=Electronic imaging 2007;,citation_conference=International Society for Optics; Photonics;">
<meta name="citation_reference" content="citation_title=Combined non-local averaging and intersection of confiden intervals for image de-noising;,citation_author=R. C. Bilcu;,citation_author=M. Vehvilainen;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Random projection in dimensionality reduction: Applications to image and text data;,citation_author=E. Bingham;,citation_author=H. Mannila;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=Proceedings of the seventh ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Gaussian model selection;,citation_author=L. Birgé;,citation_author=P. Massart;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=3;,citation_volume=3;,citation_journal_title=J. Eur. Math. Soc. (JEMS);">
<meta name="citation_reference" content="citation_title=Minimum contrast estimators on sieves: Exponential bounds and rates of convergence;,citation_author=L. Birgé;,citation_author=P. Massart;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=3;,citation_volume=4;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Model selection via testing: An alternative to (penalized) maximum likelihood estimators;,citation_author=L. Birgé;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=42;,citation_journal_title=Ann. Inst. H. Poincaré Probab. Statist.;">
<meta name="citation_reference" content="citation_title=Pattern recognition and machine learning;,citation_author=C. M. Bishop;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_series_title=Information science and statistics;">
<meta name="citation_reference" content="citation_title=Edges as outliers: Anisotropic smoothing using local image statistics;,citation_author=M. J. Black;,citation_author=G. Sapiro;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=SCALE-SPACE ’99: Proceedings of the second international conference on scale-space theories in computer vision;">
<meta name="citation_reference" content="citation_title=Convex factorization machines;,citation_author=M. Blondel;,citation_author=A. Fujino;,citation_author=N. Ueda;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_inbook_title=Machine learning and knowledge discovery in databases;">
<meta name="citation_reference" content="citation_title=Block coordinate descent algorithms for large-scale sparse multiclass classification;,citation_author=M. Blondel;,citation_author=K. Seki;,citation_author=K. Uehara;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=93;,citation_journal_title=Machine Learning;">
<meta name="citation_reference" content="citation_title=Least absolute deviations;,citation_author=P. Bloomfield;,citation_author=W. L. Steiger;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_volume=6;,citation_series_title=Progress in probability and statistics;">
<meta name="citation_reference" content="citation_title=The SURE-LET approach to image denoising;,citation_author=T. Blu;,citation_author=F. Luisier;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=11;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Iterative thresholding for sparse approximations;,citation_author=T. Blumensath;,citation_author=M. E. Davies;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=5;,citation_volume=14;,citation_journal_title=J. Fourier Anal. Appl.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Recommender systems survey;,citation_author=J. Bobadilla;,citation_author=F. Ortega;,citation_author=A. Hernando;,citation_author=A. Gutiérrez;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=0;,citation_volume=46;,citation_journal_title=Knowledge-Based Systems;">
<meta name="citation_reference" content="citation_title=SLOPE-adaptive variable selection via convex optimization;,citation_author=M. Bogdan;,citation_author=E. Berg;,citation_author=C. Sabatti;,citation_author=W. Su;,citation_author=E. J. Candès;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=3;,citation_volume=9;,citation_journal_title=Ann. Appl. Stat.;">
<meta name="citation_reference" content="citation_title=Active set strategy for high-dimensional non-convex sparse optimization problems;,citation_author=A. Boisbunon;,citation_author=R. Flamary;,citation_author=A. Rakotomamonjy;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=ICASSP;">
<meta name="citation_reference" content="citation_title=Nonlinear acceleration of momentum and primal-dual algorithms;,citation_author=R. Bollapragada;,citation_author=D. Scieur;,citation_author=A. Aspremont;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=abs/1810.04539;,citation_journal_title=ArXiv e-print;">
<meta name="citation_reference" content="citation_title=Space-time event sparse penalization for magneto-/electroencephalography;,citation_author=A. Bolstad;,citation_author=B. Van Veen;,citation_author=R. Nowak;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=4;,citation_volume=46;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=A mathematical model for automatic differentiation in machine learning;,citation_author=J. Bolte;,citation_author=E. Pauwels;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=abs/2006.02080;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Proximal alternating linearized minimization for nonconvex and nonsmooth problems;,citation_author=J. Bolte;,citation_author=S. Sabach;,citation_author=M. Teboulle;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=146;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Simultaneous regression shrinkage, variable selection, and supervised clustering of predictors with OSCAR;,citation_author=H. D. Bondell;,citation_author=B. J. Reich;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=1;,citation_volume=64;,citation_journal_title=Biometrics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=A dynamic screening principle for the lasso;,citation_author=A. Bonnefoy;,citation_author=V. Emiya;,citation_author=L. Ralaivola;,citation_author=R. Gribonval;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=EUSIPCO;">
<meta name="citation_reference" content="citation_title=Dynamic screening: accelerating first-order algorithms for the Lasso and Group-Lasso;,citation_author=A. Bonnefoy;,citation_author=V. Emiya;,citation_author=L. Ralaivola;,citation_author=R. Gribonval;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=19;,citation_volume=63;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Plant identification: Experts vs. Machines in the era of deep learning;,citation_author=P. Bonnet;,citation_author=H. Goëau;,citation_author=S. T. Hang;,citation_author=M. Lasseck;,citation_author=M. Šulc;,citation_author=V. Malécot;,citation_author=P. Jauzein;,citation_author=undefined Melet;,citation_author=C. You;,citation_author=A. Joly;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=Multimedia tools and applications for environmental &amp;amp;amp; biodiversity informatics;">
<meta name="citation_reference" content="citation_title=A note on differentials and the CLT and LIL for statistical functions, with application to $M$-estimates;,citation_author=D. D. Boos;,citation_author=R. J. Serfling;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=3;,citation_volume=8;,citation_journal_title=Ann. Statist.;,citation_publisher=The Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Radioactive Scandium in the youngest galactic supernova remnant G1. 9+ 0.3;,citation_author=K. J. Borkowski;,citation_author=S. P. Reynolds;,citation_author=D. A. Green;,citation_author=U. Hwang;,citation_author=R. Petre;,citation_author=K. Krishnamurthy;,citation_author=R. Willett;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=724;,citation_journal_title=The Astrophysical Journal Letters;,citation_publisher=IOP Publishing;">
<meta name="citation_reference" content="citation_title=Convex analysis and nonlinear optimization. Theory and examples;,citation_author=J. M. Borwein;,citation_author=A. S. Lewis;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=A training algorithm for optimal margin classifiers;,citation_author=B. E. Boser;,citation_author=I. M. Guyon;,citation_author=V. N. Vapnik;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_conference_title=Proceedings of the fifth annual workshop on computational learning theory;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=The art of readable code;,citation_author=D. Boswell;,citation_author=T. Foucher;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=A deep learning approach to species distribution modelling;,citation_author=C. Botella;,citation_author=A. Joly;,citation_author=P. Bonnet;,citation_author=P. Monestiez;,citation_author=F. Munoz;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_inbook_title=Multimedia tools and applications for environmental &amp;amp;amp; biodiversity informatics;">
<meta name="citation_reference" content="citation_title=The tradeoffs of large scale learning;,citation_author=L. Bottou;,citation_author=O. Bousquet;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Online learning and stochastic approximations;,citation_author=L. Bottou;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=9;,citation_volume=17;,citation_journal_title=On-line learning in neural networks;,citation_publisher=Cambridge University Press;">
<meta name="citation_reference" content="citation_title=Theory of classification: A survey of some recent advances;,citation_author=S. Boucheron;,citation_author=O. Bousquet;,citation_author=G. Lugosi;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=9;,citation_journal_title=ESAIM Probab. Stat.;">
<meta name="citation_reference" content="citation_title=Concentration inequalities: A nonasymptotic theory of independence;,citation_author=S. Boucheron;,citation_author=G. Lugosi;,citation_author=P. Massart;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Local and nonlocal discrete regularization on weighted graphs for image and mesh processing;,citation_author=S. Bougleux;,citation_author=A. Elmoataz;,citation_author=M. Melkemi;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=84;,citation_journal_title=Int. J. Comput. Vision;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Patch-based nonlocal functional for denoising fluorescence microscopy image sequences.;,citation_author=J. Boulanger;,citation_author=C. Kervrann;,citation_author=P. Bouthemy;,citation_author=P. Elbau;,citation_author=undefined Sibarita;,citation_author=J. Salamero;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=29;,citation_journal_title=IEEE Trans. Med. Imag.;">
<meta name="citation_reference" content="citation_title=Handbook of image and video processing (communications, networking and multimedia);,citation_author=A. C. Bovik;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Robustness in the strategy of scientific model building;,citation_author=G. E. P. Box;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_inbook_title=Robustness in statistics;">
<meta name="citation_reference" content="citation_title=Randomized gossip algorithms;,citation_author=S. Boyd;,citation_author=A. Ghosh;,citation_author=B. Prabhakar;,citation_author=D. Shah;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=6;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Distributed optimization and statistical learning via the alternating direction method of multipliers;,citation_author=S. Boyd;,citation_author=N. Parikh;,citation_author=E. Chu;,citation_author=B. Peleato;,citation_author=J. Eckstein;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=3;,citation_journal_title=Foundations and Trends in Machine Learning;">
<meta name="citation_reference" content="citation_title=Convex optimization;,citation_author=S. Boyd;,citation_author=L. Vandenberghe;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Adapting to unknown noise level in sparse deconvolution;,citation_author=C. Boyer;,citation_author=Y. De Castro;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=http://arxiv.org/pdf/1606.04760v1;,citation_issue=3;,citation_volume=6;,citation_journal_title=Inf. Inference;">
<meta name="citation_reference" content="citation_title=Differential sparse coding;,citation_author=D. M. Bradley;,citation_author=J. A. Bagnell;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=22;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Inverse problems in spaces of measures;,citation_author=K. Bredies;,citation_author=H. K. Pikkarainen;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=01;,citation_volume=19;,citation_journal_title=ESAIM: Control, Optimisation and Calculus of Variations;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=The relaxation method of finding the common point of convex sets and its application to the solution of problems in convex programming;,citation_author=L. M. Bregman;,citation_publication_date=1967;,citation_cover_date=1967;,citation_year=1967;,citation_issue=3;,citation_volume=7;,citation_journal_title=Comput. Math. Math. Phys.;">
<meta name="citation_reference" content="citation_title=Coordinate descent algorithms for nonconvex penalized regression, with applications to biological feature selection;,citation_author=P. Breheny;,citation_author=J. Huang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=5;,citation_journal_title=Ann. Appl. Stat.;,citation_publisher=NIH Public Access;">
<meta name="citation_reference" content="citation_title=Classification and regression trees;,citation_author=L. Breiman;,citation_author=J. H. Friedman;,citation_author=R. A. Olshen;,citation_author=C. J. Stone;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_series_title=Wadsworth statistics/probability series;">
<meta name="citation_reference" content="citation_title=Random Forests;,citation_author=L. Breiman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=1;,citation_volume=45;,citation_journal_title=Mach. Learn.;,citation_publisher=Springer Netherlands;">
<meta name="citation_reference" content="citation_title=Better subset regression using the nonnegative garrote;,citation_author=L. Breiman;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_volume=37;,citation_journal_title=Technometrics;,citation_publisher=Springer Netherlands;">
<meta name="citation_reference" content="citation_title=Stacked regressions;,citation_author=L. Breiman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=1;,citation_volume=24;,citation_journal_title=Mach. Learn.;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Bagging predictors;,citation_author=L. Breiman;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=2;,citation_volume=24;,citation_journal_title=Mach. Learn.;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Markov chains;,citation_author=P. Brémaud;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=31;,citation_series_title=Texts in applied mathematics;">
<meta name="citation_reference" content="citation_title=Functional analysis, Sobolev spaces and partial differential equations;,citation_author=H. Brezis;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_series_title=Universitext;">
<meta name="citation_reference" content="citation_title=The DFT an owners’ manual for the Discrete Fourier Transform;,citation_author=W. L. Briggs;,citation_author=V. E. Henson;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;">
<meta name="citation_reference" content="citation_title=Bias-reduction in variational regularization;,citation_author=E.-M. Brinkmann;,citation_author=M. Burger;,citation_author=J. Rasch;,citation_author=C. Sutour;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=3;,citation_volume=59;,citation_journal_title=J. Math. Imaging Vis.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning;,citation_author=E. Brochu;,citation_author=V. M. Cora;,citation_author=N. De Freitas;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=The root-unroot algorithm for density estimation as implemented via wavelet block thresholding;,citation_author=L. Brown;,citation_author=T. T. Cai;,citation_author=R. Zhang;,citation_author=L. Zhao;,citation_author=H. Zhou;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3-4;,citation_volume=146;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=Iterated nonlocal means for texture restoration;,citation_author=T. Brox;,citation_author=D. Cremers;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=4485;,citation_conference_title=SSVM;,citation_series_title=Lecture notes in computer science;">
<meta name="citation_reference" content="citation_title=Efficient nonlocal means for denoising of textural patterns;,citation_author=T. Brox;,citation_author=O. Kleinschmidt;,citation_author=D. Cremers;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=7;,citation_volume=17;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Image and movie denoising by non local means;,citation_author=A. Buades;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_dissertation_institution=Universitat de les Illes Balears;">
<meta name="citation_reference" content="citation_title=A review of image denoising algorithms, with a new one;,citation_author=A. Buades;,citation_author=B. Coll;,citation_author=undefined Morel;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=4;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=The staircasing effect in neighborhood filters and its solution;,citation_author=A. Buades;,citation_author=B. Coll;,citation_author=undefined Morel;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=6;,citation_volume=15;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Nonlocal image and movie denoising;,citation_author=A. Buades;,citation_author=B. Coll;,citation_author=undefined Morel;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=76;,citation_journal_title=Int. J. Comput. Vision;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Non-local means denoising;,citation_author=A. Buades;,citation_author=B. Coll;,citation_author=undefined Morel;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Image Processing on Line;">
<meta name="citation_reference" content="citation_title=Implementation of the “non-local Bayes” image denoising algorithm;,citation_author=A. Buades;,citation_author=M. Lebrun;,citation_author=undefined Morel;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Image Processing On Line;">
<meta name="citation_reference" content="citation_title=Regret analysis of stochastic and nonstochastic multi-armed bandit problems;,citation_author=S. Bubeck;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=5;,citation_journal_title=Foundations and Trends in Machine Learning;,citation_publisher=Now publishers Inc;">
<meta name="citation_reference" content="citation_title=WaveLab and reproducible research;,citation_author=J. B. Buckheit;,citation_author=D. L. Donoho;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_inbook_title=Wavelets and statistics;,citation_series_title=Lect. Notes statist.;">
<meta name="citation_reference" content="citation_title=Statistics for high-dimensional data;,citation_author=P. Bühlmann;,citation_author=S. Geer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Statistics for big data: A perspective;,citation_author=P. Bühlmann;,citation_author=S. Geer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=136;,citation_journal_title=Statistics &amp;amp;amp; Probability Letters;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Boosting with the L2 loss: Regression and classification;,citation_author=P. Bühlmann;,citation_author=B. Yu;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=462;,citation_volume=98;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Statistical significance in high-dimensional linear models;,citation_author=P. Bühlmann;,citation_publication_date=2013-09;,citation_cover_date=2013-09;,citation_year=2013;,citation_issue=4;,citation_volume=19;,citation_journal_title=Bernoulli;,citation_publisher=Bernoulli Society for Mathematical Statistics; Probability;">
<meta name="citation_reference" content="citation_title=High-dimensional statistics, with applications to genome-wide association studies;,citation_author=P. Bühlmann;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=4;,citation_journal_title=EMS Surveys in Mathematical Sciences;">
<meta name="citation_reference" content="citation_title=The group square-root Lasso: Theoretical properties and fas algorithms;,citation_author=F. Bunea;,citation_author=J. Lederer;,citation_author=Y. She;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=60;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Sequential procedures for aggregating arbitrary estimators of a conditional mean;,citation_author=F. Bunea;,citation_author=A. Nobel;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=54;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Aggregation for Gaussian regression;,citation_author=F. Bunea;,citation_author=A. B. Tsybakov;,citation_author=M. H. Wegkamp;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=4;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Sparsity oracle inequalities for the Lasso;,citation_author=F. Bunea;,citation_author=A. B. Tsybakov;,citation_author=M. H. Wegkamp;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=1;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Nonlinear inverse scale space methods;,citation_author=M. Burger;,citation_author=G. Gilboa;,citation_author=S. Osher;,citation_author=J. Xu;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=4;,citation_journal_title=Communications in Mathematical Sciences;,citation_publisher=International Press of Boston;">
<meta name="citation_reference" content="citation_title=Convergence rates of convex variational regularization;,citation_author=M. Burger;,citation_author=S. Osher;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=5;,citation_volume=20;,citation_journal_title=Inverse Problems;">
<meta name="citation_reference" content="citation_title=Image denoising with multi-layer perceptrons, part 1: Comparison with existing algorithms and with bounds;,citation_author=H. C. Burger;,citation_author=C. J. Schuler;,citation_author=S. Harmeling;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=arXiv preprint arXiv:1211.1544;">
<meta name="citation_reference" content="citation_title=Image denoising with multi-layer perceptrons, part 2: Training trade-offs and analysis of their mechanisms;,citation_author=H. C. Burger;,citation_author=C. J. Schuler;,citation_author=S. Harmeling;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=arXiv preprint arXiv:1211.1552;">
<meta name="citation_reference" content="citation_title=On the identification of active constraints;,citation_author=J. V. Burke;,citation_author=J. J. Moré;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=5;,citation_volume=25;,citation_journal_title=SIAM J. Numer. Anal.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=A singular value thresholding algorithm for matrix completion;,citation_author=undefined Cai;,citation_author=E. J. Candès;,citation_author=Z. Shen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=20;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Matrix completion via max-norm constrained optimization;,citation_author=T. T. Cai;,citation_author=undefined Zhou;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=abs/1303.0341;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=A max-norm constrained minimization approach to 1-bit matrix completion;,citation_author=T. T. Cai;,citation_author=undefined Zhou;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=14;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Adaptive wavelet estimation: A block thresholding and oracle inequality approach;,citation_author=T. T. Cai;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=3;,citation_volume=27;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Sparse identification of polynomial and posynomial models;,citation_author=G. C. Calafiore;,citation_author=L. El Ghaoui;,citation_author=C. Novara;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=47;,citation_journal_title=IFAC Proceedings Volumes;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Fast discrete curvelet transforms;,citation_author=E. J. Candès;,citation_author=L. Demanet;,citation_author=D. L. Donoho;,citation_author=L. Ying;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=5;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=Curvelets-a surprisingly effective nonadaptive representation for objects with edges;,citation_author=E. J. Candès;,citation_author=D. L. Donoho;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=Curve and surface fitting;">
<meta name="citation_reference" content="citation_title=Super-resolution from noisy data;,citation_author=E. J. Candès;,citation_author=C. Fernandez-Granda;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=6;,citation_volume=19;,citation_journal_title=J. Fourier Anal. Appl.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Towards a mathematical theory of super-resolution;,citation_author=E. J. Candès;,citation_author=C. Fernandez-Granda;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=6;,citation_volume=67;,citation_journal_title=Comm. Pure Appl. Math.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Robust principal component analysis?;,citation_author=E. J. Candès;,citation_author=X. Li;,citation_author=Y. Ma;,citation_author=J. Wright;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=58;,citation_journal_title=J. ACM;">
<meta name="citation_reference" content="citation_title=Near-ideal model selection by $\ell_1$ minimization;,citation_author=E. J. Candès;,citation_author=Y. Plan;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5A;,citation_volume=37;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Matrix completion with noise;,citation_author=E. J. Candès;,citation_author=Y. Plan;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=6;,citation_volume=98;,citation_journal_title=Proceedings of the IEEE;">
<meta name="citation_reference" content="citation_title=Exact matrix completion via convex optimization;,citation_author=E. J. Candès;,citation_author=B. Recht;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=6;,citation_volume=9;,citation_journal_title=Found. Comput. Math.;">
<meta name="citation_reference" content="citation_title=Simple bounds for recovering low-complexity models;,citation_author=E. J. Candès;,citation_author=B. Recht;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Math. Program.;,citation_publisher=Springer Berlin / Heidelberg;">
<meta name="citation_reference" content="citation_title=Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information;,citation_author=E. J. Candès;,citation_author=J. Romberg;,citation_author=T. Tao;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=2;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Decoding by linear programming;,citation_author=E. J. Candès;,citation_author=T. Tao;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=12;,citation_volume=51;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=The Dantzig selector: Statistical estimation when $p$ is much larger than $n$;,citation_author=E. J. Candès;,citation_author=T. Tao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=6;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Rejoinder: “The Dantzig selector: Statistical estimation when $p$ is much larger than $n$”;,citation_author=E. J. Candès;,citation_author=T. Tao;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=6;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=The power of convex relaxation: Near-optimal matrix completion;,citation_author=E. J. Candès;,citation_author=T. Tao;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=5;,citation_volume=56;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Enhancing sparsity by reweighted $l_1$ minimization;,citation_author=E. J. Candès;,citation_author=M. B. Wakin;,citation_author=S. P. Boyd;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=5-6;,citation_volume=14;,citation_journal_title=J. Fourier Anal. Applicat.;">
<meta name="citation_reference" content="citation_title=Learning imbalanced datasets with label-distribution-aware margin loss;,citation_author=K. Cao;,citation_author=C. Wei;,citation_author=A. Gaidon;,citation_author=N. Arechiga;,citation_author=T. Ma;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=32;,citation_conference_title=NeurIPS;,citation_conference=Curran Associates, Inc.;">
<meta name="citation_reference" content="citation_title=On-line expectation–maximization algorithm for latent data models;,citation_author=O. Cappé;,citation_author=É. Moulines;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=71;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Programmation dynamique;,citation_author=G. Carlier;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Going deeper in the automated identification of herbarium specimens;,citation_author=J. Carranza-Rojas;,citation_author=H. Goëau;,citation_author=P. Bonnet;,citation_author=E. Mata-Montero;,citation_author=A. Joly;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=17;,citation_journal_title=BMC evolutionary biology;,citation_publisher=BioMed Central;">
<meta name="citation_reference" content="citation_title=Transformation and weighting in regression;,citation_author=R. J. Carroll;,citation_author=D. Ruppert;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_volume=30;">
<meta name="citation_reference" content="citation_title=Multitask learning;,citation_author=R. Caruana;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_inbook_title=Learning to learn;">
<meta name="citation_reference" content="citation_title=Statistical inference;,citation_author=G. Casella;,citation_author=R. L. Berger;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Statistical learning theory and stochastic optimization;,citation_author=O. Catoni;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=1851;,citation_series_title=Lecture notes in mathematics;">
<meta name="citation_reference" content="citation_title=Pac-Bayesian supervised classification: The thermodynamics of statistical learning;,citation_author=O. Catoni;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Challenging the empirical mean and empirical variance: A deviation study;,citation_author=O. Catoni;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=48;,citation_journal_title=Ann. Inst. Henri Poincaré Probab. Stat.;">
<meta name="citation_reference" content="citation_title=&amp;amp;amp;quot;Universal&amp;quot; aggregation rules with exact bias bounds;,citation_author=O. Catoni;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_technical_report_institution=Université Paris 6 Pierre et Marie Curie;">
<meta name="citation_reference" content="citation_title=Méthode générale pour la résolution des systèmes d’équations simultanées;,citation_author=A. Cauchy;,citation_publication_date=1847;,citation_cover_date=1847;,citation_year=1847;,citation_issue=1847;,citation_volume=25;,citation_journal_title=Comp. Rend. Sci. Paris;">
<meta name="citation_reference" content="citation_title=Oracle inequalities for inverse problems;,citation_author=L. Cavalier;,citation_author=G. K. Golubev;,citation_author=D. Picard;,citation_author=A. B. Tsybakov;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=3;,citation_volume=30;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Penalized blockwise Stein’s method, monotone oracles and sharp adaptive estimation;,citation_author=L. Cavalier;,citation_author=A. B. Tsybakov;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=3;,citation_volume=10;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=Sharp adaptation for inverse problems with random noise;,citation_author=L. Cavalier;,citation_author=A. B. Tsybakov;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=3;,citation_volume=123;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=Nonparametric statistical inverse problems;,citation_author=L. Cavalier;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=24;,citation_journal_title=Inverse Problems;">
<meta name="citation_reference" content="citation_title=Computational acceleration of projection algorithms for the linear best approximation problem;,citation_author=Y. Censor;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=416;,citation_journal_title=Linear Algebra and its Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Prediction, learning, and games;,citation_author=N. Cesa-Bianchi;,citation_author=G. Lugosi;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Improved second-order bounds for prediction with expert advice;,citation_author=N. Cesa-Bianchi;,citation_author=Y. Mansour;,citation_author=G. Stoltz;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=66;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=Singular values of random matrices;,citation_author=D. Chafaï;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Lecture Notes;,citation_publisher=Citeseer;">
<meta name="citation_reference" content="citation_title=How to make sure the iterates of FISTA converge;,citation_author=A. Chambolle;,citation_author=C. Dossal;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=Preprint;">
<meta name="citation_reference" content="citation_title=A first-order primal-dual algorithm for convex problems with applications to imaging;,citation_author=A. Chambolle;,citation_author=T. Pock;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=40;,citation_journal_title=J. Math. Imaging Vis.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=The convex geometry of linear inverse problems;,citation_author=V. Chandrasekaran;,citation_author=B. Recht;,citation_author=P. A. Parrilo;,citation_author=A. S. Willsky;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=6;,citation_volume=12;,citation_journal_title=Foundations of Computational Mathematics;">
<meta name="citation_reference" content="citation_title=LIBSVM: A library for support vector machines;,citation_author=undefined Chang;,citation_author=undefined Lin;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=2;,citation_journal_title=ACM transactions on intelligent systems and technology (TIST);,citation_publisher=Acm;">
<meta name="citation_reference" content="citation_title=Prediction error of cross-validated lasso;,citation_author=S. Chatterjee;,citation_author=J. Jafarov;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=arXiv preprint arXiv:1502.06291;">
<meta name="citation_reference" content="citation_title=A generalization of non-local means via kernel regression;,citation_author=P. Chatterjee;,citation_author=P. Milanfar;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=6814;,citation_conference_title=SPIE;">
<meta name="citation_reference" content="citation_title=Patch-based near-optimal image denoising;,citation_author=P. Chatterjee;,citation_author=P. Milanfar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Alternating estimation for structured high-dimensional multi-response models;,citation_author=S. Chen;,citation_author=A. Banerjee;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Robust sparse regression under adversarial corruption;,citation_author=Y. Chen;,citation_author=C. Caramanis;,citation_author=S. Mannor;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Noisy and missing data regression: Distribution-oblivious support recovery;,citation_author=Y. Chen;,citation_author=C. Caramanis;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Atomic decomposition by basis pursuit;,citation_author=S. S. Chen;,citation_author=D. L. Donoho;,citation_author=M. A. Saunders;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=1;,citation_volume=20;,citation_journal_title=SIAM J. Sci. Comput.;">
<meta name="citation_reference" content="citation_title=Atomic decomposition by basis pursuit;,citation_author=S. S. Chen;,citation_author=D. L. Donoho;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_conference_title=SPIE;">
<meta name="citation_reference" content="citation_title=A general decision theory for huber’s $\epsilon$-contamination model;,citation_author=M. Chen;,citation_author=C. Gao;,citation_author=Z. Ren;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_volume=10;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Maximum block improvement and polynomial optimization;,citation_author=B. Chen;,citation_author=S. He;,citation_author=Z. Li;,citation_author=S. Zhang;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=22;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Robust covariance matrix estimation under huber’s contamination model;,citation_author=M. Chen;,citation_author=C. Gao;,citation_author=Z. Ren;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=A simple framework for contrastive learning of visual representations;,citation_author=Ting Chen;,citation_author=Simon Kornblith;,citation_author=Mohammad Norouzi;,citation_author=Geoffrey E. Hinton;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=119;,citation_conference_title=ICML;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Absolute approximation of Tukey depth: Theory and experiments;,citation_author=D. Chen;,citation_author=P. Morin;,citation_author=U. Wagner;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=5;,citation_volume=46;,citation_journal_title=Comput. Geom.;">
<meta name="citation_reference" content="citation_title=Poisson approximation for dependent trials;,citation_author=L. H. Y. Chen;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_journal_title=Ann. Probability;">
<meta name="citation_reference" content="citation_title=Mean shift, mode seeking, and clustering;,citation_author=Y. Cheng;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=8;,citation_volume=17;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;,citation_publisher=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Optimal two-step prediction in regression;,citation_author=D. Chételat;,citation_author=J. Lederer;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=11;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Statistical inference with ensemble of clustered desparsified lasso;,citation_author=undefined Chevalier;,citation_author=J. Salmon;,citation_author=B. Thirion;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=International Conference on Medical Image Computing and Computer-Assisted Intervention;">
<meta name="citation_reference" content="citation_title=Performances statistiques d’estimateurs non-linéaires;,citation_author=M. Chichignoud;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_dissertation_institution=Université Aix-Marseille 1;">
<meta name="citation_reference" content="citation_title=Tuning lasso for sup-norm optimality;,citation_author=M. Chichignoud;,citation_author=J. Lederer;,citation_author=M. J. Wainwright;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=17;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=A robust, adaptive M-estimator for pointwise estimation in heteroscedastic regression;,citation_author=M. Chichignoud;,citation_author=J. Lederer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=20;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Fast tree inference with weighted fusion penalties;,citation_author=J. Chiquet;,citation_author=P. Gutierrez;,citation_author=G. Rigaill;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1407.5915;">
<meta name="citation_reference" content="citation_title=Learning a similarity metric discriminatively, with application to face verification;,citation_author=Sumit Chopra;,citation_author=Raia Hadsell;,citation_author=Yann LeCun;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=CVPR;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Sparse recovery with unknown variance: A LASSO-type approach;,citation_author=S. Chrétien;,citation_author=S. Darses;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Spectral Graph Theory;,citation_author=F. R. K. Chung;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_volume=92;">
<meta name="citation_reference" content="citation_title=On the benefits of output sparsity for multi-label classification;,citation_author=E. Chzhen;,citation_author=C. Denis;,citation_author=M. Hebiri;,citation_author=J. Salmon;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=On Lasso refitting strategies;,citation_author=E. Chzhen;,citation_author=M. Hebiri;,citation_author=J. Salmon;,citation_publication_date=2019-11;,citation_cover_date=2019-11;,citation_year=2019;,citation_issue=4A;,citation_volume=25;,citation_journal_title=Bernoulli;,citation_publisher=Bernoulli Society for Mathematical Statistics; Probability;">
<meta name="citation_reference" content="citation_title=Plug-in approach for sparse multi-label learning;,citation_author=E. Chzhen;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=(under review);">
<meta name="citation_reference" content="citation_title=Introduction à l’analyse numérique matricielle et à l’optimisation. Cours et exercices corrigés;,citation_author=P. G. Ciarlet;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Linear models: The theory and application of analysis of variance;,citation_author=B. R. Clarke;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=634;">
<meta name="citation_reference" content="citation_title=Method of dynamic and nonsmooth optimization;,citation_author=F. H. Clarke;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;">
<meta name="citation_reference" content="citation_title=Coresets, sparse greedy approximation, and the frank-wolfe algorithm;,citation_author=K. L. Clarkson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=6;,citation_journal_title=ACM Transactions on Algorithms (TALG);,citation_publisher=ACM;">
<meta name="citation_reference" content="citation_title=Expectation consistency for calibration of neural networks;,citation_author=L. Clarté;,citation_author=B. Loureiro;,citation_author=F. Krzakala;,citation_author=L. Zdeborová;,citation_editor=Robin J. Evans;,citation_editor=Ilya Shpitser;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_fulltext_html_url=https://proceedings.mlr.press/v216/clarte23a.html;,citation_volume=216;,citation_conference_title=Uncertainty in artificial intelligence;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Ranking and empirical minimization of U-statistics;,citation_author=S. Clémençon;,citation_author=G. Lugosi;,citation_author=N. Vayatis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=36;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On U-processes and clustering performance;,citation_author=S. Clémençon;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Maximal spaces with given rate of convergence for thresholding algorithms;,citation_author=A. Cohen;,citation_author=R. A. DeVore;,citation_author=G. Kerkyacharian;,citation_author=D. Picard;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=2;,citation_volume=11;,citation_journal_title=Appl. Comput. Harmon. Anal.;">
<meta name="citation_reference" content="citation_title=Magnetoencephalography: Evidence of magnetic fields produced by alpha-rhythm currents;,citation_author=D. Cohen;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_journal_title=Science;,citation_publisher=American Association for the Advancement of Science;">
<meta name="citation_reference" content="citation_title=All admissible linear estimates of the mean vector;,citation_author=A. Cohen;,citation_publication_date=1966;,citation_cover_date=1966;,citation_year=1966;,citation_issue=2;,citation_volume=37;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=Translation-invariant de-noising;,citation_author=R. R. Coifman;,citation_author=D. L. Donoho;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_technical_report_institution=Stanford;">
<meta name="citation_reference" content="citation_title=Adaptation des méthodes d’apprentissage aux u-statistiques;,citation_author=I. Colin;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_dissertation_institution=Télécom ParisTech;">
<meta name="citation_reference" content="citation_title=Extending gossip algorithms to distributed estimation of U-Statistics;,citation_author=I. Colin;,citation_author=A. Bellet;,citation_author=J. Salmon;,citation_author=S. Clémençon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Gossip dual averaging for decentralized optimization of pairwise functions;,citation_author=I. Colin;,citation_author=A. Bellet;,citation_author=J. Salmon;,citation_author=S. Clémençon;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=A generalization of principal components analysis to the exponential family;,citation_author=M. Collins;,citation_author=S. Dasgupta;,citation_author=R. E. Schapire;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Mean shift: A robust approach toward feature space analysis;,citation_author=D. Comaniciu;,citation_author=P. Meer;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=5;,citation_volume=24;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;,citation_publisher=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Mean shift analysis and applications;,citation_author=D. Comaniciu;,citation_author=P. Meer;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=2;,citation_conference_title=ICCV;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Perspective functions: Proximal calculus and applications in high-dimensional statistics;,citation_author=P. L. Combettes;,citation_author=C. L. Müller;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=J. Math. Anal. Appl.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Proximal splitting methods in signal processing;,citation_author=P. L. Combettes;,citation_author=undefined Pesquet;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=49;,citation_inbook_title=Fixed-point algorithms for inverse problems in science and engineering;,citation_series_title=Springer optim. appl.;">
<meta name="citation_reference" content="citation_title=Signal recovery by proximal forward-backward splitting;,citation_author=P. L. Combettes;,citation_author=V. R. Wajs;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=4;,citation_volume=4;,citation_journal_title=Multiscale Modeling &amp;amp;amp; Simulation;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Perspective functions: Properties, constructions, and examples;,citation_author=P. L. Combettes;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=arXiv preprint arXiv:1610.01552;">
<meta name="citation_reference" content="citation_title=A Simple Trick to Speed Up and Improve the Non-Local Means;,citation_author=L. Condat;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=submited,hal-00512801;">
<meta name="citation_reference" content="citation_title=A primal–dual splitting method for convex optimization involving Lipschitzian, proximable and linear composite terms;,citation_author=L. Condat;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=158;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Introduction to algorithms;,citation_author=T. H. Cormen;,citation_author=C. E. Leiserson;,citation_author=R. L. Rivest;,citation_author=C. Stein;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Statistiques avec R;,citation_author=P-A. Cornillon;,citation_author=A. Guyader;,citation_author=F. Husson;,citation_author=N. Jégou;,citation_author=J. Josse;,citation_author=M. Kloareg;,citation_author=E. Matzner-Løber;,citation_author=L. Rouvière;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_series_title=Didact statistiques;">
<meta name="citation_reference" content="citation_title=Recursive bias estimation for multivariate regression smoothers;,citation_author=P-A. Cornillon;,citation_author=N. Hengartner;,citation_author=E. Matzner-Løber;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=submitted;">
<meta name="citation_reference" content="citation_title=Régression avec R;,citation_author=P-A. Cornillon;,citation_author=E. Matzner-Løber;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;">
<meta name="citation_reference" content="citation_title=Exercices de probabilités, licence - master - Écoles d’ingénieur;,citation_author=M. Cottrell;,citation_author=V. Genon-Catalot;,citation_author=C. Duhamel;,citation_author=T. Meyre;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Informatique pour tous en classes préparatoires aux grandes écoles: Manuel d’algorithmique et programmation structurée avec python;,citation_author=J. Courant;,citation_author=M. Falco;,citation_author=S. Gonnord;,citation_author=undefined Filliâtre;,citation_author=S. Conchon;,citation_author=G. Dowek;,citation_author=B. Wack;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Elements of information theory;,citation_author=T. M. Cover;,citation_author=J. A. Thomas;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_series_title=Wiley series in telecommunications;">
<meta name="citation_reference" content="citation_title=Object removal by exemplar-based inpainting;,citation_author=A. Criminisi;,citation_author=P. Pérez;,citation_author=K. Toyama;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=2;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Region filling and object removal by exemplar-based image inpainting;,citation_author=A. Criminisi;,citation_author=P. Pérez;,citation_author=K. Toyama;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=9;,citation_volume=13;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Summed-area tables for texture mapping;,citation_author=F. C. Crow;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=3;,citation_volume=18;,citation_journal_title=ACM SIGGRAPH Computer Graphics;,citation_publisher=ACM;">
<meta name="citation_reference" content="citation_title=Image denoising by sparse 3-D transform-domain collaborative filtering;,citation_author=K. Dabov;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=8;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=A non-local and shape-adaptive transform-domain collaborative filtering;,citation_author=K. Dabov;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=LNLA;">
<meta name="citation_reference" content="citation_title=BM3D image denoising with shape-adaptive principal component analysis;,citation_author=K. Dabov;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=Proc. Workshop on signal processing with adaptive sparse structured representations (SPARS’09);">
<meta name="citation_reference" content="citation_title=Deviation optimal learning using greedy Q-aggregation;,citation_author=D. Dai;,citation_author=P. Rigollet;,citation_author=T. Zhang;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=40;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Greedy model averaging;,citation_author=D. Dai;,citation_author=T. Zhang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Fused sparsity and robust estimation for linear models with unknown variance;,citation_author=A. S. Dalalyan;,citation_author=Y. Chen;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=On the prediction performance of the Lasso;,citation_author=A. S. Dalalyan;,citation_author=M. Hebiri;,citation_author=J. Lederer;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=23;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Learning heteroscedastic models by convex programming under group sparsity;,citation_author=A. S. Dalalyan;,citation_author=M. Hebiri;,citation_author=K. Meziani;,citation_author=J. Salmon;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Competing against the best nearest neighbor filter in regression;,citation_author=A. S. Dalalyan;,citation_author=J. Salmon;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ALT;">
<meta name="citation_reference" content="citation_title=Sharp oracle inequalities for aggregation of affine estimators;,citation_author=A. S. Dalalyan;,citation_author=J. Salmon;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=40;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Aggregation by exponential weighting, sharp oracle inequalities and sparsity;,citation_author=A. S. Dalalyan;,citation_author=A. B. Tsybakov;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Aggregation by exponential weighting, sharp PAC-Bayesian bounds and sparsity;,citation_author=A. S. Dalalyan;,citation_author=A. B. Tsybakov;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=72;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=Sparse regression learning by aggregation and Langevin Monte-Carlo;,citation_author=A. S. Dalalyan;,citation_author=A. B. Tsybakov;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Mirror averaging with sparsity priors;,citation_author=A. S. Dalalyan;,citation_author=A. B. Tsybakov;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Sparse regression learning by aggregation and Langevin Monte-Carlo;,citation_author=A. S. Dalalyan;,citation_author=A. B. Tsybakov;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=5;,citation_volume=78;,citation_journal_title=J. Comput. System Sci.;">
<meta name="citation_reference" content="citation_title=SOCP based variance free Dantzig selector with application to robust estimation;,citation_author=A. S. Dalalyan;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=15-16;,citation_volume=350;,citation_journal_title=C. R. Math. Acad. Sci. Paris;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Denoising of multispectral images via nonlocal groupwise spectrum-PCA;,citation_author=A. Danielyan;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. Egiazarian;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=CGIV2010/MCS’10;">
<meta name="citation_reference" content="citation_title=BM3D frames and variational image deblurring;,citation_author=A. Danielyan;,citation_author=V. Katkovnik;,citation_author=K. Egiazarian;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=21;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Fast nonlocal filtering applied to electron cryomicroscopy;,citation_author=J. Darbon;,citation_author=A. Cunha;,citation_author=T. F. Chan;,citation_author=S. Osher;,citation_author=G. J. Jensen;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ISBI;">
<meta name="citation_reference" content="citation_title=An elementary proof of a theorem of johnson and lindenstrauss;,citation_author=S. Dasgupta;,citation_author=A. Gupta;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=1;,citation_volume=22;,citation_journal_title=Random Structures &amp;amp;amp; Algorithms;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=An iterative thresholding algorithm for linear inverse problems with a sparsity constraint;,citation_author=I. Daubechies;,citation_author=M. Defrise;,citation_author=C. De Mol;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=11;,citation_volume=57;,citation_journal_title=Comm. Pure Appl. Math.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Iteratively reweighted least squares minimization for sparse recovery;,citation_author=I. Daubechies;,citation_author=R. DeVore;,citation_author=M. Fornasier;,citation_author=S. C. Güntürk;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=63;,citation_journal_title=Comm. Pure Appl. Math.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Ten lectures on wavelets;,citation_author=I. Daubechies;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=61;,citation_series_title=CBMS-NSF regional conference series in applied mathematics;">
<meta name="citation_reference" content="citation_title=A fast non-local image denoising algorithm;,citation_author=A. Dauwe;,citation_author=B. Goossens;,citation_author=H. Q. Luong;,citation_author=W. Philips;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=6812;,citation_conference_title=SPIE;">
<meta name="citation_reference" content="citation_title=1-bit matrix completion;,citation_author=M. A. Davenport;,citation_author=Y. Plan;,citation_author=E. Berg;,citation_author=M. Wootters;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=3;,citation_journal_title=Inf. Inference;">
<meta name="citation_reference" content="citation_title=Adaptive greedy approximations;,citation_author=G. Davis;,citation_author=S. Mallat;,citation_author=M. Avellaneda;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=13;,citation_journal_title=Constr. Approx.;">
<meta name="citation_reference" content="citation_title=High-dimensional heteroscedastic regression with an application to eQTL data analysis;,citation_author=J. Daye;,citation_author=J. Chen;,citation_author=H. Li;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=68;,citation_journal_title=Biometrics;,citation_publisher=Blackwell Publishing Inc;">
<meta name="citation_reference" content="citation_title=Shrinkage and model selection with correlated variables via weighted fusion;,citation_author=Z. Daye;,citation_author=X. Jeng;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=53;,citation_journal_title=Comput. Statist. Data Anal.;">
<meta name="citation_reference" content="citation_title=Exact reconstruction using Beurling minimal extrapolation;,citation_author=Y. De Castro;,citation_author=F. Gamboa;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=395;,citation_journal_title=J. Math. Anal. Appl.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Non-uniform spline recovery from small degree polynomial approximation;,citation_author=Y. De Castro;,citation_author=G. Mijoule;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=J. Math. Anal. Appl.;">
<meta name="citation_reference" content="citation_title=Iterative weighted maximum likelihood denoising with probabilistic patch-based weights;,citation_author=undefined Deledalle;,citation_author=L. Denis;,citation_author=F. Tupin;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=12;,citation_volume=18;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE Press;">
<meta name="citation_reference" content="citation_title=Poisson NL means: Unsupervised non local means for Poisson noise;,citation_author=undefined Deledalle;,citation_author=L. Denis;,citation_author=F. Tupin;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=NL-InSAR: Nonlocal interferogram estimation;,citation_author=undefined Deledalle;,citation_author=L. Denis;,citation_author=F. Tupin;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=49;,citation_journal_title=IEEE Trans. Geosci. Remote Sens.;,citation_publisher=IEEE Press;">
<meta name="citation_reference" content="citation_title=Patch similarity under non-gaussian noise;,citation_author=undefined Deledalle;,citation_author=F. Tupin;,citation_author=L. Denis;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=How to compare noisy patches? Patch similarity beyond gaussian noise;,citation_author=undefined Deledalle;,citation_author=L. Denis;,citation_author=F. Tupin;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Int. J. Comput. Vision;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Anisotropic non-local means with spatially adaptive patch shapes;,citation_author=undefined Deledalle;,citation_author=V. Duval;,citation_author=J. Salmon;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=SSVM;">
<meta name="citation_reference" content="citation_title=Non-local methods with shape-adaptive patches (NLM-SAP);,citation_author=undefined Deledalle;,citation_author=V. Duval;,citation_author=J. Salmon;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=43;,citation_journal_title=J. Math. Imaging Vis.;">
<meta name="citation_reference" content="citation_title=CLEAR: Covariant LEAst-square Re-fitting with applications to image restoration;,citation_author=undefined Deledalle;,citation_author=N. Papadakis;,citation_author=J. Salmon;,citation_author=S. Vaiter;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=10;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=On debiasing restoration algorithms: applications to total-variation and nonlocal-means;,citation_author=undefined Deledalle;,citation_author=N. Papadakis;,citation_author=J. Salmon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=SSVM;">
<meta name="citation_reference" content="citation_title=Contrast re-enhancement of Total-Variation regularization jointly with the Douglas-Rachford iterations;,citation_author=undefined Deledalle;,citation_author=N. Papadakis;,citation_author=J. Salmon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=SPARS;">
<meta name="citation_reference" content="citation_title=Image restoration with generalized gaussian mixture model patch priors;,citation_author=undefined Deledalle;,citation_author=S. Parameswaran;,citation_author=T. Q. Nguyen;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=arXiv preprint arXiv:1802.01458;">
<meta name="citation_reference" content="citation_title=Image denoising with patch based PCA: Local versus global;,citation_author=undefined Deledalle;,citation_author=J. Salmon;,citation_author=A. S. Dalalyan;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=BMVC;">
<meta name="citation_reference" content="citation_title=Stein Unbiased GrAdient estimator of the Risk (SUGAR) for multiple parameter selection;,citation_author=undefined Deledalle;,citation_author=S. Vaiter;,citation_author=J. Fadili;,citation_author=G. Peyré;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=4;,citation_volume=7;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=A patch-based approach for removing mixed gaussian-impulse noise;,citation_author=J. Delon;,citation_author=A. Desolneux;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_technical_report_institution=Telecom Paristech;">
<meta name="citation_reference" content="citation_title=Independent EEG sources are dipolar;,citation_author=A. Delorme;,citation_author=J. Palmer;,citation_author=J. Onton;,citation_author=R. Oostenveld;,citation_author=S. Makeig;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=7;,citation_journal_title=PloS one;,citation_publisher=Public Library of Science;">
<meta name="citation_reference" content="citation_title=Régression;,citation_author=B. Delyon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_fulltext_html_url=https://perso.univ-rennes1.fr/bernard.delyon/regression.pdf;">
<meta name="citation_reference" content="citation_title=Bilevel programming problems;,citation_author=S. Dempe;,citation_author=V. Kalashnikov;,citation_author=G. A. Pérez-Valdés;,citation_author=N. Kalashnykova;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=Energy Systems. Springer, Berlin;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Maximum likelihood from incomplete data via the EM algorithm;,citation_author=Arthur P Dempster;,citation_author=Nan M Laird;,citation_author=Donald B Rubin;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;,citation_issue=1;,citation_volume=39;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Imagenet: A large-scale hierarchical image database;,citation_author=J. Deng;,citation_author=W. Dong;,citation_author=R. Socher;,citation_author=undefined Li;,citation_author=K. Li;,citation_author=undefined L.;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Image-to-markup generation with coarse-to-fine attention;,citation_author=Y. Deng;,citation_author=A. Kanervisto;,citation_author=J. Ling;,citation_author=A. M. Rush;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_volume=70;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Support recovery for sparse deconvolution of positive measures;,citation_author=Q. Denoyelle;,citation_author=V. Duval;,citation_author=G. Peyré;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=J. Fourier Anal. Appl.;">
<meta name="citation_reference" content="citation_title=Constructive approximation;,citation_author=R. A. DeVore;,citation_author=G. G. Lorentz;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;">
<meta name="citation_reference" content="citation_title=A probabilistic theory of pattern recognition;,citation_author=L. Devroye;,citation_author=L. Györfi;,citation_author=G. Lugosi;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=31;,citation_series_title=Applications of mathematics (new york);">
<meta name="citation_reference" content="citation_title=High-dimensional inference: Confidence intervals, $p$-values and r-software hdi;,citation_author=R. Dezeure;,citation_author=P. Bühlmann;,citation_author=L. Meier;,citation_author=N. Meinshausen;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=30;,citation_journal_title=Statist. Sci.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Gossip algorithms for distributed signal processing;,citation_author=A. G. Dimakis;,citation_author=S. Kar;,citation_author=J. M. F. Moura;,citation_author=M. G. Rabbat;,citation_author=A. Scaglione;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=11;,citation_volume=98;,citation_journal_title=Proceedings of the IEEE;">
<meta name="citation_reference" content="citation_title=Geographic Gossip: Efficient Averaging for Sensor Networks;,citation_author=A. G. Dimakis;,citation_author=A. D. Sarwate;,citation_author=M. J. Wainwright;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=56;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=A compressed PCA subspace method for anomaly detection in high-dimensional data;,citation_author=Q. Ding;,citation_author=E. D. Kolaczyk;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_journal_title=Arxiv preprint arXiv:1109.4408;">
<meta name="citation_reference" content="citation_title=Class-conditional conformal prediction with many classes;,citation_author=T. Ding;,citation_author=A. Angelopoulos;,citation_author=S. Bates;,citation_author=M. I. Jordan;,citation_author=R. J. Tibshirani;,citation_editor=Alice Oh;,citation_editor=Tristan Naumann;,citation_editor=Amir Globerson;,citation_editor=Kate Saenko;,citation_editor=Moritz Hardt;,citation_editor=Sergey Levine;,citation_publication_date=2023;,citation_cover_date=2023;,citation_year=2023;,citation_conference_title=NeurIPS;">
<meta name="citation_reference" content="citation_title=Generic methods for optimization-based modeling;,citation_author=J. Domke;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=22;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Breakdown properties of multivariate location estimators;,citation_author=D. L. Donoho;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_dissertation_institution=Harvard University;">
<meta name="citation_reference" content="citation_title=Stable recovery of sparse overcomplete representations in the presence of noise;,citation_author=D. L. Donoho;,citation_author=M. Elad;,citation_author=V. Temlyakov;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Breakdown properties of location estimates based on halfspace depth and projected outlyingness;,citation_author=D. L. Donoho;,citation_author=M. Gasko;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=4;,citation_volume=20;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=The notion of breakdown point;,citation_author=D. L. Donoho;,citation_author=P. J. Huber;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_inbook_title=A Festschrift for Erich L. Lehmann;,citation_series_title=Wadsworth statist./probab. ser.;">
<meta name="citation_reference" content="citation_title=Maximum entropy and the nearly black object;,citation_author=D. L. Donoho;,citation_author=I. M. Johnstone;,citation_author=J. C. Hoch;,citation_author=A. S. Stern;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1;,citation_volume=54;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Wavelet shrinkage: asymptopia?;,citation_author=D. L. Donoho;,citation_author=I. M. Johnstone;,citation_author=G. Kerkyacharian;,citation_author=D. Picard;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=2;,citation_volume=57;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Ideal spatial adaptation by wavelet shrinkage;,citation_author=D. L. Donoho;,citation_author=I. M. Johnstone;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=3;,citation_volume=81;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Adapting to unknown smoothness via wavelet shrinkage;,citation_author=D. L. Donoho;,citation_author=I. M. Johnstone;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=432;,citation_volume=90;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Minimax risk over hyperrectangles, and implications;,citation_author=D. L. Donoho;,citation_author=R. C. Liu;,citation_author=B. MacGibbon;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=3;,citation_volume=18;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Message-passing algorithms for compressed sensing;,citation_author=D. L. Donoho;,citation_author=A. Maleki;,citation_author=A. Montanari;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=45;,citation_volume=106;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=National Acad Sciences;">
<meta name="citation_reference" content="citation_title=Compressed sensing;,citation_author=D. L. Donoho;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=4;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Asymptotic evaluation of certain Markov process expectations for large time. III;,citation_author=M. D. Donsker;,citation_author=S. R. S. Varadhan;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=4;,citation_volume=29;,citation_journal_title=Comm. Pure Appl. Math.;">
<meta name="citation_reference" content="citation_title=Robust NL-Means Filter With Optimal Pixel-Wise Smoothing Parameter for Statistical Image Denoising;,citation_author=V. Doré;,citation_author=M. Cheriet;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=57;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=On the numerical solution of heat conduction problems in two and three space variables;,citation_author=J. Douglas;,citation_author=H. H. Rachford;,citation_publication_date=1956;,citation_cover_date=1956;,citation_year=1956;,citation_issue=2;,citation_volume=82;,citation_journal_title=Transactions of the American mathematical Society;">
<meta name="citation_reference" content="citation_title=Applied regression analysis;,citation_author=N. R. Draper;,citation_author=H. Smith;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_series_title=Wiley series in probability and statistics: Texts and references section;">
<meta name="citation_reference" content="citation_title=On the Nyström method for approximating a Gram matrix for improved kernel-based learning;,citation_author=P. Drineas;,citation_author=M. W. Mahoney;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=6;,citation_journal_title=J. Mach. Learn. Res.;,citation_publisher=JMLR. org;">
<meta name="citation_reference" content="citation_title=Concentration of measure for the analysis of randomized algorithms;,citation_author=D. Dubhashi;,citation_author=A. Panconesi;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=16;">
<meta name="citation_reference" content="citation_title=Dual averaging for distributed optimization: Convergence analysis and network scaling;,citation_author=J. C. Duchi;,citation_author=A. Agarwal;,citation_author=M. J. Wainwright;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=57;,citation_journal_title=IEEE Trans. Automat. Control;">
<meta name="citation_reference" content="citation_title=Efficient projections onto the $\ell_1$-ball for learning in high dimensions;,citation_author=J. Duchi;,citation_author=S. Shalev-Shwartz;,citation_author=Y. Singer;,citation_author=T. Chandra;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICML;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Composite objective mirror descent;,citation_author=J. Duchi;,citation_author=S. Shalev-Shwartz;,citation_author=Y. Singer;,citation_author=A. Tewari;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Pattern classification;,citation_author=R O. Duda;,citation_author=P. E. Hart;,citation_author=D. G. Stork;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Lifted coordinate descent for learning with trace-norm regularization;,citation_author=M. Dudík;,citation_author=Z. Harchaoui;,citation_author=J. Malick;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Algorithmes stochastiques;,citation_author=M. Duflo;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=23;,citation_series_title=Mathématiques &amp;amp;amp; applications (berlin) [mathematics &amp; applications];">
<meta name="citation_reference" content="citation_title=Random iterative models;,citation_author=M. Duflo;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_volume=34;,citation_series_title=Applications of mathematics (new york);">
<meta name="citation_reference" content="citation_title=Positive trigonometric polynomials and signal processing applications;,citation_author=B. A. Dumitrescu;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Primal-dual rates and certificates;,citation_author=C. Dünner;,citation_author=S. Forte;,citation_author=M. Takáč;,citation_author=M. Jaggi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=48;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=A bias-variance approach for the nonlocal means;,citation_author=V. Duval;,citation_author=undefined Aujol;,citation_author=Y. Gousseau;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=4;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Exact support recovery for sparse spikes deconvolution;,citation_author=V. Duval;,citation_author=G. Peyré;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=Found. Comput. Math.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Sparse spikes deconvolution on thin grids;,citation_author=V. Duval;,citation_author=G. Peyré;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=The non degenerate source condition: Support robustness for discrete and continuous sparse deconvolution;,citation_author=V. Duval;,citation_author=G. Peyré;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=CAMSAP;">
<meta name="citation_reference" content="citation_title=The algorithmic foundations of differential privacy;,citation_author=C. Dwork;,citation_author=A. Roth;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3–4;,citation_volume=9;,citation_journal_title=Foundations and Trends in Theoretical Computer Science;,citation_publisher=Now publishers, Inc.;">
<meta name="citation_reference" content="citation_title=Exact computation of the halfspace depth;,citation_author=R. Dyckerhoff;,citation_author=P. Mozharovskyi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=98;,citation_journal_title=Computational Statistics &amp;amp;amp; Data Analysis;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=An algorithm for restricted least squares regression;,citation_author=R. L. Dykstra;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=384;,citation_volume=78;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Inverse problems and self-similarity in imaging;,citation_author=M. Ebrahimi;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_dissertation_institution=University of Waterloo;">
<meta name="citation_reference" content="citation_title=A self-training algorithm for nonparametric filtering;,citation_author=S. Y. Efromovich;,citation_author=M. S. Pinsker;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=11;,citation_volume=1;,citation_journal_title=Avtomat. i Telemekh.;">
<meta name="citation_reference" content="citation_title=Sharp-optimal and adaptive estimation for heteroscedastic nonparametric regression;,citation_author=S. Y. Efromovich;,citation_author=M. S. Pinsker;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=4;,citation_volume=6;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=On nonparametric regression for IID observations in a general setting;,citation_author=S. Y. Efromovich;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=3;,citation_volume=24;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Nonparametric curve estimation;,citation_author=S. Efromovich;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Least angle regression;,citation_author=B. Efron;,citation_author=T. J. Hastie;,citation_author=I. M. Johnstone;,citation_author=R. Tibshirani;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=2;,citation_volume=32;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Discussion: “The Dantzig selector: Statistical estimation when $p$ is much larger than $n$” [Ann. Statist. &amp;amp;amp;lt;b&amp;gt;35&amp;lt;/b&amp;gt; (2007), no. 6, 2313–2351; MR2382644] by E. Candès and T. Tao;,citation_author=B. Efron;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=6;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=An introduction to the bootstrap;,citation_author=B. Efron;,citation_author=R. Tibshirani;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=Bootstrap methods: Another look at the Jackknife;,citation_author=B. Efron;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=1;,citation_volume=7;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Texture synthesis by non-parametric sampling;,citation_author=A. A. Efros;,citation_author=T. K. Leung;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=ICCV;">
<meta name="citation_reference" content="citation_title=Multiple regression analysis;,citation_author=M. A. Efroymson;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_inbook_title=Mathematical methods for digital computers;">
<meta name="citation_reference" content="citation_title=Local transform-based image denoising with adaptive window-size selection;,citation_author=K. O. Egiazarian;,citation_author=V. Katkovnik;,citation_author=J. T. Astola;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=4170;,citation_conference_title=SPIE;">
<meta name="citation_reference" content="citation_title=Convex analysis and variational problems;,citation_author=I. Ekeland;,citation_author=R. Temam;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;">
<meta name="citation_reference" content="citation_title=Image denoising via sparse and redundant representations over learned dictionaries;,citation_author=M. Elad;,citation_author=M. Aharon;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=12;,citation_volume=15;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Analysis versus synthesis in signal priors;,citation_author=M. Elad;,citation_author=P. Milanfar;,citation_author=R. Rubinstein;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=3;,citation_volume=23;,citation_journal_title=Inverse problems;,citation_publisher=IOP Publishing;">
<meta name="citation_reference" content="citation_title=On the origin of the bilateral filter and ways to improve it;,citation_author=M. Elad;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=10;,citation_volume=11;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Sparse and redundant representations. From theory to applications in signal and image processing.;,citation_author=M. Elad;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Safe feature elimination in sparse supervised learning;,citation_author=L. El Ghaoui;,citation_author=V. Viallon;,citation_author=T. Rabbani;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=8;,citation_journal_title=J. Pacific Optim.;">
<meta name="citation_reference" content="citation_title=Automated model selection in covariance estimation and spatial whitening of MEG and EEG signals;,citation_author=D. A. Engemann;,citation_author=A. Gramfort;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=108;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=Regularization of inverse problems;,citation_author=H. W. Engl;,citation_author=M. Hanke;,citation_author=A. Neubauer;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=375;,citation_series_title=Mathematics and its applications;">
<meta name="citation_reference" content="citation_title=Autoregressive conditional heteroscedasticity with estimates of the variance of united kingdom inflation;,citation_author=R. Engle;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=4;,citation_volume=50;,citation_journal_title=Econometrica;">
<meta name="citation_reference" content="citation_title=Stable recovery with analysis decomposable priors;,citation_author=J. Fadili;,citation_author=G. Peyré;,citation_author=S. Vaiter;,citation_author=undefined Deledalle;,citation_author=J. Salmon;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=SPARS;">
<meta name="citation_reference" content="citation_title=Stable recovery with analysis decomposable priors;,citation_author=J. Fadili;,citation_author=G. Peyré;,citation_author=S. Vaiter;,citation_author=undefined Deledalle;,citation_author=J. Salmon;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=SampTA;">
<meta name="citation_reference" content="citation_title=LIBLINEAR: A library for large linear classification;,citation_author=undefined Fan;,citation_author=undefined Chang;,citation_author=undefined Hsieh;,citation_author=undefined Wang;,citation_author=undefined Lin;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Local polynomial modelling and its applications;,citation_author=J. Fan;,citation_author=I. Gijbels;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=66;,citation_series_title=Monographs on statistics and applied probability;">
<meta name="citation_reference" content="citation_title=Approximate $\ell_{0}$-penalized estimation of piecewise-constant signals on graphs;,citation_author=Z. Fan;,citation_author=L. Guan;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=6B;,citation_volume=46;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Variable selection via nonconcave penalized likelihood and its oracle properties;,citation_author=J. Fan;,citation_author=R. Li;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=456;,citation_volume=96;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Sure independence screening for ultrahigh dimensional feature space;,citation_author=J. Fan;,citation_author=J. Lv;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=5;,citation_volume=70;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Matrix rank minimization with applications;,citation_author=M. Fazel;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=A coordinate descent primal-dual algorithm with large step size and possibly non-separable functions;,citation_author=O. Fercoq;,citation_author=P. Bianchi;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=29 (1);,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Mind the duality gap: Safer rules for the lasso;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=37;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Accelerated, parallel and proximal coordinate descent;,citation_author=O. Fercoq;,citation_author=P. Richtárik;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Accelerated, parallel and proximal coordinate descent;,citation_author=O. Fercoq;,citation_author=P. Richtárik;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=3;,citation_volume=25;,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Support detection in super-resolution;,citation_author=C. Fernandez-Granda;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=SampTA;">
<meta name="citation_reference" content="citation_title=Super-resolution of point sources via convex programming;,citation_author=C. Fernandez-Granda;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=3;,citation_volume=5;,citation_journal_title=Inf. Inference;">
<meta name="citation_reference" content="citation_title=Nonnegative matrix factorization with the Itakura-Saito divergence. With application to music analysis;,citation_author=C. Févotte;,citation_author=N. Bertin;,citation_author=J-L. Durrieu;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=21;,citation_journal_title=Neural Computation;">
<meta name="citation_reference" content="citation_title=Restoration of poissonian images using alternating direction optimization;,citation_author=M. A. T. Figueiredo;,citation_author=J. M. Bioucas-Dias;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=12;,citation_volume=19;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Adaptive sparseness using Jeffreys prior;,citation_author=M. Figueiredo;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=The limiting distribution of a function of two independent random variables and its statistical application;,citation_author=M. Fisz;,citation_publication_date=1955;,citation_cover_date=1955;,citation_year=1955;,citation_volume=3;,citation_journal_title=Colloquium Mathematicum;">
<meta name="citation_reference" content="citation_title=Calcul des probabilités: Cours et exercices corrigés;,citation_author=D. Foata;,citation_author=A. Fuchs;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Anisotropic nonparametric image processing: Theory, algorithms and applications;,citation_author=A. Foi;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=Politecnico di Milano;">
<meta name="citation_reference" content="citation_title=A novel anisotropic local polynomial estimator based on derectional multiscale optimizations;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Proceedings of the sixth IMA international conference on mathematics in signal processing;">
<meta name="citation_reference" content="citation_title=Pointwise shape-adaptive DCT for high-quality denoising and deblocking of grayscale and color images;,citation_author=A. Foi;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=5;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=An invitation to compressive sensing;,citation_author=S. Foucart;,citation_author=H. Rauhut;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Learning with the weighted trace-norm under arbitrary sampling distributions.;,citation_author=R. Foygel;,citation_author=R. Salakhutdinov;,citation_author=O. Shamir;,citation_author=N. Srebro;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Forward and reverse gradient-based hyperparameter optimization;,citation_author=L. Franceschi;,citation_author=M. Donini;,citation_author=P. Frasconi;,citation_author=M. Pontil;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Bilevel programming for hyperparameter optimization and meta-learning;,citation_author=L. Franceschi;,citation_author=P. Frasconi;,citation_author=S. Salzo;,citation_author=M. Pontil;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=A decision-theoretic generalization of on-line learning and an application to boosting;,citation_author=Y. Freund;,citation_author=R. E. Schapire;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=55;,citation_journal_title=Journal of computer and system sciences;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Boosting a weak learning algorithm by majority;,citation_author=Y. Freund;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Pathwise coordinate optimization;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=H. Höfling;,citation_author=R. Tibshirani;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=1;,citation_journal_title=Ann. Appl. Stat.;">
<meta name="citation_reference" content="citation_title=Additive logistic regression: A statistical view of boosting;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=Robert R. Tibshirani;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=2;,citation_volume=28;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Sparse inverse covariance estimation with the graphical lasso;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=9;,citation_journal_title=Biostatistics;,citation_publisher=Biometrika Trust;">
<meta name="citation_reference" content="citation_title=Regularization paths for generalized linear models via coordinate descent;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=33;,citation_journal_title=J. Stat. Softw.;,citation_publisher=NIH Public Access;">
<meta name="citation_reference" content="citation_title=Greedy function approximation: A gradient boosting machine;,citation_author=J. Friedman;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=29;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Poisson intensity estimation using wavelets and the Fisz transformation;,citation_author=P. Fryźlewicz;,citation_author=G. P. Nason;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_technical_report_institution=Department of Mathematics, University of Bristol, United Kingdom;">
<meta name="citation_reference" content="citation_title=A Haar-Fisz algorithm for Poisson intensity estimation;,citation_author=P. Fryźlewicz;,citation_author=G. P. Nason;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=3;,citation_volume=13;,citation_journal_title=J. Comput. Graph. Statist.;,citation_publisher=ASA;">
<meta name="citation_reference" content="citation_title=Penalized regressions: The bridge versus the lasso;,citation_author=W. J. Fu;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=3;,citation_volume=7;,citation_journal_title=J. Comput. Graph. Statist.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=On sparse representations in arbitrary redundant bases;,citation_author=Jean-Jacques Fuchs;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=6;,citation_volume=50;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Recovery of exact sparse representations in the presence of bounded noise;,citation_author=Jean-Jacques Fuchs;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=10;,citation_volume=51;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Spread representations;,citation_author=Jean-Jacques Fuchs;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ASILOMAR;">
<meta name="citation_reference" content="citation_title=The estimation of the gradient of a density function, with applications in pattern recognition;,citation_author=K. Fukunaga;,citation_author=L. Hostetler;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_issue=1;,citation_volume=21;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=High dimensional matrix estimation with unknown variance of the noise.;,citation_author=S. Gaïffas;,citation_author=O. Klopp;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=27;,citation_journal_title=Stat. Sin.;">
<meta name="citation_reference" content="citation_title=Hyper-sparse optimal aggregation;,citation_author=S. Gaïffas;,citation_author=G. Lecué;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Fundamentals of linear algebra and optimization;,citation_author=J. Gallier;,citation_author=J. Quaintance;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_fulltext_html_url=https://www.seas.upenn.edu/~cis515/linalg.pdf;">
<meta name="citation_reference" content="citation_title=Sharp non-asymptotic oracle inequalities for non-parametric heteroscedastic regression models;,citation_author=L. Galtchouk;,citation_author=S. Pergamenshchikov;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=21;,citation_journal_title=J. Nonparametr. Stat.;">
<meta name="citation_reference" content="citation_title=WaveShrink with firm shrinkage;,citation_author=undefined Gao;,citation_author=A. G. Bruce;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Simplification and hierarchical representations of mixtures of exponential families;,citation_author=V. Garcia;,citation_author=F. Nielsen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=12;,citation_volume=90;,citation_journal_title=Signal Processing;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Pl@ntNet-300K: A plant image dataset with high label ambiguity and a long-tailed distribution;,citation_author=C. Garcin;,citation_author=A. Joly;,citation_author=P. Bonnet;,citation_author=A. Affouard;,citation_author=undefined Lombardo;,citation_author=M. Chouet;,citation_author=M. Servajean;,citation_author=J. Salmon;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_conference_title=NeurIPS datasets and benchmarks 2021;">
<meta name="citation_reference" content="citation_title=Stochastic smoothing of the top-k calibrated hinge loss for deep imbalanced classification;,citation_author=C. Garcin;,citation_author=M. Servajean;,citation_author=A. Joly;,citation_author=J. Salmon;,citation_publication_date=2022;,citation_cover_date=2022;,citation_year=2022;,citation_volume=162;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Loss functions for set-valued classification;,citation_author=Camille Garcin;,citation_publication_date=2023-09;,citation_cover_date=2023-09;,citation_year=2023;,citation_fulltext_html_url=https://theses.hal.science/tel-04534631;,citation_dissertation_institution=Université de Montpellier;">
<meta name="citation_reference" content="citation_title=Merging uncertainty sets via majority vote;,citation_author=M. Gasparin;,citation_author=A. Ramdas;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://arxiv.org/abs/2401.09379;">
<meta name="citation_reference" content="citation_title=Fourier analysis and applications;,citation_author=C. Gasquet;,citation_author=P. Witomski;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=30;,citation_series_title=Texts in applied mathematics;">
<meta name="citation_reference" content="citation_title=Recovering sparse signals with non-convex penalties and DC programming;,citation_author=G. Gasso;,citation_author=A. Rakotomamonjy;,citation_author=S. Canu;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=12;,citation_volume=57;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Theoria motus corporum coelestium in sectionibus conicis solem ambientium;,citation_author=C. F. Gauss;,citation_publication_date=1809;,citation_cover_date=1809;,citation_year=1809;,citation_volume=7;">
<meta name="citation_reference" content="citation_title=On inverses of Vandermonde and confluent Vandermonde matrices;,citation_author=W. Gautschi;,citation_publication_date=1962;,citation_cover_date=1962;,citation_year=1962;,citation_volume=4;,citation_journal_title=Numerische Mathematik;,citation_publisher=Springer Berlin / Heidelberg;">
<meta name="citation_reference" content="citation_title=Optimal mini-batch and step sizes for SAGA;,citation_author=N. Gazagnadou;,citation_author=R. Gower;,citation_author=J. Salmon;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Transductive conformal inference with adaptive scores;,citation_author=U. Gazin;,citation_author=G. Blanchard;,citation_author=E. Roquain;,citation_editor=Sanjoy Dasgupta;,citation_editor=Stephan Mandt;,citation_editor=Yingzhen Li;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://proceedings.mlr.press/v238/gazin24a.html;,citation_volume=238;,citation_conference_title=AISTATS;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Minimax multiple shrinkage estimation;,citation_author=E. I. George;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=1;,citation_volume=14;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Combining minimax shrinkage estimators;,citation_author=E. I. George;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=394;,citation_volume=81;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Sparsity regret bounds for individual sequences in online linear regression;,citation_author=S. Gerchinovitz;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=19;,citation_journal_title=Journal of Machine Learning Research - Proceedings Track;">
<meta name="citation_reference" content="citation_title=Hands-on machine learning with Scikit-Learn and TensorFlow: Concepts, tools, and techniques to build intelligent systems;,citation_author=A. Géron;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Machine learning avec Scikit-Learn - Mise en oeuvre et cas concrets;,citation_author=A. Géron;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Approximating parameterized convex optimization problems;,citation_author=J. Giesen;,citation_author=M. Jaggi;,citation_author=S. Laue;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=European symposium on algorithms;">
<meta name="citation_reference" content="citation_title=Approximating concavely parameterized optimization problems;,citation_author=J. Giesen;,citation_author=J. K. Müller;,citation_author=S. Laue;,citation_author=S. Swiercy;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Robust and efficient kernel hyperparameter paths with guarantees;,citation_author=J. Giesen;,citation_author=S. Laue;,citation_author=P. Wieschollek;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Nonlocal linear image regularization and supervised segmentation;,citation_author=G. Gilboa;,citation_author=S. Osher;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=6;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=Nonlocal operators with applications to image processing;,citation_author=G. Gilboa;,citation_author=S. Osher;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=7;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=A total variation spectral framework for scale and texture analysis;,citation_author=G. Gilboa;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=4;,citation_volume=7;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Statistical modelling with quantile functions;,citation_author=W. Gilchrist;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;">
<meta name="citation_reference" content="citation_title=Regression revisited;,citation_author=W. Gilchrist;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=76;,citation_journal_title=International Statistical Review / Revue Internationale de Statistique;,citation_publisher=[Wiley, International Statistical Institute (ISI)];">
<meta name="citation_reference" content="citation_title=Discovering conditionally salient features with statistical guarantees;,citation_author=J. R. Gimenez;,citation_author=J. Zou;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=High-dimensional regression with unknown variance;,citation_author=C. Giraud;,citation_author=S. Huet;,citation_author=N. Verzelen;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=27;,citation_journal_title=Statist. Sci.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Mixing least-squares estimators when the variance is unknown;,citation_author=C. Giraud;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=14;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Introduction to high-dimensional statistics;,citation_author=C. Giraud;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=138;">
<meta name="citation_reference" content="citation_title=Deep sparse rectifier neural networks;,citation_author=X. Glorot;,citation_author=A. Bordes;,citation_author=Y. Bengio;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Universal pointwise selection rule in multivariate function estimation;,citation_author=A. Goldenshluger;,citation_author=O. V. Lepski;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=4;,citation_volume=14;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Structural adaptation via $L_p$-norm oracle inequalities;,citation_author=A. Goldenshluger;,citation_author=O. V. Lepski;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1-2;,citation_volume=143;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=Bandwidth selection in kernel density estimation: Oracle inequalities and adaptive minimax optimality;,citation_author=A. Goldenshluger;,citation_author=O. V. Lepski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=39;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On spatially adaptive estimation of nonparametric regression;,citation_author=A. Goldenshluger;,citation_author=A. S. Nemirovski;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=2;,citation_volume=6;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=A family of variable-metric methods derived by variational means;,citation_author=D. Goldfarb;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=109;,citation_volume=24;,citation_journal_title=Mathematics of computation;">
<meta name="citation_reference" content="citation_title=The split Bregman method for L1-regularized problems;,citation_author=T. Goldstein;,citation_author=S. Osher;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=2;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Molecular classification of cancer: class discovery and class prediction by gene expression monitoring.;,citation_author=T. R. Golub;,citation_author=D. K. Slonim;,citation_author=P. Tamayo;,citation_author=C. Huard;,citation_author=M. Gaasenbeek;,citation_author=J. P. Mesirov;,citation_author=H. Coller;,citation_author=M. L. Loh;,citation_author=J. R. Downing;,citation_author=M. A. Caligiuri;,citation_author=C. D. Bloomfield;,citation_author=E. S. Lander;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=5439;,citation_volume=286;,citation_journal_title=Science;">
<meta name="citation_reference" content="citation_title=Matrix computations;,citation_author=G. H. Golub;,citation_author=C. F. Loan;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;">
<meta name="citation_reference" content="citation_title=Matrix computations;,citation_author=G. H. Golub;,citation_author=C. F. Loan;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=On universal oracle inequalities related to high-dimensional linear models;,citation_author=Y. Golubev;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=5;,citation_volume=38;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Nonparametric estimation of smooth densities of a distribution in $L\_2$;,citation_author=G. K. Golubev;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1;,citation_volume=28;,citation_journal_title=Problemy Peredachi Informatsii;">
<meta name="citation_reference" content="citation_title=Digital image processing using MATLAB;,citation_author=R. C. Gonzalez;,citation_author=R. E. Woods;,citation_author=S. L. Eddins;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;">
<meta name="citation_reference" content="citation_title=Deep learning;,citation_author=I. Goodfellow;,citation_author=Y. Bengio;,citation_author=A. Courville;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=An improved non-local denoising algorithm;,citation_author=B. Goossens;,citation_author=H. Q. Luong;,citation_author=A. Pizurica;,citation_author=W. Philips;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=LNLA;">
<meta name="citation_reference" content="citation_title=Generalized$^{\mbox{2}}$ linear$^{\mbox{2}}$ models;,citation_author=G. J. Gordon;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Sparse signal reconstruction from limited data using FOCUSS: A re-weighted minimum norm algorithm;,citation_author=I. F. Gorodnitsky;,citation_author=B. D. Rao;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=3;,citation_volume=45;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Les maths en tête : analyse;,citation_author=X. Gourdon;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Les maths en tête : Algèbre;,citation_author=X. Gourdon;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Mixed-norm estimates for the M/EEG inverse problem using accelerated gradient methods;,citation_author=A. Gramfort;,citation_author=M. Kowalski;,citation_author=M. Hämäläinen;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=7;,citation_volume=57;,citation_journal_title=Phys. Med. Biol.;,citation_publisher=IOP Science;">
<meta name="citation_reference" content="citation_title=Time-frequency mixed-norm estimates: Sparse M/EEG imaging with non-stationary source activations;,citation_author=A. Gramfort;,citation_author=D. Strohmeier;,citation_author=J. Haueisen;,citation_author=M. S. Hämäläinen;,citation_author=M. Kowalski;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=70;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=Least absolute shrinkage is equivalent to quadratic penalization;,citation_author=Y. Grandvalet;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=International conference on artificial neural networks;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Graph implementations for nonsmooth convex programs;,citation_author=M. Grant;,citation_author=S. Boyd;,citation_editor=V. Blondel;,citation_editor=S. Boyd;,citation_editor=H. Kimura;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=Recent advances in learning and control;,citation_series_title=Lecture notes in control and information sciences;">
<meta name="citation_reference" content="citation_title=CVX: Matlab software for disciplined convex programming, version 2.1;,citation_author=M. Grant;,citation_author=S. Boyd;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=The residual method for regularizing ill-posed problems;,citation_author=M. Grasmair;,citation_author=M. Haltmeier;,citation_author=O. Scherzer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=6;,citation_volume=218;,citation_journal_title=Applied Mathematics and Computation;">
<meta name="citation_reference" content="citation_title=Necessary and sufficient conditions for linear convergence of $\ell_1$-regularization;,citation_author=M. Grasmair;,citation_author=O. Scherzer;,citation_author=M. Haltmeier;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=64;,citation_journal_title=Communications on Pure and Applied Mathematics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Generalized Bregman distances and convergence rates for non-convex regularization methods;,citation_author=M. Grasmair;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=11;,citation_volume=26;,citation_journal_title=Inverse Problems;">
<meta name="citation_reference" content="citation_title=Linear convergence rates for Tikhonov regularization with positively homogeneous functionals;,citation_author=M. Grasmair;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=27;,citation_journal_title=Inverse Problems;,citation_publisher=IOP Publishing;">
<meta name="citation_reference" content="citation_title=Nonparametric regression and generalized linear models;,citation_author=P. J. Green;,citation_author=B. W. Silverman;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_volume=58;,citation_series_title=Monographs on statistics and applied probability;">
<meta name="citation_reference" content="citation_title=Learning fast approximations of sparse coding;,citation_author=K. Gregor;,citation_author=Y. LeCun;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=A collection of matrices for testing computational algorithms;,citation_author=R. T. Gregory;,citation_author=D. L. Karney;,citation_publication_date=1969;,citation_cover_date=1969;,citation_year=1969;">
<meta name="citation_reference" content="citation_title=Some direct estimates of the mode;,citation_author=U. Grenander;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=36;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=Probability and random processes;,citation_author=G. R. Grimmett;,citation_author=D. R. Stirzaker;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Asynchronous distributed learning with sparse communications and identification;,citation_author=D. Grishchenko;,citation_author=F. Iutzeler;,citation_author=J. Malick;,citation_author=undefined Amini;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=arXiv preprint arXiv:1812.03871;">
<meta name="citation_reference" content="citation_title=Recovering low-rank matrices from few coefficients in any basis;,citation_author=D. Gross;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=57;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Convex polytopes;,citation_author=B. Grünbaum;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=A new generalized error path algorithm for model selection;,citation_author=B. Gu;,citation_author=C. X. Ling;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=PAC-bayesian estimation and prediction in sparse additive models;,citation_author=B. Guedj;,citation_author=P. Alquier;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=7;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Is that you? Metric learning approaches for face identification;,citation_author=M. Guillaumin;,citation_author=J. Verbeek;,citation_author=C. Schmid;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICCV;">
<meta name="citation_reference" content="citation_title=Weighted averaging for denoising with overcomplete dictionaries;,citation_author=O. G. Guleryuz;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=12;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Exponential family matrix completion under structural constraints;,citation_author=S. Gunasekar;,citation_author=P. Ravikumar;,citation_author=J. Ghosh;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Fast iterative kernel principal component analysis;,citation_author=S. Günter;,citation_author=N. N. Schraudolph;,citation_author=S. V. N. Vishwanathan;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=8;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Mandatory critical points of 2D uncertain scalar fields;,citation_author=D. Günther;,citation_author=J. Salmon;,citation_author=J. Tierny;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=33;,citation_conference_title=Computer graphics forum;">
<meta name="citation_reference" content="citation_title=On calibration of modern neural networks;,citation_author=C. Guo;,citation_author=G. Pleiss;,citation_author=Y. Sun;,citation_author=K. Q. Weinberger;,citation_editor=Doina Precup;,citation_editor=Yee Whye Teh;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_fulltext_html_url=http://proceedings.mlr.press/v70/guo17a.html;,citation_volume=70;,citation_conference_title=ICML;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Introduction to computation and programming using python: With application to understanding data;,citation_author=J. V. Guttag;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=A distribution-free theory of nonparametric regression;,citation_author=L. Györfi;,citation_author=M. Kohler;,citation_author=A. Krzyżak;,citation_author=H. Walk;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Strategies for sequential prediction of stationary time series;,citation_author=L. Györfi;,citation_author=G. Lugosi;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=46;,citation_inbook_title=Modeling uncertainty;,citation_series_title=Internat. Ser. Oper. Res. Management sci.;">
<meta name="citation_reference" content="citation_title=Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit;,citation_author=R. H. R. Hahnloser;,citation_author=R. Sarpeshkar;,citation_author=M. A. Mahowald;,citation_author=R. J. Douglas;,citation_author=H. S. Seung;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=6789;,citation_volume=405;,citation_journal_title=Nature;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=Fixed-point continuation for $\ell_1$-minimization: Methodology and convergence;,citation_author=E. Hale;,citation_author=W. Yin;,citation_author=Y. Zhang;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=19;,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions;,citation_author=N. Halko;,citation_author=P. Martinsson;,citation_author=J. A. Tropp;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=53;,citation_journal_title=SIAM Review;">
<meta name="citation_reference" content="citation_title=Stable signal reconstruction via $\ell_1$ minimization in redundant, non-tight frames;,citation_author=M. Haltmeier;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=61;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Alternatives to the k-means algorithm that find better clusterings;,citation_author=G. Hamerly;,citation_author=C. Elkan;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=ICIKM;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Time series analysis;,citation_author=J. D. Hamilton;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=Contributions to the theory of robust estimation;,citation_author=F. R. Hampel;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_dissertation_institution=University of California, Berkeley;">
<meta name="citation_reference" content="citation_title=Robust statistics: The approach based on influence functions;,citation_author=F. R. Hampel;,citation_author=E. M. Ronchetti;,citation_author=P. J. Rousseeuw;,citation_author=W. A. Stahel;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=The meaning and use of the area under a receiver operating characteristic (ROC) curve;,citation_author=J. A. Hanley;,citation_author=B. J. McNeil;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=1;,citation_volume=143;,citation_journal_title=Radiology;">
<meta name="citation_reference" content="citation_title=Interaction screening for ultrahigh-dimensional data;,citation_author=N. Hao;,citation_author=H. H. Zhang;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=507;,citation_volume=109;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Conditional gradient algorithms for machine learning;,citation_author=Z. Harchaoui;,citation_author=A. Juditsky;,citation_author=A. Nemirovski;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=NIPS workshop;">
<meta name="citation_reference" content="citation_title=Conditional gradient algorithms for norm-regularized smooth convex optimization;,citation_author=Z. Harchaoui;,citation_author=A. Juditsky;,citation_author=A. Nemirovski;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=Math. Program.;,citation_publisher=Springer Berlin Heidelberg;">
<meta name="citation_reference" content="citation_title=Multiple change-point estimation with a total variation penalty;,citation_author=Z. Harchaoui;,citation_author=C. Lévy-Leduc;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=492;,citation_volume=105;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Wavelets, approximation, and statistical applications;,citation_author=W. Härdle;,citation_author=G. Kerkyacharian;,citation_author=D. Picard;,citation_author=A. B. Tsybakov;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=129;,citation_series_title=Lecture notes in statistics;">
<meta name="citation_reference" content="citation_title=Applied nonparametric regression;,citation_author=W. Härdle;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_volume=19;,citation_series_title=Econometric society monographs;">
<meta name="citation_reference" content="citation_title=MEG-EEG primer;,citation_author=R. Hari;,citation_author=A. Puce;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=This is SPIRAL-TAP: Sparse Poisson Intensity Reconstruction ALgorithms – Theory and Practice;,citation_author=Z. Harmany;,citation_author=R. Marcia;,citation_author=R. Willett;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=21;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=A brief introduction to mixed effects modelling and multi-model inference in ecology;,citation_author=X. A. Harrison;,citation_author=L. Donaldson;,citation_author=M. E. Correa-Cano;,citation_author=J. Evans;,citation_author=D. N. Fisher;,citation_author=C. E. D. Goodwin;,citation_author=B. S. Robinson;,citation_author=D. J. Hodgson;,citation_author=R. Inger;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=6;,citation_journal_title=PeerJ;,citation_publisher=PeerJ Inc.;">
<meta name="citation_reference" content="citation_title=The Elements of Statistical Learning;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_author=J. Friedman;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Statistical learning with sparsity: The lasso and generalizations;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_author=M. Wainwright;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Generalized additive models;,citation_author=T. J. Hastie;,citation_author=R. J. Tibshirani;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_volume=43;">
<meta name="citation_reference" content="citation_title=Combining sparsity and rotational invariance in EEG/MEG source reconstruction;,citation_author=S. Haufe;,citation_author=V. V. Nikulin;,citation_author=A. Ziehe;,citation_author=undefined Müller;,citation_author=G. Nolte;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=42;,citation_journal_title=NeuroImage;,citation_publisher=Academic Press;">
<meta name="citation_reference" content="citation_title=TIGRESS: Trustful Inference of Gene REgulation using Stability Selection.;,citation_author=undefined Haury;,citation_author=F. Mordelet;,citation_author=P. Vera-Licona;,citation_author=undefined Vert;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=6;,citation_journal_title=BMC systems biology;">
<meta name="citation_reference" content="citation_title=Tight worst-case loss bounds for predicting with expert advice;,citation_author=D. Haussler;,citation_author=J. Kivinen;,citation_author=M. K. Warmuth;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_volume=904;,citation_inbook_title=Computational learning theory (EuroCOLT);,citation_series_title=Lecture notes in comput. sci.;">
<meta name="citation_reference" content="citation_title=Sequential prediction of individual sequences under general loss functions;,citation_author=D. Haussler;,citation_author=J. Kivinen;,citation_author=M. K. Warmuth;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=5;,citation_volume=44;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Quelques questions de sélection de variables autour de l’estimateur LASSO;,citation_author=M. Hebiri;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_dissertation_institution=Université Paris Diderot;">
<meta name="citation_reference" content="citation_title=How correlations influence Lasso prediction;,citation_author=M. Hebiri;,citation_author=J. C. Lederer;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=The smooth-Lasso and other $\ell\_1 + \ell\_2$-regularized methods;,citation_author=M. Hebiri;,citation_author=S. Geer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=5;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Data-efficient image recognition with contrastive predictive coding;,citation_author=Olivier J. Hénaff;,citation_author=Aravind Srinivas;,citation_author=Jeffrey De Fauw;,citation_author=Ali Razavi;,citation_author=Carl Doersch;,citation_author=S. M. Ali Eslami;,citation_author=Aäron Oord;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=119;,citation_conference_title=ICML;,citation_conference=PMLR;,citation_series_title=Proceedings of machine learning research;">
<meta name="citation_reference" content="citation_title=Large margin rank boundaries for ordinal regression;,citation_author=R. Herbrich;,citation_author=T. Graepel;,citation_author=K. Obermayer;,citation_editor=undefined Smola;,citation_editor=undefined Bartlett;,citation_editor=undefined Schoelkopf;,citation_editor=undefined Schuurmans;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_inbook_title=Advances in large margin classifiers;">
<meta name="citation_reference" content="citation_title=Violin plots: A box plot-density trace synergism;,citation_author=J. L. Hintze;,citation_author=R. D. Nelson;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=2;,citation_volume=52;,citation_journal_title=The American Statistician;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Image denoising using total least squares;,citation_author=K. Hirakawa;,citation_author=T. W. Parks;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=9;,citation_volume=15;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Convex analysis and minimization algorithms. I;,citation_author=undefined Hiriart-Urruty;,citation_author=C. Lemaréchal;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_volume=305;">
<meta name="citation_reference" content="citation_title=Convex analysis and minimization algorithms. II;,citation_author=undefined Hiriart-Urruty;,citation_author=C. Lemaréchal;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_volume=306;">
<meta name="citation_reference" content="citation_title=Multiple comparison procedures;,citation_author=Y. Hochberg;,citation_author=A. C. Tamhane;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Long short-term memory;,citation_author=S. Hochreiter;,citation_author=J. Schmidhuber;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=8;,citation_volume=9;,citation_journal_title=Neural computation;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Clusterpath an algorithm for clustering using convex fusion penalties;,citation_author=T. D. Hocking;,citation_author=A. Joulin;,citation_author=F. Bach;,citation_author=undefined Vert;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=The analysis and selection of variables in linear regression;,citation_author=R. R. Hocking;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=1;,citation_volume=32;,citation_journal_title=Biometrics;">
<meta name="citation_reference" content="citation_title=Probability inequalities for sums of bounded random variables;,citation_author=W. Hoeffding;,citation_publication_date=1963;,citation_cover_date=1963;,citation_year=1963;,citation_issue=301;,citation_volume=58;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis Group;">
<meta name="citation_reference" content="citation_title=A path algorithm for the fused lasso signal approximator;,citation_author=H. Hoefling;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=19;,citation_journal_title=J. Comput. Graph. Stat.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Ridge regression: Biased estimation for nonorthogonal problems;,citation_author=A. E. Hoerl;,citation_author=R. W. Kennard;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=1;,citation_volume=12;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Modern statistics for modern biology;,citation_author=S. Holmes;,citation_author=W. Huber;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Deviation bounds for wavelet shrinkage;,citation_author=D. Hong;,citation_author=J-C. Birget;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=7;,citation_volume=49;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Neural networks and physical systems with emergent collective computational abilities;,citation_author=J. J. Hopfield;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=8;,citation_volume=79;,citation_journal_title=Proceedings of the National Academy of Sciences;,citation_publisher=National Acad Sciences;">
<meta name="citation_reference" content="citation_title=Topics in matrix analysis;,citation_author=R. A. Horn;,citation_author=C. R. Johnson;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;">
<meta name="citation_reference" content="citation_title=DC programming: overview;,citation_author=R. Horst;,citation_author=N. V. Thoai;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=103;,citation_journal_title=Journal of Optimization Theory and Applications;">
<meta name="citation_reference" content="citation_title=Independent component analysis in image denoising;,citation_author=P. O. Hoyer;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_dissertation_institution=Helsinki University of Technology;">
<meta name="citation_reference" content="citation_title=Numerical solution of robust regression problems;,citation_author=P. J. Huber;,citation_author=R. Dutter;,citation_publication_date=1974;,citation_cover_date=1974;,citation_year=1974;,citation_conference_title=Compstat 1974 (Proc. Sympos. Computational Statist., Univ. Vienna, Vienna, 1974);,citation_conference=Physica Verlag, Vienna;">
<meta name="citation_reference" content="citation_title=Robust statistics;,citation_author=P. J. Huber;,citation_author=E. M. Ronchetti;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Robust estimation of a location parameter;,citation_author=P. J. Huber;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_volume=35;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=Robust statistics;,citation_author=P. J. Huber;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;">
<meta name="citation_reference" content="citation_title=A natural identity for exponential families with applications in multiparameter estimation;,citation_author=H. M. Hudson;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=3;,citation_volume=6;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Robust non-local denoising of colored depth data;,citation_author=B. Huhle;,citation_author=T. Schairer;,citation_author=P. Jenke;,citation_author=W. Straßer;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=IEEE CVPR workshop on time of flight camera based computer vision (ToF-CV);">
<meta name="citation_reference" content="citation_title=Robust video denoising using low rank matrix completion;,citation_author=J. Hui;,citation_author=L. Chaoqiang;,citation_author=S. Zuowei;,citation_author=X. Yuhong;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=0;,citation_journal_title=CVPR;,citation_publisher=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Beyond manual tuning of hyperparameters;,citation_author=F. Hutter;,citation_author=J. Lücke;,citation_author=L. Schmidt-Thieme;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=29;,citation_journal_title=Künstliche Intell.;">
<meta name="citation_reference" content="citation_title=Optimal rates for total variation denoising;,citation_author=undefined Hütter;,citation_author=P. Rigollet;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Conference on learning theory;">
<meta name="citation_reference" content="citation_title=Sparse code shrinkage: Denoising by nonlinear maximum likelihood estimation;,citation_author=A. Hyvärinen;,citation_author=P. O. Hoyer;,citation_author=E. Oja;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Approximate nearest neighbors: Towards removing the curse of dimensionality;,citation_author=P. Indyk;,citation_author=R. Motwani;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=Proceedings of the thirtieth annual ACM symposium on theory of computing;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Batch normalization: Accelerating deep network training by reducing internal covariate shift;,citation_author=S. Ioffe;,citation_author=C. Szegedy;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=arXiv preprint arXiv:1502.03167;">
<meta name="citation_reference" content="citation_title=Efficiently exploring architectural design spaces via predictive modeling;,citation_author=E. Ïpek;,citation_author=S. A. McKee;,citation_author=R. Caruana;,citation_author=B. R. Supinski;,citation_author=M. Schulz;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=41;">
<meta name="citation_reference" content="citation_title=Asynchronous distributed optimization using a randomized alternating direction method of multipliers;,citation_author=F. Iutzeler;,citation_author=P. Bianchi;,citation_author=P. Ciblat;,citation_author=W. Hachem;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=CDC;">
<meta name="citation_reference" content="citation_title=Group lasso with overlap and graph lasso;,citation_author=L. Jacob;,citation_author=G. Obozinski;,citation_author=undefined Vert;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Revisiting Frank-Wolfe: Projection-free sparse convex optimization;,citation_author=M. Jaggi;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Extreme multi-label loss functions for recommendation, tagging, ranking &amp;amp;amp; other missing label applications;,citation_author=H. Jain;,citation_author=Y. Prabhu;,citation_author=M. Varma;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=KDD;">
<meta name="citation_reference" content="citation_title=Fundamentals of digital image processing;,citation_author=A. K. Jain;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;">
<meta name="citation_reference" content="citation_title=Estimation with quadratic loss;,citation_author=W. James;,citation_author=C. M. Stein;,citation_publication_date=1961;,citation_cover_date=1961;,citation_year=1961;,citation_volume=1;,citation_inbook_title=Proc. 4th Berkeley Sympos. Math. Statist. And Prob.;">
<meta name="citation_reference" content="citation_title=An introduction to statistical learning;,citation_author=G. James;,citation_author=D. Witten;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=103;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=The distribution of the latent roots of the covariance matrix;,citation_author=A. T. James;,citation_publication_date=1960;,citation_cover_date=1960;,citation_year=1960;,citation_issue=1;,citation_volume=31;,citation_journal_title=The Annals of Mathematical Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Non-stochastic best arm identification and hyperparameter optimization;,citation_author=K. Jamieson;,citation_author=A. Talwalkar;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Model selection for high-dimensional regression under the generalized irrepresentability condition;,citation_author=A. Javanmard;,citation_author=A. Montanari;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_technical_report_institution=Stanford;">
<meta name="citation_reference" content="citation_title=Confidence intervals and hypothesis testing for high-dimensional regression;,citation_author=A. Javanmard;,citation_author=A. Montanari;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=15;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Anti-sparse coding for approximate nearest neighbor search;,citation_author=H. Jégou;,citation_author=T. Furon;,citation_author=Jean-Jacques Fuchs;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICASSP;">
<meta name="citation_reference" content="citation_title=Multi-scale mining of fMRI data with hierarchical structured sparsity;,citation_author=R. Jenatton;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=G. Obozinski;,citation_author=F. Bach;,citation_author=B. Thirion;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=Pattern recognition in NeuroImaging (PRNI), 2011 international workshop on;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Proximal methods for hierarchical sparse coding;,citation_author=R. Jenatton;,citation_author=J. Mairal;,citation_author=G. Obozinski;,citation_author=F. Bach;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=A moment-based nonlocal-means algorithm for image denoising;,citation_author=Z. Ji;,citation_author=Q. Chen;,citation_author=Q-S. Sun;,citation_author=D-S. Xia;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=23-24;,citation_volume=109;,citation_journal_title=Information Processing Letters;">
<meta name="citation_reference" content="citation_title=Tensor Completion for Estimating Missing Values in Visual Data;,citation_author=L. Ji;,citation_author=P. Musialski;,citation_author=P. Wonka;,citation_author=undefined J.;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=35;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;,citation_publisher=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Cutting-plane training of structural SVMs;,citation_author=T. Joachims;,citation_author=T. Finley;,citation_author=undefined J. Yu;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=77;,citation_journal_title=Machine Learning;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Optimizing search engines using clickthrough data;,citation_author=T. Joachims;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the eighth ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Text categorization with support vector machines: Learning with many relevant features;,citation_author=T. Joachims;,citation_editor=C. Nédellec;,citation_editor=C. Rouveirol;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=1398;,citation_inbook_title=Machine learning: ECML-98;,citation_series_title=Lecture notes in computer science;">
<meta name="citation_reference" content="citation_title=Making large-scale SVM learning practical;,citation_author=T. Joachims;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_technical_report_institution=Universität Dortmund, LS VIII-Report;,citation_technical_report_number=24;">
<meta name="citation_reference" content="citation_title=A randomized incremental subgradient method for distributed optimization in networked systems;,citation_author=B. Johansson;,citation_author=M. Rabi;,citation_author=M. Johansson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3;,citation_volume=20;,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Blitz: A principled meta-algorithm for scaling sparse optimization;,citation_author=T. B. Johnson;,citation_author=C. Guestrin;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=37;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Unified methods for exploiting piecewise linear structure in convex optimization;,citation_author=T. B. Johnson;,citation_author=C. Guestrin;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=StingyCD: Safely avoiding wasteful updates in coordinate descent;,citation_author=T. B. Johnson;,citation_author=C. Guestrin;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=A fast, principled working set algorithm for exploiting piecewise linear structure in convex problems;,citation_author=T. B. Johnson;,citation_author=C. Guestrin;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=arXiv preprint arXiv:1807.08046;">
<meta name="citation_reference" content="citation_title=Extensions of Lipschitz mappings into a Hilbert space;,citation_author=W. B. Johnson;,citation_author=J. Lindenstrauss;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=189-206;,citation_volume=26;,citation_journal_title=Contemporary mathematics;">
<meta name="citation_reference" content="citation_title=The densest hemisphere problem;,citation_author=D. S. Johnson;,citation_author=F. P. Preparata;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=1;,citation_volume=6;,citation_journal_title=Theoret. Comput. Sci.;">
<meta name="citation_reference" content="citation_title=Oracle inequalities and nonparametric function estimation;,citation_author=I. M. Johnstone;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=Proceedings of the International Congress of Mathematicians, Vol. III (Berlin, 1998);">
<meta name="citation_reference" content="citation_title=Wavelet shrinkage for correlated data and inverse problems: Adaptivity results;,citation_author=I. M. Johnstone;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=9;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Principal component analysis;,citation_author=I. T. Jolliffe;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Robust estimation of heavy-tailed distributions;,citation_author=E. Joly;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_dissertation_institution=Université Paris-Sud;">
<meta name="citation_reference" content="citation_title=Interactive plant identification based on social image data;,citation_author=A. Joly;,citation_author=H. Goëau;,citation_author=P. Bonnet;,citation_author=V. Bakić;,citation_author=J. Barbe;,citation_author=S. Selmi;,citation_author=I. Yahiaoui;,citation_author=J. Carré;,citation_author=E. Mouysset;,citation_author=undefined Molino;,citation_author=N. Boujemaa;,citation_author=D. Barthélémy;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=23;,citation_journal_title=Ecological Informatics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Crowdsourcing biodiversity monitoring: How sharing your photo stream can sustain our planet;,citation_author=A. Joly;,citation_author=H. Goëau;,citation_author=J. Champ;,citation_author=S. Dufour-Kowalski;,citation_author=H. Müller;,citation_author=P. Bonnet;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 24th ACM international conference on multimedia;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Inequality restrictions in regression analysis;,citation_author=G. G. Judge;,citation_author=T. Takayama;,citation_publication_date=1966;,citation_cover_date=1966;,citation_year=1966;,citation_volume=61;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Recursive aggregation of estimators by the mirror descent method with averaging;,citation_author=A. B. Juditsky;,citation_author=A. V. Nazin;,citation_author=A. B. Tsybakov;,citation_author=N. Vayatis;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=4;,citation_volume=41;,citation_journal_title=Problemy Peredachi Informatsii;">
<meta name="citation_reference" content="citation_title=Functional aggregation for nonparametric regression;,citation_author=A. B. Juditsky;,citation_author=A. S. Nemirovski;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=3;,citation_volume=28;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Nonparametric denoising of signals with unknown local structure. I. Oracle inequalities;,citation_author=A. B. Juditsky;,citation_author=A. S. Nemirovski;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=27;,citation_journal_title=Appl. Comput. Harmon. Anal.;">
<meta name="citation_reference" content="citation_title=On verifiable sufficient conditions for sparse signal recovery via $\ell_1$ minimization;,citation_author=A. B. Juditsky;,citation_author=A. S. Nemirovski;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=127;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Learning by mirror averaging;,citation_author=A. B. Juditsky;,citation_author=P. Rigollet;,citation_author=A. B. Tsybakov;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=5;,citation_volume=36;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Lectures on wiener and kalman filtering;,citation_author=T. Kailath;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_inbook_title=Lectures on wiener and kalman filtering;">
<meta name="citation_reference" content="citation_title=Agnostically learning halfspaces;,citation_author=A. Kalai;,citation_author=A. Klivans;,citation_author=Y. Mansour;,citation_author=R. Servedio;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=6;,citation_volume=37;,citation_journal_title=SIAM J. Comput.;">
<meta name="citation_reference" content="citation_title=Efficient Greedy Coordinate Descent for Composite Problems;,citation_author=P. Karimireddy;,citation_author=A. Koloskova;,citation_author=S. Stich;,citation_author=M. Jaggi;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=arXiv preprint arXiv:1810.06999;">
<meta name="citation_reference" content="citation_title=Almost optimal exploration in multi-armed bandits;,citation_author=Z. Karnin;,citation_author=T. Koren;,citation_author=O. Somekh;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Randomized rumor spreading;,citation_author=R. Karp;,citation_author=C. Schindelhauer;,citation_author=S. Shenker;,citation_author=B. Vocking;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=Symposium on foundations of computer science;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Deep visual-semantic alignments for generating image descriptions;,citation_author=A. Karpathy;,citation_author=L. Fei-Fei;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Median filter with varying bandwidth adaptive to unknown smoothness of the signal;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_conference_title=IEEE international symposium on circuits and systems;">
<meta name="citation_reference" content="citation_title=Adaptive window size image de-noising based on intersection of confidence intervals (ICI) rule;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=3;,citation_volume=16;,citation_journal_title=J. Math. Imaging Vis.;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Application of the ICI principle to window size adaptive median filtering;,citation_author=V. Katkovnik;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=2;,citation_volume=83;,citation_journal_title=Signal Processing;">
<meta name="citation_reference" content="citation_title=Directional varying scale approximations for anisotropic signal processing;,citation_author=V. Katkovnik;,citation_author=A. Foi;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=EUSIPCO;">
<meta name="citation_reference" content="citation_title=From local kernel to nonlocal multiple-model image denoising;,citation_author=V. Katkovnik;,citation_author=A. Foi;,citation_author=K. O. Egiazarian;,citation_author=J. T. Astola;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=86;,citation_journal_title=Int. J. Comput. Vision;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Spatially adaptive estimation via fitted local likelihood techniques;,citation_author=V. Katkovnik;,citation_author=V. G. Spokoiny;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=3;,citation_volume=56;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=A new method for varying adaptive bandwidth selection;,citation_author=V. Katkovnik;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=9;,citation_volume=47;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Thompson sampling: An asymptotically optimal finite-time analysis;,citation_author=E. Kaufmann;,citation_author=N. Korda;,citation_author=R. Munos;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=Algorithmic learning theory;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=Toward efficient agnostic learning;,citation_author=M. J. Kearns;,citation_author=R. E. Schapire;,citation_author=L. Sellie;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2-3;,citation_volume=17;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=Gossip-Based Computation of Aggregate Information;,citation_author=D. Kempe;,citation_author=A. Dobra;,citation_author=J. Gehrke;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=Symposium on Foundations of Computer Science;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Bayesian non-local means filter, image redundancy and adaptive dictionaries for noise removal;,citation_author=C. Kervrann;,citation_author=J. Boulanger;,citation_author=P. Coupé;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=4485;,citation_conference_title=SSVM;">
<meta name="citation_reference" content="citation_title=Optimal spatial adaptation for patch-based image denoising;,citation_author=C. Kervrann;,citation_author=J. Boulanger;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=10;,citation_volume=15;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Matrix completion from noisy entries;,citation_author=R. H. Keshavan;,citation_author=A. Montanari;,citation_author=S. Oh;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Robust linear model selection based on least angle regression;,citation_author=J. A. Khan;,citation_author=S. Van Aelst;,citation_author=R. H. Zamar;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=480;,citation_volume=102;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Invariant image recognition by zernike moments;,citation_author=A. Khotanzad;,citation_author=Y. H. Hong;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=5;,citation_volume=12;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;,citation_publisher=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Iterative kernel principal component analysis for image modeling;,citation_author=K. I. Kim;,citation_author=M. O. Franz;,citation_author=B. Schölkopf;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=9;,citation_volume=27;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=$l_1$ trend filtering;,citation_author=undefined Kim;,citation_author=K. Koh;,citation_author=S. Boyd;,citation_author=D. Gorinevsky;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=51;,citation_journal_title=SIAM Rev.;">
<meta name="citation_reference" content="citation_title=An interior-point method for large-scale $\ell_1$-regularized least squares;,citation_author=undefined Kim;,citation_author=K. Koh;,citation_author=M. Lustig;,citation_author=S. Boyd;,citation_author=D. Gorinevsky;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=4;,citation_volume=1;,citation_journal_title=IEEE J. Sel. Topics Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Fast active-set-type algorithms for L1-regularized linear regression.;,citation_author=J. Kim;,citation_author=H. Park;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Deblurring and denoising of images by nonlocal functionals;,citation_author=S. Kindermann;,citation_author=S. Osher;,citation_author=P. W. Jones;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=4;,citation_volume=4;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=Exponentiated gradient versus gradient descent for linear predictors;,citation_author=J. Kivinen;,citation_author=M. K. Warmuth;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=132;,citation_journal_title=Inform. and Comput.;">
<meta name="citation_reference" content="citation_title=Averaging expert predictions;,citation_author=J. Kivinen;,citation_author=M. K. Warmuth;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=1572;,citation_inbook_title=Computational learning theory (EuroCOLT);,citation_series_title=Lecture notes in comput. sci.;">
<meta name="citation_reference" content="citation_title=Empirical risk minimization in inverse problems;,citation_author=J. Klemelä;,citation_author=E. Mammen;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=1;,citation_volume=38;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Adaptive multinomial matrix completion;,citation_author=O. Klopp;,citation_author=J. Lafond;,citation_author=E. Moulines;,citation_author=J. Salmon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=2;,citation_volume=9;,citation_journal_title=Electron. J. Statist.;">
<meta name="citation_reference" content="citation_title=Rank penalized estimators for high-dimensional matrices;,citation_author=O. Klopp;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=5;,citation_journal_title=Electron. J. Stat.;,citation_publisher=The Institute of Mathematical Statistics; the Bernoulli Society;">
<meta name="citation_reference" content="citation_title=Noisy low-rank matrix completion with general sampling distribution;,citation_author=O. Klopp;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=2;,citation_journal_title=Bernoulli;,citation_publisher=Bernoulli Society for Mathematical Statistics; Probability;">
<meta name="citation_reference" content="citation_title=On the adaptive estimation of anisotropic functions;,citation_author=N. Klutchnikoff;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_dissertation_institution=University Aix-Marseille;">
<meta name="citation_reference" content="citation_title=Dual-domain image denoising;,citation_author=C. Knaus;,citation_author=M. Zwicker;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Ordered linear smoothers;,citation_author=Alois Kneip;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=2;,citation_volume=22;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On the asymptotic performance of median smoothers in image analysis and nonparametric regression;,citation_author=I. Koch;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=4;,citation_volume=24;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Regression quantiles;,citation_author=R. Koenker;,citation_author=G. Bassett;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=1;,citation_volume=46;,citation_journal_title=Econometrica;">
<meta name="citation_reference" content="citation_title=Quantile regression;,citation_author=R. Koenker;,citation_author=K. F. Hallock;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=4;,citation_volume=15;,citation_journal_title=J. Econ. Perspect.;">
<meta name="citation_reference" content="citation_title=An interior-point method for large-scale l1-regularized logistic regression.;,citation_author=K. Koh;,citation_author=undefined Kim;,citation_author=S. Boyd;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=8;,citation_volume=8;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Automatic parameter selection by minimizing estimated error;,citation_author=R. Kohavi;,citation_author=G. H. John;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_inbook_title=ICML;">
<meta name="citation_reference" content="citation_title=Multiscale likelihood analysis and complexity penalized estimation;,citation_author=E. D. Kolaczyk;,citation_author=R. D. Nowak;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=2;,citation_volume=32;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Wavelet shrinkage estimation of certain Poisson intensity signals using corrected thresholds;,citation_author=E. D. Kolaczyk;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1;,citation_volume=9;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Variance function estimation in high-dimensions;,citation_author=M. Kolar;,citation_author=J. Sharpnack;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Nuclear-norm penalization and optimal rates for noisy low-rank matrix completion;,citation_author=V. Koltchinskii;,citation_author=K. Lounici;,citation_author=A. B. Tsybakov;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=5;,citation_volume=39;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=$L_1$-penalization in functional linear regression with subgaussian design.;,citation_author=V. Koltchinskii;,citation_author=S. Minsker;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=1;,citation_journal_title=J. Éc. Polytech., Math.;,citation_publisher=Université Paris-Saclay, École Polytechnique, Palaiseau;">
<meta name="citation_reference" content="citation_title=Rademacher penalties and structural risk minimization;,citation_author=V. Koltchinskii;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=5;,citation_volume=47;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Sparse recovery in convex hulls via entropy penalization;,citation_author=V. Koltchinskii;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=37;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Oracle inequalities in empirical risk minimization and sparse recovery problems;,citation_author=V. Koltchinskii;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=2033;,citation_series_title=Lecture notes in mathematics;">
<meta name="citation_reference" content="citation_title=Federated optimization: Distributed machine learning for on-device intelligence;,citation_author=J. Konečný;,citation_author=H. B. McMahan;,citation_author=D. Ramage;,citation_author=P. Richtárik;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=abs/1610.02527;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Matrix factorization techniques for recommender systems;,citation_author=Y. Koren;,citation_author=R. Bell;,citation_author=C. Volinsky;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=8;,citation_volume=42;,citation_journal_title=Computer;,citation_publisher=IEEE Computer Society Press;">
<meta name="citation_reference" content="citation_title=Minimax theory of image reconstruction;,citation_author=A. P. Korostelëv;,citation_author=A. B. Tsybakov;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_volume=82;,citation_series_title=Lecture notes in statistics;">
<meta name="citation_reference" content="citation_title=Eigenvalues and eigenvectors of tridiagonal matrices;,citation_author=S. Kouachi;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_volume=15;,citation_journal_title=Electron. J. Linear Algebra;">
<meta name="citation_reference" content="citation_title=Newscast EM;,citation_author=W. Kowalczyk;,citation_author=N. A. Vlassis;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Accelerating ISTA with an active set strategy;,citation_author=M. Kowalski;,citation_author=P. Weiss;,citation_author=A. Gramfort;,citation_author=S. Anthoine;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=OPT 2011: 4th international workshop on optimization for machine learning;">
<meta name="citation_reference" content="citation_title=Sparse regression using mixed norms;,citation_author=M. Kowalski;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=27;,citation_journal_title=Appl. Comput. Harmon. Anal.;">
<meta name="citation_reference" content="citation_title=Learning multiple layers of features from tiny images;,citation_author=A. Krizhevsky;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_technical_report_institution=Univ. of Toronto;">
<meta name="citation_reference" content="citation_title=Multiscale photon-limited spectral image reconstruction;,citation_author=K. Krishnamurthy;,citation_author=M. Raginsky;,citation_author=R. Willett;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3;,citation_volume=3;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Metric Learning: A Survey;,citation_author=B. Kulis;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=5;,citation_journal_title=Foundations and Trends in Machine Learning;">
<meta name="citation_reference" content="citation_title=A binary classification framework for two-stage multiple kernel learning;,citation_author=A. Kumar;,citation_author=A. Niculescu-Mizil;,citation_author=K. Kavukcuoglu;,citation_author=H. Daume III;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Stochastic approximation and recursive algorithms and applications;,citation_author=H. J. Kushner;,citation_author=G. Yin;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=35;">
<meta name="citation_reference" content="citation_title=Penalized regression, standard errors, and bayesian lassos;,citation_author=M. Kyung;,citation_author=J. Gill;,citation_author=M. Ghosh;,citation_author=G. Casella;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=5;,citation_journal_title=Bayesian Analysis;">
<meta name="citation_reference" content="citation_title=Rodeo: Sparse, greedy nonparametric regression;,citation_author=J. Lafferty;,citation_author=L. Wasserman;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=1;,citation_volume=36;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Complétion de matrice de faible rang: Aspects statistiques et computationnels;,citation_author=J. Lafond;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_dissertation_institution=Télécom ParisTech;">
<meta name="citation_reference" content="citation_title=Probabilistic low-rank matrix completion on finite alphabet;,citation_author=J. Lafond;,citation_author=O. Klopp;,citation_author=E. Moulines;,citation_author=J. Salmon;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Low rank matrix completion with exponential family noise;,citation_author=J. Lafond;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Mondrian forests: Efficient online random forests;,citation_author=B. Lakshminarayanan;,citation_author=D. M. Roy;,citation_author=Y. W. Teh;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Numba: A LLVM-based Python JIT Compiler;,citation_author=S. K. Lam;,citation_author=A. Pitrou;,citation_author=S. Seibert;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the second workshop on the LLVM compiler infrastructure in HPC;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Learning the kernel matrix with semidefinite programming;,citation_author=G. R. G. Lanckriet;,citation_author=N. Cristianini;,citation_author=P. Bartlett;,citation_author=L. El Ghaoui;,citation_author=M. Jordan;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=5;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=MM optimization algorithms;,citation_author=K. Lange;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=PAC-Bayes &amp;amp;amp; margins;,citation_author=J. Langford;,citation_author=J. Shawe-Taylor;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Analysis and optimization of loss functions for multiclass, top-k, and multilabel classification;,citation_author=M. Lapin;,citation_author=M. Hein;,citation_author=B. Schiele;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=7;,citation_volume=40;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Design and regularization of neural networks: The optimal use of a validation set;,citation_author=J. Larsen;,citation_author=L. K. Hansen;,citation_author=C. Svarer;,citation_author=M. Ohlsson;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_conference_title=Neural networks for signal processing VI. Proceedings of the 1996 IEEE signal processing society workshop;">
<meta name="citation_reference" content="citation_title=Matrix analysis for scientists and engineers;,citation_author=A. J. Laub;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=Adaptive estimation of a quadratic functional by model selection;,citation_author=B. Laurent;,citation_author=P. Massart;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=5;,citation_volume=28;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=A nonlocal bayesian image denoising algorithm;,citation_author=M. Lebrun;,citation_author=A. Buades;,citation_author=undefined Morel;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=6;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Secrets of image denoising cuisine;,citation_author=M. Lebrun;,citation_author=M. Colom;,citation_author=A. Buades;,citation_author=undefined Morel;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=21;,citation_journal_title=Acta Numerica;,citation_publisher=Cambridge Univ Press;">
<meta name="citation_reference" content="citation_title=Robust machine learning by median-of-means: Theory and practice;,citation_author=G. Lecué;,citation_author=M. Lerasle;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=arXiv preprint arXiv:1711.10306;">
<meta name="citation_reference" content="citation_title=Aggregation via empirical risk minimization;,citation_author=G. Lecué;,citation_author=S. Mendelson;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3-4;,citation_volume=145;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=On the optimality of the aggregate with exponential weights for low temperatures;,citation_author=G. Lecué;,citation_author=S. Mendelson;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=submitted;">
<meta name="citation_reference" content="citation_title=Optimal rates of aggregation in classification under low noise assumption;,citation_author=G. Lecué;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=4;,citation_volume=13;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Don’t fall for tuning parameters: Tuning-free variable selection in high dimensions with the TREX;,citation_author=J. Lederer;,citation_author=C. L. Müller;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=AAAI;">
<meta name="citation_reference" content="citation_title=Trust, but verify: Benefits and pitfalls of least-squares refitting in high dimensions;,citation_author=J. Lederer;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Don’t fall for tuning parameters: Tuning-free variable selection in high dimensions with the TREX;,citation_author=C. L. Müller;,citation_author=J. Lederer;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=A well-conditioned estimator for large-dimensional covariance matrices;,citation_author=O. Ledoit;,citation_author=M. Wolf;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=2;,citation_volume=88;,citation_journal_title=J. Multivariate Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Probability in Banach spaces;,citation_author=M. Ledoux;,citation_author=M. Talagrand;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_series_title=Classics in mathematics;">
<meta name="citation_reference" content="citation_title=Probability in Banach spaces;,citation_author=M. Ledoux;,citation_author=M. Talagrand;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_volume=23;,citation_series_title=Ergebnisse der mathematik und ihrer grenzgebiete (3) [results in mathematics and related areas (3)];">
<meta name="citation_reference" content="citation_title=The concentration of measure phenomenon;,citation_author=M. Ledoux;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=89;,citation_series_title=Mathematical surveys and monographs;">
<meta name="citation_reference" content="citation_title=Isoperimetry and gaussian analysis;,citation_author=M. Ledoux;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Efficient sparse coding algorithms;,citation_author=H. Lee;,citation_author=A. Battle;,citation_author=R. Raina;,citation_author=A. Y. Ng;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Simultaneous multiple response regression and inverse covariance matrix estimation via penalized Gaussian maximum likelihood;,citation_author=W. Lee;,citation_author=Y. Liu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=111;,citation_journal_title=Journal of multivariate analysis;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Algorithms for non-negative matrix factorization;,citation_author=D. D. Lee;,citation_author=H. S. Seung;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=13;,citation_conference_title=NIPS;,citation_conference=Citeseer;">
<meta name="citation_reference" content="citation_title=Adaptive multi-task lasso: With application to eQTL detection;,citation_author=S. Lee;,citation_author=J. Zhu;,citation_author=E. P. Xing;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Digital image smoothing and the sigma filter;,citation_author=undefined Lee;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=2;,citation_volume=24;,citation_journal_title=Computer Vision, Graphics, and Image Processing;">
<meta name="citation_reference" content="citation_title=U-statistics: Theory and Practice;,citation_author=A. J. Lee;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;">
<meta name="citation_reference" content="citation_title=Itakura-saito nonnegative matrix factorization with group sparsity;,citation_author=A. Lefèvre;,citation_author=F. Bach;,citation_author=C. Févotte;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICASSP;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Bayesian inference on multiscale models for Poisson intensity estimation: Applications to photon-limited image denoising;,citation_author=S. Lefkimmiatis;,citation_author=P. Maragos;,citation_author=G. Papandreou;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=8;,citation_volume=18;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Identify ambiguous tasks combining crowdsourced labels by weighting areas under the margin;,citation_author=T. Lefort;,citation_author=B. Charlier;,citation_author=A. Joly;,citation_author=J. Salmon;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_journal_title=TMLR;">
<meta name="citation_reference" content="citation_title=Peerannot: Classification for crowd-sourced image datasets with python;,citation_author=T. Lefort;,citation_author=B. Charlier;,citation_author=A. Joly;,citation_author=J. Salmon;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://tanglef.github.io/computo_2023/;,citation_journal_title=Computo;">
<meta name="citation_reference" content="citation_title=Cooperative learning of pl@ntNet’s artificial intelligence algorithm: How does it work and how can we improve it?;,citation_author=T. Lefort;,citation_author=A. Affouard;,citation_author=B. Charlier;,citation_author=J.-C. Lombardo;,citation_author=M. Chouet;,citation_author=H. Goëau;,citation_author=J. Salmon;,citation_author=P. Bonnet;,citation_author=A. Joly;,citation_publication_date=2025;,citation_cover_date=2025;,citation_year=2025;,citation_fulltext_html_url=https://arxiv.org/abs/2406.03356;,citation_journal_title=Methods in Ecology and Evolution;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Nouvelles méthodes pour la détermination des orbites des comètes;,citation_author=undefined Legendre;,citation_publication_date=1805;,citation_cover_date=1805;,citation_year=1805;">
<meta name="citation_reference" content="citation_title=Theory of point estimation;,citation_author=E. L. Lehmann;,citation_author=G. Casella;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=Statistiques, la théorie et ses applications;,citation_author=M. Lejeune;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Nonlinear Perron-Frobenius theory;,citation_author=B. Lemmens;,citation_author=R. Nussbaum;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=189;,citation_series_title=Cambridge tracts in mathematics;">
<meta name="citation_reference" content="citation_title=WHInter: A working set algorithm for high-dimensional sparse second order interaction models;,citation_author=M. Le Morvan;,citation_author=undefined Vert;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Sparse geometric image representations with bandelets;,citation_author=E. Le Pennec;,citation_author=S. Mallat;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=4;,citation_volume=14;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Optimal spatial adaptation to inhomogeneous smoothness: An approach based on kernel estimates with variable bandwidth selectors;,citation_author=O. V. Lepski;,citation_author=E. Mammen;,citation_author=V. G. Spokoiny;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=3;,citation_volume=25;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On a problem of adaptive estimation in Gaussian white noise;,citation_author=O. V. Lepski;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_issue=3;,citation_volume=35;,citation_journal_title=Theory Probab. Appl.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=On problems of adaptive estimation in white Gaussian noise;,citation_author=O. V. Lepski;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=12;,citation_inbook_title=Topics in nonparametric estimation;,citation_series_title=Adv. Soviet math.;">
<meta name="citation_reference" content="citation_title=Robust empirical mean estimators;,citation_author=M. Lerasle;,citation_author=R. I. Oliveira;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_journal_title=arXiv preprint arXiv:1112.3914;">
<meta name="citation_reference" content="citation_title=Information theory and mixing least squares regression;,citation_author=G. Leung;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_dissertation_institution=Yale University;">
<meta name="citation_reference" content="citation_title=Information theory and mixing least-squares regressions;,citation_author=G. Leung;,citation_author=A. R. Barron;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=8;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Natural image denoising: Optimality and inherent bounds;,citation_author=A. Levin;,citation_author=B. Nadler;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Location-aided fast distributed consensus in wireless networks;,citation_author=W. Li;,citation_author=H. Dai;,citation_author=Y. Zhang;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=12;,citation_volume=56;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=A first order free lunch for SQRT-lasso;,citation_author=X. Li;,citation_author=J. Haupt;,citation_author=R. Arora;,citation_author=H. Liu;,citation_author=M. Hong;,citation_author=T. Zhao;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Hyperband: A novel bandit-based approach to hyperparameter optimization;,citation_author=L. Li;,citation_author=K. Jamieson;,citation_author=G. DeSalvo;,citation_author=A. Rostamizadeh;,citation_author=A. Talwalkar;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=The well tempered Lasso;,citation_author=Y. Li;,citation_author=Y. Singer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_journal_title=ICML;">
<meta name="citation_reference" content="citation_title=On convergence of the maximum block improvement method;,citation_author=Z. Li;,citation_author=A. Uschmajew;,citation_author=S. Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=1;,citation_volume=25;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=From Stein’s unbiased risk estimates to the method of generalized cross validation;,citation_author=undefined Li;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_issue=4;,citation_volume=13;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Local linear convergence of forward–backward under partial smoothness;,citation_author=J. Liang;,citation_author=J. Fadili;,citation_author=G. Peyré;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Activity Identification and Local Linear Convergence of Forward–Backward-type Methods;,citation_author=J. Liang;,citation_author=J. Fadili;,citation_author=G. Peyré;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=27;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Real-time texture synthesis by patch-based sampling;,citation_author=L. Liang;,citation_author=C. Liu;,citation_author=Y-Q. Xu;,citation_author=B. Guo;,citation_author=H-Y. Shum;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=3;,citation_volume=20;,citation_journal_title=ACM Trans. Graph.;,citation_publisher=ACM;">
<meta name="citation_reference" content="citation_title=Inequality constrained least-squares estimation;,citation_author=C. K. Liew;,citation_publication_date=1976;,citation_cover_date=1976;,citation_year=1976;,citation_issue=355;,citation_volume=71;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Component selection and smoothing in multivariate nonparametric regression;,citation_author=Y. Lin;,citation_author=H. H. Zhang;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=5;,citation_volume=34;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Online EM algorithm for mixture with application to internet traffic modeling;,citation_author=Z. Liu;,citation_author=J. Almhana;,citation_author=V. Choulakian;,citation_author=R. McGorman;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=4;,citation_volume=50;,citation_journal_title=Comput. Statist. Data Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=On the limited memory BFGS method for large scale optimization;,citation_author=D. C. Liu;,citation_author=J. Nocedal;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A robust and fast non-local means algorithm for image denoising;,citation_author=Y-L. Liu;,citation_author=J. Wang;,citation_author=X. Chen;,citation_author=Y-W. Guo;,citation_author=Q-S. Peng;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=23;,citation_journal_title=Journal of Computer Science and Technology;">
<meta name="citation_reference" content="citation_title=Parametric or nonparametric? A parametricness index for model selection;,citation_author=W. Liu;,citation_author=Y. Yang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=39;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Combining models in longitudinal data analysis;,citation_author=S. Liu;,citation_author=Y. Yang;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=64;,citation_journal_title=Annals of the Institute of Statistical Mathematics;,citation_publisher=Springer Netherlands;">
<meta name="citation_reference" content="citation_title=Robust elastic net regression;,citation_author=W. Liu;,citation_author=Z. Yu;,citation_author=M. Yang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Least squares quantization in PCM;,citation_author=S. Lloyd;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;,citation_issue=2;,citation_volume=28;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Regularized m-estimators with nonconvexity: Statistical and algorithmic theory for local optima;,citation_author=undefined Loh;,citation_author=M. J. Wainwright;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=16;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Breakdown points of affine equivariant estimators of multivariate location and covariance matrices;,citation_author=H. P. Lopuhaä;,citation_author=P. J. Rousseeuw;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_issue=1;,citation_volume=19;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Toward a large-scale and deep phenological stage annotation of herbarium specimens: Case studies from temperate, tropical, and equatorial floras;,citation_author=T. Lorieul;,citation_author=K. Pearson;,citation_author=E. Ellwood;,citation_author=H. Goëau;,citation_author=undefined Molino;,citation_author=P. Sweeney;,citation_author=J. Yost;,citation_author=J. Sachs;,citation_author=G. Nelson;,citation_author=P. Soltis;,citation_author=P. Bonnet;,citation_author=A. Joly;,citation_author=E. Mata-Montero;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=3;,citation_volume=7;,citation_journal_title=Applications in Plant Sciences;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Active set algorithms for the LASSO;,citation_author=M. Loth;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_dissertation_institution=Université des Sciences et Technologie de Lille - Lille I;">
<meta name="citation_reference" content="citation_title=Nonlocal similarity image filtering;,citation_author=Y. Lou;,citation_author=P. Favaro;,citation_author=S. Soatto;,citation_author=A. Bertozzi;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICIAP ’09: Proceedings of the 15th international conference on image analysis and processing;,citation_conference=Springer-Verlag;">
<meta name="citation_reference" content="citation_title=Variational and bayesian models for image denoising : From total variation towards non-local means;,citation_author=C. Louchet;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_dissertation_institution=Université Paris Descartes;">
<meta name="citation_reference" content="citation_title=Total variation denoising using posterior expectation;,citation_author=C. Louchet;,citation_author=L. Moisan;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=EUSIPCO;">
<meta name="citation_reference" content="citation_title=Total variation as a local filter;,citation_author=C. Louchet;,citation_author=L. Moisan;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=4;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Estimation statistique en grande dimension, parcimonie et inégalités d’oracle;,citation_author=K. Lounici;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_dissertation_institution=Université Paris Diderot;">
<meta name="citation_reference" content="citation_title=Muddling labels for regularization, a novel approach to generalization;,citation_author=K. Lounici;,citation_author=K. Meziani;,citation_author=B. Riu;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;,citation_journal_title=arXiv preprint arXiv:2102.08769;">
<meta name="citation_reference" content="citation_title=Oracle inequalities and optimal inference under group sparsity;,citation_author=K. Lounici;,citation_author=M. Pontil;,citation_author=S. Geer;,citation_author=A. B. Tsybakov;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=4;,citation_volume=39;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Generalized mirror averaging and $D$-convex aggregation;,citation_author=K. Lounici;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=3;,citation_volume=16;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=Sup-norm convergence rate and sign concentration property of Lasso and Dantzig estimators;,citation_author=K. Lounici;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=2;,citation_journal_title=Electron. J. Stat.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Fast interscale wavelet denoising of Poisson-corrupted images;,citation_author=F. Luisier;,citation_author=C. Vonesch;,citation_author=T. Blu;,citation_author=M. Unser;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=90;,citation_journal_title=Signal Processing;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Sparse MRI: The application of compressed sensing for rapid MR imaging;,citation_author=M. Lustig;,citation_author=D. L. Donoho;,citation_author=J. M. Pauly;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=6;,citation_volume=58;,citation_journal_title=Magnetic Resonance in Medicine;,citation_publisher=Wiley Subscription Services, Inc., A Wiley Company;">
<meta name="citation_reference" content="citation_title=Fixed point and Bregman iterative methods for matrix rank minimization;,citation_author=S. Ma;,citation_author=D. Goldfarb;,citation_author=L. Chen;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Compressive video sampling with approximate message passing decoding;,citation_author=J. Ma;,citation_author=G. Plonka;,citation_author=M. Y. Hussaini;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=9;,citation_volume=22;,citation_journal_title=IEEE Trans. Circuits Syst. Video Technol.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Information theory, inference and learning algorithms;,citation_author=D. J. C. MacKay;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Introduction to general and generalized linear models;,citation_author=H. Madsen;,citation_author=P. Thyregod;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Video denoising, deblocking, and enhancement through separable 4-D nonlocal spatiotemporal transforms;,citation_author=M. Maggioni;,citation_author=G. Boracchi;,citation_author=A. Foi;,citation_author=K. Egiazarian;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=9;,citation_volume=21;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=A nonlocal transform-domain filter for volumetric data denoising and reconstruction;,citation_author=M. Maggioni;,citation_author=V. Katkovnik;,citation_author=K. Egiazarian;,citation_author=A. Foi;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=22;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Fast image and video denoising via nonlocal means of similar neighborhoods;,citation_author=M. Mahmoudi;,citation_author=G. Sapiro;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=12;,citation_journal_title=IEEE Trans. Signal Process. Lett.;">
<meta name="citation_reference" content="citation_title=Sparse coding for machine learning, image processing and computer vision;,citation_author=J. Mairal;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_dissertation_institution=École normale supérieure de Cachan;">
<meta name="citation_reference" content="citation_title=Non-local sparse models for image restoration;,citation_author=J. Mairal;,citation_author=F. Bach;,citation_author=J. Ponce;,citation_author=G. Sapiro;,citation_author=A. Zisserman;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICCV;">
<meta name="citation_reference" content="citation_title=Online dictionary learning for sparse coding;,citation_author=J. Mairal;,citation_author=F. Bach;,citation_author=J. Ponce;,citation_author=G. Sapiro;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=382;,citation_conference_title=ICML;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Online learning for matrix factorization and sparse coding;,citation_author=J. Mairal;,citation_author=F. Bach;,citation_author=J. Ponce;,citation_author=G. Sapiro;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Task-driven dictionary learning;,citation_author=J. Mairal;,citation_author=F. Bach;,citation_author=J. Ponce;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=34;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Convex and network flow optimization for structured sparsity;,citation_author=J. Mairal;,citation_author=R. Jenatton;,citation_author=G. Obozinski;,citation_author=F. Bach;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Learning multiscale sparse representations for image and video restoration;,citation_author=J. Mairal;,citation_author=G. Sapiro;,citation_author=M. Elad;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=1;,citation_volume=7;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=Complexity analysis of the lasso regularization path;,citation_author=J. Mairal;,citation_author=B. Yu;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Optimization with first-order surrogate functions;,citation_author=J. Mairal;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Optimal inversion of the Anscombe transformation in low-count Poisson image denoising;,citation_author=M. Mäkitalo;,citation_author=A. Foi;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=20;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Optimal inversion of the generalized anscombe transformation for poisson-gaussian noise;,citation_author=M. Mäkitalo;,citation_author=A. Foi;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=submitted;">
<meta name="citation_reference" content="citation_title=Optimal inversion of the generalized Anscombe transformation for Poisson-Gaussian noise;,citation_author=M. Mäkitalo;,citation_author=A. Foi;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=22;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Anisotropic nonlocal means;,citation_author=A. Maleki;,citation_author=M. Narayan;,citation_author=R. G. Baraniuk;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Appl. Comput. Harmon. Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Suboptimality of nonlocal means for images with sharp edges;,citation_author=A. Maleki;,citation_author=M. Narayan;,citation_author=R. G. Baraniuk;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=33;,citation_journal_title=Appl. Comput. Harmon. Anal.;">
<meta name="citation_reference" content="citation_title=Projecting onto a polytope simplifies data distributions;,citation_author=F. Malgouyres;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_technical_report_institution=University Paris 13;">
<meta name="citation_reference" content="citation_title=Rank related properties for basis pursuit and total variation regularization;,citation_author=F. Malgouyres;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=87;,citation_journal_title=Signal Processing;">
<meta name="citation_reference" content="citation_title=Matching pursuit with time-frequency dictionaries;,citation_author=S. Mallat;,citation_author=Z. Zhang;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_volume=41;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=A wavelet tour of signal processing;,citation_author=S. Mallat;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=A theory for multiresolution signal decomposition: The wavelet representation;,citation_author=S. Mallat;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=7;,citation_volume=11;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=A wavelet tour of signal processing;,citation_author=S. Mallat;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Some comments on $C\_{p}$;,citation_author=C. L. Mallows;,citation_publication_date=1973;,citation_cover_date=1973;,citation_year=1973;,citation_issue=4;,citation_volume=15;,citation_journal_title=Technometrics;">
<meta name="citation_reference" content="citation_title=Smooth discrimination analysis;,citation_author=E. Mammen;,citation_author=A. B. Tsybakov;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=6;,citation_volume=27;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Locally adaptive regression splines;,citation_author=E. Mammen;,citation_author=S. Geer;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=25;,citation_journal_title=Ann. Statist.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Hierarchical testing in the high-dimensional setting with correlated variables;,citation_author=J. Mandozzi;,citation_author=P. Bühlmann;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=513;,citation_volume=111;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Differentially private coordinate descent for composite empirical risk minimization;,citation_author=P. Mangold;,citation_author=A. Bellet;,citation_author=J. Salmon;,citation_author=M. Tommasi;,citation_publication_date=2021;,citation_cover_date=2021;,citation_year=2021;">
<meta name="citation_reference" content="citation_title=On a test of whether one of two random variables is stochastically larger than the other;,citation_author=H. B. Mann;,citation_author=D. R. Whitney;,citation_publication_date=1947;,citation_cover_date=1947;,citation_year=1947;,citation_issue=1;,citation_volume=18;,citation_journal_title=Ann. Math. Stat.;">
<meta name="citation_reference" content="citation_title=Introduction to information retrieval;,citation_author=C. D. Manning;,citation_author=P. Raghavan;,citation_author=H. Schütze;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;">
<meta name="citation_reference" content="citation_title=Bayesian core: A practical approach to computational Bayesian statistics;,citation_author=undefined Marin;,citation_author=C. P. Robert;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=Portfolio selection;,citation_author=H. Markowitz;,citation_publication_date=1952;,citation_cover_date=1952;,citation_year=1952;,citation_issue=1;,citation_volume=7;,citation_journal_title=The Journal of Finance;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The optimization of a quadratic function subject to linear constraints;,citation_author=H. Markowitz;,citation_publication_date=1956;,citation_cover_date=1956;,citation_year=1956;,citation_volume=3;,citation_journal_title=Naval Res. Logist. Quart.;">
<meta name="citation_reference" content="citation_title=Robust statistics: Theory and methods;,citation_author=R. A. Maronna;,citation_author=R. D. Martin;,citation_author=V. J. Yohai;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Bayesian multi-task learning for decoding multi-subject neuroimaging data;,citation_author=A. Marquand;,citation_author=M. Brammer;,citation_author=S. Williams;,citation_author=O. Doyle;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=92;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=Inequalities: Theory of majorization and its applications;,citation_author=A. W. Marshall;,citation_author=I. Olkin;,citation_author=B. C. Arnold;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Brève communication. Régularisation d’inéquations variationnelles par approximations successives;,citation_author=B. Martinet;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_issue=R3;,citation_volume=4;,citation_journal_title=Revue française d’informatique et de recherche opérationnelle. Série rouge;,citation_publisher=EDP Sciences;">
<meta name="citation_reference" content="citation_title=The Lasso as an l1-ball model selection procedure;,citation_author=P. Massart;,citation_author=C. Meynet;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=5;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=About the constants in Talagrand’s concentration inequalities for empirical processes;,citation_author=P. Massart;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=2;,citation_volume=28;,citation_journal_title=Ann. Probab.;">
<meta name="citation_reference" content="citation_title=Concentration inequalities and model selection;,citation_author=P. Massart;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=1896;,citation_series_title=Lecture notes in mathematics;">
<meta name="citation_reference" content="citation_title=Support recovery and sup-norm convergence rates for sparse pivotal regression;,citation_author=M. Massias;,citation_author=Q. Bertrand;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Generalized concomitant multi-task lasso for sparse multimodal regression;,citation_author=M. Massias;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=84;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=From safe screening rules to working sets for faster lasso-type solvers;,citation_author=M. Massias;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS-OPT;">
<meta name="citation_reference" content="citation_title=Celer: a Fast Solver for the Lasso with Dual Extrapolation;,citation_author=M. Massias;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=80;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Dual extrapolation for sparse generalized linear models;,citation_author=M. Massias;,citation_author=S. Vaiter;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=21;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Understanding and using linear programming;,citation_author=J. Matoušek;,citation_author=B. Gärtner;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_series_title=Universitext;">
<meta name="citation_reference" content="citation_title=On variants of the Johnson–Lindenstrauss Lemma;,citation_author=J. Matoušek;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=33;,citation_journal_title=Random Structures &amp;amp;amp; Algorithms;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=&amp;amp;amp;lt;i&amp;gt;SparseNet&amp;lt;/i&amp;gt;: Coordinate descent with nonconvex penalties;,citation_author=R. Mazumder;,citation_author=J. H. Friedman;,citation_author=T. J. Hastie;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=495;,citation_volume=106;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Spectral regularization algorithms for learning large incomplete matrices;,citation_author=R. Mazumder;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=J. Mach. Learn. Res.;,citation_publisher=JMLR. org;">
<meta name="citation_reference" content="citation_title=Some PAC-bayesian theorems;,citation_author=D. A. McAllester;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=COLT;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Generalized linear models;,citation_author=P. McCullagh;,citation_author=J. A. Nelder;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_series_title=Chapman and hall/CRC monographs on statistics and applied probability series;">
<meta name="citation_reference" content="citation_title=Statistical rethinking: A bayesian course with examples in r and stan;,citation_author=R. McElreath;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_series_title=Chapman &amp;amp;amp; hall/CRC texts in statistical science;">
<meta name="citation_reference" content="citation_title=Variations of box plots;,citation_author=R. McGill;,citation_author=J. W. Tukey;,citation_author=W. A. Larsen;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=1;,citation_volume=32;,citation_journal_title=The American Statistician;,citation_publisher=Taylor &amp;amp;amp; Francis Group;">
<meta name="citation_reference" content="citation_title=UMAP: Uniform manifold approximation and projection for dimension reduction;,citation_author=L. McInnes;,citation_author=J. Healy;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=abs/1802.03426;,citation_journal_title=ArXiv;">
<meta name="citation_reference" content="citation_title=Python for data analysis: Data wrangling with pandas, NumPy, and IPython;,citation_author=W. McKinney;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=On the eigenvalues of double band matrices;,citation_author=T. McMillen;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=10;,citation_volume=431;,citation_journal_title=Linear Algebra and Its Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=High-dimensional graphs and variable selection with the lasso;,citation_author=N. Meinshausen;,citation_author=P. Bühlmann;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=34;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Stability selection;,citation_author=N. Meinshausen;,citation_author=P. Bühlmann;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=72;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=P-values for high-dimensional regression;,citation_author=N. Meinshausen;,citation_author=L. Meier;,citation_author=P. Bühlmann;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=488;,citation_volume=104;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Graph theoretic methods in multiagent networks;,citation_author=M. Mesbahi;,citation_author=M. Egerstedt;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=The beginning of the monte carlo method;,citation_author=Nicholas Metropolis;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=15;,citation_journal_title=Los Alamos Science;">
<meta name="citation_reference" content="citation_title=Wavelets and operators;,citation_author=Y. Meyer;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=37;,citation_series_title=Cambridge studies in advanced mathematics;">
<meta name="citation_reference" content="citation_title=Markov chains and stochastic stability;,citation_author=S. Meyn;,citation_author=R. L. Tweedie;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Probabilistic graphical models for boosting cardinal and ordinal peer grading in MOOCs;,citation_author=F. Mi;,citation_author=undefined Yeung;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Twenty-ninth AAAI conference on artificial intelligence;">
<meta name="citation_reference" content="citation_title=A family of penalty functions for structured sparsity;,citation_author=C. A. Micchelli;,citation_author=J. M. Morales;,citation_author=M. Pontil;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=A finite algorithm for finding the projection of a point onto the canonical simplex of $\mathbb{R}^n$;,citation_author=C. Michelot;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=1;,citation_volume=50;,citation_journal_title=Journal of Optimization Theory and Applications;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Kernel PCA and de-noising in feature spaces;,citation_author=S. Mika;,citation_author=B. Schölkopf;,citation_author=A. J. Smola;,citation_author=K-R. Müller;,citation_author=M. Scholz;,citation_author=G. Rätsch;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=A tour of modern image filtering: New insights and methods, both practical and theoretical;,citation_author=P. Milanfar;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=30;,citation_journal_title=IEEE Signal Process. Mag.;">
<meta name="citation_reference" content="citation_title=Symmetrizing smoothing filters;,citation_author=P. Milanfar;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=6;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Geometric median and robust estimation in banach spaces;,citation_author=S. Minsker;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=4;,citation_volume=21;,citation_journal_title=Bernoulli;,citation_publisher=Bernoulli Society for Mathematical Statistics; Probability;">
<meta name="citation_reference" content="citation_title=The benefit of group sparsity in group inference with de-biased scaled group lasso;,citation_author=R. Mitra;,citation_author=undefined Zhang;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=2;,citation_volume=10;,citation_journal_title=Electron. J. Stat.;,citation_publisher=The Institute of Mathematical Statistics; the Bernoulli Society;">
<meta name="citation_reference" content="citation_title=MNE software for processing MEG and EEG data;,citation_author=A. Gramfort;,citation_author=M. Luessi;,citation_author=E. Larson;,citation_author=D. A. Engemann;,citation_author=D. Strohmeier;,citation_author=C. Brodbeck;,citation_author=L. Parkkonen;,citation_author=M. S. Hämäläinen;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_volume=86;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=Fonctions convexes duales et points proximaux dans un espace hilbertien;,citation_author=Jean-Jacques Moreau;,citation_publication_date=1962;,citation_cover_date=1962;,citation_year=1962;,citation_volume=255;,citation_journal_title=C. R. Acad. Sci. Paris;">
<meta name="citation_reference" content="citation_title=Proximité et dualité dans un espace hilbertien;,citation_author=Jean-Jacques Moreau;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_volume=93;,citation_journal_title=Bull. Soc. Math. France;">
<meta name="citation_reference" content="citation_title=Fast distributed algorithms for computing separable functions;,citation_author=D. Mosk-Aoyama;,citation_author=D. Shah;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=7;,citation_volume=54;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Depth statistics;,citation_author=K. Mosler;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=Robustness and complex data structures;">
<meta name="citation_reference" content="citation_title=Tukey depth: Linear programming and applications;,citation_author=P. Mozharovskyi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=arXiv preprint arXiv:1603.00069;">
<meta name="citation_reference" content="citation_title=Aspects of multivariate statistical theory;,citation_author=R. J. Muirhead;,citation_publication_date=1982;,citation_cover_date=1982;,citation_year=1982;">
<meta name="citation_reference" content="citation_title=Handbook of floating-point arithmetic (2nd ed.);,citation_author=undefined Muller;,citation_author=N. Brunie;,citation_author=F. Dinechin;,citation_author=undefined Jeannerod;,citation_author=M. Joldes;,citation_author=V. Lefèvre;,citation_author=G. Melquiond;,citation_author=N. Revol;,citation_author=S. Torres;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;">
<meta name="citation_reference" content="citation_title=Identifying mislabeled instances in classification datasets;,citation_author=N. M. Müller Markert;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_fulltext_html_url=http://arxiv.org/abs/1912.05283;,citation_volume=abs/1912.05283;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=Variable bandwidth kernel estimators of regression curves;,citation_author=undefined Müller;,citation_author=U. Stadtmüller;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_issue=1;,citation_volume=15;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Adaptive principal components and image denoising;,citation_author=D. D. Muresan;,citation_author=T. W. Parks;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Machine learning: A probabilistic perspective;,citation_author=K. P. Murphy;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;">
<meta name="citation_reference" content="citation_title=On estimating regression;,citation_author=E. A. Nadaraya;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_issue=1;,citation_volume=9;,citation_journal_title=Theory of Probability and its Applications;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Safe feature pruning for sparse high-order interaction models;,citation_author=K. Nakagawa;,citation_author=S. Suzumura;,citation_author=M. Karasuyama;,citation_author=K. Tsuda;,citation_author=I. Takeuchi;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Safe pattern pruning: An efficient approach for predictive pattern mining;,citation_author=K. Nakagawa;,citation_author=S. Suzumura;,citation_author=M. Karasuyama;,citation_author=K. Tsuda;,citation_author=I. Takeuchi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Sparse approximate solutions to linear systems;,citation_author=B. K. Natarajan;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_issue=2;,citation_volume=24;,citation_journal_title=SIAM J. Comput.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Efficient smoothed concomitant lasso estimation for high dimensional regression;,citation_author=E. Ndiaye;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=V. Leclère;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=1;,citation_volume=904;,citation_journal_title=Journal of Physics: Conference Series;">
<meta name="citation_reference" content="citation_title=GAP safe screening rules for sparse multi-task and multi-class models;,citation_author=E. Ndiaye;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=GAP safe screening rules for sparse-group-lasso;,citation_author=E. Ndiaye;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Gap safe screening rules for sparsity enforcing penalties;,citation_author=E. Ndiaye;,citation_author=O. Fercoq;,citation_author=A. Gramfort;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=128;,citation_volume=18;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Safe grid search with optimal complexity;,citation_author=E. Ndiaye;,citation_author=T. Le;,citation_author=O. Fercoq;,citation_author=J. Salmon;,citation_author=I. Takeuchi;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=97;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Safe optimization algorithms for variable selection and hyperparameter tuning;,citation_author=E. Ndiaye;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_dissertation_institution=Université Paris-Saclay;">
<meta name="citation_reference" content="citation_title=Decentralized online optimization with global objectives and local communication;,citation_author=A. Nedić;,citation_author=S. Lee;,citation_author=M. Raginsky;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=ACC;">
<meta name="citation_reference" content="citation_title=Distributed subgradient methods for multi-agent optimization;,citation_author=A. Nedić;,citation_author=A. E. Ozdaglar;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=54;,citation_journal_title=IEEE Trans. Autom. Control;">
<meta name="citation_reference" content="citation_title=A unified framework for high-dimensional analysis of $M$-estimators with decomposable regularizers;,citation_author=S. Negahban;,citation_author=P. Ravikumar;,citation_author=M. J. Wainwright;,citation_author=B. Yu;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Restricted strong convexity and weighted matrix completion: Optimal bounds with noise;,citation_author=S. Negahban;,citation_author=M. J. Wainwright;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=13;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Problem complexity and method efficiency in optimization;,citation_author=A. S. Nemirovski;,citation_author=D. B. Yudin;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_series_title=A wiley-interscience publication;">
<meta name="citation_reference" content="citation_title=Topics in non-parametric statistics;,citation_author=A. S. Nemirovski;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_volume=1738;,citation_series_title=Lecture notes in math.;">
<meta name="citation_reference" content="citation_title=Introductory lectures on convex optimization;,citation_author=Y. Nesterov;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=87;,citation_series_title=Applied optimization;">
<meta name="citation_reference" content="citation_title=Smooth minimization of non-smooth functions;,citation_author=Y. Nesterov;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_volume=103;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Primal-dual subgradient methods for convex problems;,citation_author=Y. Nesterov;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=120;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Efficiency of coordinate descent methods on huge-scale optimization problems;,citation_author=Y. Nesterov;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=22;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=A method for solving a convex programming problem with rate of convergence ${O}(1/k^2)$;,citation_author=Y. Nesterov;,citation_publication_date=1983;,citation_cover_date=1983;,citation_year=1983;,citation_issue=3;,citation_volume=269;,citation_journal_title=Soviet Math. Doklady;">
<meta name="citation_reference" content="citation_title=ECKO: Ensemble of clustered knockoffs for robust multivariate inference on fMRI data;,citation_author=undefined Nguyen;,citation_author=undefined Chevalier;,citation_author=B. Thirion;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=International conference on information processing in medical imaging;">
<meta name="citation_reference" content="citation_title=Predicting good probabilities with supervised learning;,citation_author=A. Niculescu-Mizil;,citation_author=R. Caruana;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Statistical exponential families: A digest with flash cards;,citation_author=F. Nielsen;,citation_author=V. Garcia;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Local strong homogeneity of a regularized estimator;,citation_author=M. Nikolova;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=2;,citation_volume=61;,citation_journal_title=SIAM J. Appl. Math.;">
<meta name="citation_reference" content="citation_title=Hogwild!: A lock-free approach to parallelizing stochastic gradient descent;,citation_author=F. Niu;,citation_author=B. Recht;,citation_author=C. Ré;,citation_author=S. J. Wright;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=24;,citation_journal_title=NIPS;">
<meta name="citation_reference" content="citation_title=Numerical optimization;,citation_author=J. Nocedal;,citation_author=S. J. Wright;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_series_title=Springer series in operations research;">
<meta name="citation_reference" content="citation_title=Stat labs: Mathematical statistics through applications;,citation_author=D. Nolan;,citation_author=T. P. Speed;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Coordinate descent converges faster with the Gauss-Southwell rule than random selection;,citation_author=J. Nutini;,citation_author=M. W. Schmidt;,citation_author=I. H. Laradji;,citation_author=M. P. Friedlander;,citation_author=H. A. Koepke;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Joint covariate selection and joint subspace selection for multiple classification problems;,citation_author=G. Obozinski;,citation_author=B. Taskar;,citation_author=M. I. Jordan;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=20;,citation_journal_title=Statistics and Computing;">
<meta name="citation_reference" content="citation_title=Support union recovery in high-dimensional multivariate regression;,citation_author=G. Obozinski;,citation_author=M. J. Wainwright;,citation_author=M. Jordan;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=39;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On iteratively reweighted algorithms for nonsmooth nonconvex optimization in computer vision;,citation_author=P. Ochs;,citation_author=A. Dosovitskiy;,citation_author=T. Brox;,citation_author=T. Pock;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=1;,citation_volume=8;,citation_journal_title=SIAM Journal on Imaging Sciences;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Bilevel optimization with nonsmooth lower level problems;,citation_author=P. Ochs;,citation_author=R. Ranftl;,citation_author=T. Brox;,citation_author=T. Pock;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_volume=9087;,citation_conference_title=SSVM;">
<meta name="citation_reference" content="citation_title=Safe screening of non-support vectors in pathwise SVM computation;,citation_author=K. Ogawa;,citation_author=Y. Suzuki;,citation_author=I. Takeuchi;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=28;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=DINOv2: Learning robust visual features without supervision;,citation_author=Maxime Oquab;,citation_author=Timothée Darcet;,citation_author=Théo Moutakanni;,citation_author=Huy V. Vo;,citation_author=Marc Szafraniec;,citation_author=Vasil Khalidov;,citation_author=Pierre Fernandez;,citation_author=Daniel Haziza;,citation_author=Francisco Massa;,citation_author=Alaaeldin El-Nouby;,citation_author=Mido Assran;,citation_author=Nicolas Ballas;,citation_author=Wojciech Galuba;,citation_author=Russell Howes;,citation_author=Po-Yao Huang;,citation_author=Shang-Wen Li;,citation_author=Ishan Misra;,citation_author=Michael Rabbat;,citation_author=Vasu Sharma;,citation_author=Gabriel Synnaeve;,citation_author=Hu Xu;,citation_author=Hervé Jégou;,citation_author=Julien Mairal;,citation_author=Patrick Labatut;,citation_author=Armand Joulin;,citation_author=Piotr Bojanowski;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_fulltext_html_url=https://openreview.net/forum?id=a68SUt6zFt;,citation_journal_title=Trans. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Efficient nonlocal-means denoising using the SVD;,citation_author=J. Orchard;,citation_author=M. Ebrahimi;,citation_author=A. Wong;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=A new approach to variable selection in least squares problems;,citation_author=M. R. Osborne;,citation_author=B. Presnell;,citation_author=B. A. Turlach;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=3;,citation_volume=20;,citation_journal_title=IMA J. Numer. Anal.;">
<meta name="citation_reference" content="citation_title=An iterative regularization method for total variation-based image restoration;,citation_author=S. Osher;,citation_author=M. Burger;,citation_author=D. Goldfarb;,citation_author=J. Xu;,citation_author=W. Yin;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=4;,citation_journal_title=Multiscale Model. Simul.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Sparse recovery via differential inclusions;,citation_author=S. Osher;,citation_author=F. Ruan;,citation_author=J. Xiong;,citation_author=Y. Yao;,citation_author=W. Yin;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=Appl. Comput. Harmon. Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=A distributed spatio-temporal EEG/MEG inverse solver;,citation_author=W. Ou;,citation_author=M. Hämaläinen;,citation_author=P. Golland;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=44;,citation_journal_title=NeuroImage;">
<meta name="citation_reference" content="citation_title=Probabilités : Tome 2, licence - CAPES;,citation_author=undefined Ouvrard;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_series_title=Enseignement des mathématiques;">
<meta name="citation_reference" content="citation_title=Probabilités : Tome 1, licence - CAPES;,citation_author=J-Y. Ouvrard;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_series_title=Enseignement des mathématiques;">
<meta name="citation_reference" content="citation_title=A robust hybrid of lasso and ridge regression;,citation_author=A. B. Owen;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=443;,citation_journal_title=Contemporary Mathematics;,citation_publisher=Providence, RI: American Mathematical Society;">
<meta name="citation_reference" content="citation_title=Statistique générale pour utilisateurs. Méthodologie;,citation_author=J. Pagès;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;">
<meta name="citation_reference" content="citation_title=Human age estimation by metric learning for regression problems;,citation_author=L. Pan;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=EMMCVPR;,citation_conference=Springer;">
<meta name="citation_reference" content="citation_title=A fast NL-means method in image denoising based on the similarity of spatially sampled pixels;,citation_author=C. Pang;,citation_author=O. C. Au;,citation_author=J. Dai;,citation_author=W. Yang;,citation_author=F. Zou;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=MMSP;">
<meta name="citation_reference" content="citation_title=Thumbs up?: Sentiment classification using machine learning techniques;,citation_author=B. Pang;,citation_author=L. Lee;,citation_author=S. Vaithyanathan;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=Proceedings of the ACL-02 conference on empirical methods in natural language processing - volume 10;,citation_conference=Association for Computational Linguistics;,citation_series_title=EMNLP ’02;">
<meta name="citation_reference" content="citation_title=Proximal algorithms;,citation_author=N. Parikh;,citation_author=S. Boyd;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=1;,citation_journal_title=Foundations and Trends in Machine Learning;">
<meta name="citation_reference" content="citation_title=The Bayesian lasso;,citation_author=T. Park;,citation_author=G. Casella;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=482;,citation_volume=103;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=L1-regularization path algorithm for generalized linear models;,citation_author=M. Y. Park;,citation_author=T. Hastie;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=4;,citation_volume=69;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Generalized linear models with regularization;,citation_author=M. Y. Park;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=Fast dimensionality reduction and simple PCA;,citation_author=M. Partridge;,citation_author=R. Calvo;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=2;,citation_journal_title=Intelligent Data Analysis;">
<meta name="citation_reference" content="citation_title=On estimation of a probability density function and mode;,citation_author=E. Parzen;,citation_publication_date=1962;,citation_cover_date=1962;,citation_year=1962;,citation_volume=33;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=On the criterion that a given system of deviations from the probable in the case of a correlated system of variables is such that it can be reasonably supposed to have arisen from random sampling;,citation_author=K. Pearson;,citation_publication_date=1900;,citation_cover_date=1900;,citation_year=1900;,citation_issue=302;,citation_volume=50;,citation_journal_title=The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Scikit-learn: Machine learning in Python;,citation_author=F. Pedregosa;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=V. Michel;,citation_author=B. Thirion;,citation_author=O. Grisel;,citation_author=M. Blondel;,citation_author=P. Prettenhofer;,citation_author=R. Weiss;,citation_author=V. Dubourg;,citation_author=J. Vanderplas;,citation_author=A. Passos;,citation_author=D. Cournapeau;,citation_author=M. Brucher;,citation_author=M. Perrot;,citation_author=E. Duchesnay;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_volume=12;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Isotonic regression;,citation_author=F. Pedregosa;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_publisher=https://fa.bianp.net/blog/2013/isotonic-regression/;">
<meta name="citation_reference" content="citation_title=Hyperparameter optimization with approximate gradient;,citation_author=F. Pedregosa;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=48;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Gossip algorithms for computing U-statistics;,citation_author=K. Pelckmans;,citation_author=J. Suykens;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=IFAC Workshop on Estimation and Control of Networked Systems;">
<meta name="citation_reference" content="citation_title=Coordinate-friendly structures, algorithms and applications;,citation_author=Z. Peng;,citation_author=T. Wu;,citation_author=Y. Xu;,citation_author=M. Yan;,citation_author=W. Yin;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=1;,citation_journal_title=Ann. Math. Sci. Appl.;,citation_publisher=International Press of Boston, Somerville, MA;">
<meta name="citation_reference" content="citation_title=Parallel and distributed sparse optimization;,citation_author=Z. Peng;,citation_author=M. Yan;,citation_author=W. Yin;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=2013 asilomar conference on signals, systems and computers;,citation_conference=IEEE;">
<meta name="citation_reference" content="citation_title=Faster coordinate descent via adaptive importance sampling;,citation_author=D. Perekrestenko;,citation_author=V. Cevher;,citation_author=M. Jaggi;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Scale space and edge detection using anisotropic diffusion;,citation_author=P. Perona;,citation_author=J. Malik;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_volume=12;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Improving regression estimation: Averaging methods for variance reduction with extensions to general convex measure optimization;,citation_author=M. P. Perrone;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_dissertation_institution=Brown University;">
<meta name="citation_reference" content="citation_title=When networks disagree: Ensemble method for neural networks;,citation_author=M. P. Perrone;,citation_author=L. N. Cooper;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_conference_title=Artificial neural networks for speech and vision;">
<meta name="citation_reference" content="citation_title=Learning search spaces for bayesian optimization: Another view of hyperparameter transfer learning;,citation_author=V. Perrone;,citation_author=H. Shen;,citation_author=M. W. Seeger;,citation_author=C. Archambeau;,citation_author=R. Jenatton;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=NeurIPS;">
<meta name="citation_reference" content="citation_title=Convex optimization in normed spaces: Theory, methods and examples;,citation_author=J. Peypouquet;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Image processing with nonlocal spectral bases.;,citation_author=G. Peyré;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=2;,citation_volume=7;,citation_journal_title=Multiscale Model. Simul.;">
<meta name="citation_reference" content="citation_title=Manifold models for signals and images;,citation_author=G. Peyré;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=2;,citation_volume=113;,citation_journal_title=Computer Vision and Image Understanding;">
<meta name="citation_reference" content="citation_title=Robust sketching for multiple square-root LASSO problems;,citation_author=V. Pham;,citation_author=L. El Ghaoui;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Tuned models of peer assessment in MOOCs;,citation_author=C. Piech;,citation_author=J. Huang;,citation_author=Z. Chen;,citation_author=C. B. Do;,citation_author=A. Y. Ng;,citation_author=D. Koller;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=Proceedings of the 6th international conference on educational data mining;">
<meta name="citation_reference" content="citation_title=Mixed-effects models in s and s-PLUS;,citation_author=J. Pinheiro;,citation_author=D. Bates;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Optimal filtration of square-integrable signals in Gaussian noise;,citation_author=M. S. Pinsker;,citation_publication_date=1980;,citation_cover_date=1980;,citation_year=1980;,citation_issue=2;,citation_volume=16;,citation_journal_title=Probl. Peredachi Inf.;">
<meta name="citation_reference" content="citation_title=The volume of convex bodies and Banach space geometry;,citation_author=G. Pisier;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_volume=94;,citation_series_title=Cambridge tracts in mathematics;">
<meta name="citation_reference" content="citation_title=Studies in the History of Probability and Statistics. XXIX: The discovery of the method of least squares;,citation_author=R. L. Plackett;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_issue=2;,citation_volume=59;,citation_journal_title=Biometrika;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Robust 1-bit compressed sensing and sparse logistic regression: A convex programming approach;,citation_author=Y. Plan;,citation_author=R. Vershynin;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=One-bit compressed sensing by linear programming;,citation_author=Y. Plan;,citation_author=R. Vershynin;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=Communications on Pure and Applied Mathematics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods;,citation_author=J. C. Platt;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=ADVANCES IN LARGE MARGIN CLASSIFIERS;,citation_conference=MIT Press;">
<meta name="citation_reference" content="citation_title=Identifying mislabeled data using the area under the margin ranking;,citation_author=G. Pleiss;,citation_author=T. Zhang;,citation_author=E. R. Elenberg;,citation_author=K. Q. Weinberger;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_conference_title=NeurIPS;">
<meta name="citation_reference" content="citation_title=A user’s guide to measure theoretic probability;,citation_author=D. Pollard;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=8;,citation_series_title=Cambridge series in statistical and probabilistic mathematics;">
<meta name="citation_reference" content="citation_title=Convergence of stochastic processes;,citation_author=D. Pollard;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Adaptive weights smoothing with applications to image restoration;,citation_author=J. Polzehl;,citation_author=V. G. Spokoiny;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=2;,citation_volume=62;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Image denoising: Pointwise adaptive approach;,citation_author=J. Polzehl;,citation_author=V. G. Spokoiny;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=1;,citation_volume=31;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Propagation-separation approach for local likelihood estimation;,citation_author=J. Polzehl;,citation_author=V. G. Spokoiny;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=135;,citation_journal_title=Probab. Theory Related Fields;">
<meta name="citation_reference" content="citation_title=Local convergence properties of SAGA/Prox-SVRG and acceleration;,citation_author=C. Poon;,citation_author=J. Liang;,citation_author=C. Schöenlieb;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Integral histogram: A fast way to extract histograms in cartesian spaces;,citation_author=F. M. Porikli;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=1;,citation_conference_title=CVPR;,citation_conference=IEEE Computer Society;">
<meta name="citation_reference" content="citation_title=Constant time o(1) bilateral filtering;,citation_author=F. M. Porikli;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Image denoising using scale mixtures of gaussians in the wavelet domain;,citation_author=J. Portilla;,citation_author=V. Strela;,citation_author=M. J. Wainwright;,citation_author=E. P. Simoncelli;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=11;,citation_volume=12;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Censored regression quantiles;,citation_author=J. L. Powell;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=1;,citation_volume=32;,citation_journal_title=J. Econometrics;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Quantile function methods for decision analysis;,citation_author=B. W. Powley;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_dissertation_institution=Stanford University;">
<meta name="citation_reference" content="citation_title=Non-parametric function fitting;,citation_author=M. B. Priestley;,citation_author=M. T. Chao;,citation_publication_date=1972;,citation_cover_date=1972;,citation_year=1972;,citation_volume=34;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Automatic differentiation in PyTorch;,citation_author=A. Paszke;,citation_author=S. Gross;,citation_author=S. Chintala;,citation_author=G. Chanan;,citation_author=E. Yang;,citation_author=Z. DeVito;,citation_author=Z. Lin;,citation_author=A. Desmaison;,citation_author=L. Antiga;,citation_author=A. Lerer;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS autodiff workshop;">
<meta name="citation_reference" content="citation_title=Efficient block-coordinate descent algorithms for the group lasso;,citation_author=Z. Qin;,citation_author=K. Scheinberg;,citation_author=D. Goldfarb;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=5;,citation_journal_title=Math. Program. Comput.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Numerical mathematics;,citation_author=A. Quarteroni;,citation_author=R. Sacco;,citation_author=F. Saleri;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=37;,citation_series_title=Texts in applied mathematics;">
<meta name="citation_reference" content="citation_title=Induction of decision trees;,citation_author=J. R. Quinlan;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_volume=1;,citation_journal_title=Maching Learning;">
<meta name="citation_reference" content="citation_title=Sequential anomaly detection in the presence of noise and limited feedback;,citation_author=M. Raginsky;,citation_author=R. Willett;,citation_author=C. Horn;,citation_author=J. Silva;,citation_author=R. Marcia;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_journal_title=Submitted;">
<meta name="citation_reference" content="citation_title=Random features for large-scale kernel machines;,citation_author=A. Rahimi;,citation_author=B. Recht;,citation_editor=J. C. Platt;,citation_editor=D. Koller;,citation_editor=Y. Singer;,citation_editor=S. T. Roweis;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_inbook_title=NIPS;">
<meta name="citation_reference" content="citation_title=Weighted sums of random kitchen sinks: Replacing minimization with randomization in learning;,citation_author=A. Rahimi;,citation_author=B. Recht;,citation_editor=D. Koller;,citation_editor=D. Schuurmans;,citation_editor=Y. Bengio;,citation_editor=L. Bottou;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_inbook_title=NIPS;">
<meta name="citation_reference" content="citation_title=Simultaneously leveraging output and task structures for multiple-output regression;,citation_author=P. Rai;,citation_author=A. Kumar;,citation_author=H. Daume;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Screening rules for convex problems;,citation_author=A. Raj;,citation_author=J. Olbrich;,citation_author=B. Gärtner;,citation_author=B. Schölkopf;,citation_author=M. Jaggi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=arXiv preprint arXiv:1609.07478;">
<meta name="citation_reference" content="citation_title=Screening rules for lasso with non-convex sparse regularizers;,citation_author=A. Rakotomamonjy;,citation_author=G. Gasso;,citation_author=J. Salmon;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_volume=97;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Distributed stochastic subgradient projection algorithms for convex optimization;,citation_author=S. Ram;,citation_author=A. Nedić;,citation_author=V. Veeravalli;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3;,citation_volume=147;,citation_journal_title=J. Optimiz. Theory. App.;">
<meta name="citation_reference" content="citation_title=Monte-Carlo SURE: A black-box optimization of regularization parameters for general denoising algorithms;,citation_author=S. Ramani;,citation_author=T. Blu;,citation_author=M. Unser;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=9;,citation_volume=17;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Fast and flexible ADMM algorithms for trend filtering;,citation_author=A. Ramdas;,citation_author=R. J. Tibshirani;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=3;,citation_volume=25;,citation_journal_title=Journal of Computational and Graphical Statistics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Functional data analysis;,citation_author=J. O. Ramsay;,citation_author=B. W. Silverman;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Scaled and square-root elastic net;,citation_author=E. Raninen;,citation_author=E. Ollila;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=On model selection;,citation_author=C. R. Rao;,citation_author=Y. Wu;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=38;,citation_inbook_title=Model selection;,citation_series_title=IMS lecture notes monogr. ser.;">
<meta name="citation_reference" content="citation_title=Estimation of heteroscedastic variances in linear models;,citation_author=C. R. Rao;,citation_publication_date=1970;,citation_cover_date=1970;,citation_year=1970;,citation_volume=65;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Learning to be Bayesian without supervision;,citation_author=M. Raphan;,citation_author=E. P. Simoncelli;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_volume=19;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Guaranteed minimum-rank solutions of linear matrix equations via nuclear norm minimization;,citation_author=B. Recht;,citation_author=M. Fazel;,citation_author=P. A. Parrilo;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=3;,citation_volume=52;,citation_journal_title=SIAM review;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Parallel stochastic gradient algorithms for large-scale matrix completion;,citation_author=B. Recht;,citation_author=C. Ré;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=5;,citation_journal_title=Math. Program. Comput.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=A study of error variance estimation in lasso regression;,citation_author=S. Reid;,citation_author=R. Tibshirani;,citation_author=J. Friedman;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=26;,citation_journal_title=Stat. Sin.;">
<meta name="citation_reference" content="citation_title=Factorization machines;,citation_author=Steffen Rendle;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_doi=10.1109/ICDM.2010.127;,citation_conference_title=ICDM 2010, the 10th IEEE international conference on data mining, sydney, australia, 14-17 december 2010;">
<meta name="citation_reference" content="citation_title=Factorization machines with libfm;,citation_author=S. Rendle;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=3;,citation_journal_title=ACM Transactions on Intelligent Systems and Technology (TIST);,citation_publisher=ACM;">
<meta name="citation_reference" content="citation_title=Linear and convex aggregation of density estimators;,citation_author=P. Rigollet;,citation_author=A. B. Tsybakov;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=3;,citation_volume=16;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=Exponential screening and optimal rates of sparse estimation;,citation_author=P. Rigollet;,citation_author=A. B. Tsybakov;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=2;,citation_volume=39;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Sparse estimation by exponential weighting;,citation_author=P. Rigollet;,citation_author=A. B. Tsybakov;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=27;,citation_journal_title=Statist. Sci.;">
<meta name="citation_reference" content="citation_title=Kullback-Leibler aggregation and misspecified generalized linear models;,citation_author=P. Rigollet;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=40;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Pattern recognition and neural networks;,citation_author=B. D. Ripley;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;">
<meta name="citation_reference" content="citation_title=Monte Carlo statistical methods;,citation_author=C. P. Robert;,citation_author=G. Casella;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=The Bayesian choice;,citation_author=C. P. Robert;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_series_title=Springer texts in statistics;">
<meta name="citation_reference" content="citation_title=Méthodes de Monte Carlo par chaînes de Markov;,citation_author=C. P. Robert;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_series_title=Sticatistique mathématique et probabilité. [Mathematical statistics and probability];">
<meta name="citation_reference" content="citation_title=Superquantile regression with applications to buffered reliability, uncertainty quantification, and conditional value-at-risk;,citation_author=R. T. Rockafellar;,citation_author=J. O. Royset;,citation_author=S. I. Miranda;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=234;,citation_journal_title=European J. Oper. Res.;">
<meta name="citation_reference" content="citation_title=Optimization of conditional value-at-risk;,citation_author=R. T. Rockafellar;,citation_author=S. Uryasev;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_volume=2;,citation_journal_title=Journal of Risk;">
<meta name="citation_reference" content="citation_title=Conditional value-at-risk for general loss distributions;,citation_author=R. T. Rockafellar;,citation_author=S. Uryasev;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=7;,citation_volume=26;,citation_journal_title=J. Bank. Finance;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=The fundamental risk quadrangle in risk management, optimization and statistical estimation;,citation_author=R. T. Rockafellar;,citation_author=S. Uryasev;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1-2;,citation_volume=18;,citation_journal_title=Surveys in Operations Research and Management Science;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Variational analysis;,citation_author=R. T. Rockafellar;,citation_author=R. Wets;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=317;,citation_series_title=Grundlehren der mathematischen wissenschaften [fundamental principles of mathematical sciences];">
<meta name="citation_reference" content="citation_title=Convex analysis;,citation_author=R. T. Rockafellar;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_series_title=Princeton landmarks in mathematics;">
<meta name="citation_reference" content="citation_title=Coding and information theory;,citation_author=S. Roman;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=134;,citation_series_title=Graduate texts in mathematics;">
<meta name="citation_reference" content="citation_title=Boosting of image denoising algorithms;,citation_author=Y. Romano;,citation_author=M. Elad;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=2;,citation_volume=8;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Sparse recovery under matrix uncertainty;,citation_author=M. Rosenbaum;,citation_author=A. Tsybakov;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=5;,citation_volume=38;,citation_journal_title=The Annals of Statistics;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Remarks on some nonparametric estimates of a density function;,citation_author=M. Rosenblatt;,citation_publication_date=1956;,citation_cover_date=1956;,citation_year=1956;,citation_volume=27;,citation_journal_title=Ann. Math. Statist.;">
<meta name="citation_reference" content="citation_title=Boosting as a regularized path to a maximum margin classifier;,citation_author=S. Rosset;,citation_author=J. Zhu;,citation_author=T. Hastie;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=5;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Piecewise linear regularized solution paths;,citation_author=S. Rosset;,citation_author=J. Zhu;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=3;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Fields of experts: A framework for learning image priors;,citation_author=S. Roth;,citation_author=M. J. Black;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=2;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=The group-lasso for generalized linear models: Uniqueness of solutions and efficient algorithms;,citation_author=V. Roth;,citation_author=B. Fischer;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Sparse multivariate regression with covariance estimation;,citation_author=A. J. Rothman;,citation_author=E. Levina;,citation_author=J. Zhu;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=19;,citation_journal_title=Journal of Computational and Graphical Statistics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Robust regression and outlier detection;,citation_author=P. J. Rousseeuw;,citation_author=A. M. Leroy;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;,citation_series_title=Wiley series in probability and mathematical statistics: Applied probability and statistics;">
<meta name="citation_reference" content="citation_title=Algorithm AS 307: Bivariate location depth;,citation_author=P. J. Rousseeuw;,citation_author=I. Ruts;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=4;,citation_volume=45;,citation_journal_title=J. R. Stat. Soc. Ser. C. Appl. Stat.;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Computing LTS regression for large data sets;,citation_author=P. J. Rousseeuw;,citation_author=K. Van Driessen;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=12;,citation_journal_title=Data Mining and Knowledge Discovery;">
<meta name="citation_reference" content="citation_title=Least median of squares regression;,citation_author=P. J. Rousseeuw;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_issue=388;,citation_volume=79;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Petit guide de calcul différentiel: à l’usage de la licence et de l’agrégation;,citation_author=F. Rouvière;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_series_title=Enseignement des mathématiques;">
<meta name="citation_reference" content="citation_title=Finding approximate POMDP solutions through belief compression;,citation_author=N. Roy;,citation_author=G. J. Gordon;,citation_author=S. Thrun;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_volume=23;,citation_journal_title=J. Artif. Intell. Res.;,citation_publisher=AI Access Foundation;">
<meta name="citation_reference" content="citation_title=Nonlinear total variation based noise removal algorithms;,citation_author=L. I. Rudin;,citation_author=S. Osher;,citation_author=E. Fatemi;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=1-4;,citation_volume=60;,citation_journal_title=Phys. D;,citation_publisher=Elsevier Science publishers B. V.;">
<meta name="citation_reference" content="citation_title=Real and complex analysis;,citation_author=W. Rudin;,citation_publication_date=1987;,citation_cover_date=1987;,citation_year=1987;">
<meta name="citation_reference" content="citation_title=Learning representations by back-propagating errors;,citation_author=D. E. Rumelhart;,citation_author=G. E. Hinton;,citation_author=R. J. Williams;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_issue=6088;,citation_volume=323;,citation_journal_title=Nature;,citation_publisher=Nature Publishing Group;">
<meta name="citation_reference" content="citation_title=Multivariate locally weighted least squares regression;,citation_author=D. Ruppert;,citation_author=M. P. Wand;,citation_publication_date=1994;,citation_cover_date=1994;,citation_year=1994;,citation_issue=3;,citation_volume=22;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=The impact of self-and peer-grading on student learning;,citation_author=P. M. Sadler;,citation_author=E. Good;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=11;,citation_journal_title=Educational assessment;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=On the nonasymptotic convergence of cyclic coordinate descent methods;,citation_author=A. Saha;,citation_author=A. Tewari;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=23;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Peer grading in a course on algorithms and data structures: Machine learning algorithms do not improve over simple baselines;,citation_author=M. S. M. Sajjadi;,citation_author=M. Alamgir;,citation_author=U. Luxburg;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=Proceedings of the third (2016) ACM conference on learning at scale;">
<meta name="citation_reference" content="citation_title=An efficient learning procedure for deep boltzmann machines;,citation_author=R. Salakhutdinov;,citation_author=G. Hinton;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=8;,citation_volume=24;,citation_journal_title=Neural computation;,citation_publisher=MIT Press;">
<meta name="citation_reference" content="citation_title=Image denoising using learned overcomplete representations;,citation_author=P. Sallee;,citation_author=B. A. Olshausen;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Agrégation d’estimateurs et méthodes à patch pour le débruitage d’images numériques;,citation_author=J. Salmon;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_dissertation_institution=Université Paris Diderot;">
<meta name="citation_reference" content="citation_title=Optimal aggregation of affine estimators;,citation_author=J. Salmon;,citation_author=A. S. Dalalyan;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Poisson noise reduction with non-local PCA;,citation_author=J. Salmon;,citation_author=undefined Deledalle;,citation_author=R. Willett;,citation_author=undefined Z.Harmany;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICASSP;">
<meta name="citation_reference" content="citation_title=Poisson noise reduction with non-local PCA;,citation_author=J. Salmon;,citation_author=Z. Harmany;,citation_author=undefined Deledalle;,citation_author=R. Willett;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=48;,citation_journal_title=J. Math. Imaging Vis.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=An aggregator point of view on NL-Means;,citation_author=J. Salmon;,citation_author=E. Le Pennec;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=7446;,citation_conference_title=Proceedings of the SPIE conference on mathematical imaging: Wavelet XIII;,citation_conference=SPIE;">
<meta name="citation_reference" content="citation_title=NL-Means and aggregation procedures;,citation_author=J. Salmon;,citation_author=E. Le Pennec;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=From patches to pixels in Non-Local methods: Weighted-Average reprojection;,citation_author=J. Salmon;,citation_author=Y. Strozecki;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Patch reprojections for Non Local methods;,citation_author=J. Salmon;,citation_author=Y. Strozecki;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=92;,citation_journal_title=Signal Processing;">
<meta name="citation_reference" content="citation_title=A two-stage denoising filter: The preprocessed Yaroslavsky filter;,citation_author=J. Salmon;,citation_author=R. Willett;,citation_author=E. Arias-Castro;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=SSP;">
<meta name="citation_reference" content="citation_title=Wavelet and bayesian models;,citation_author=J. Salmon;,citation_author=E. Le Pennec;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_dissertation_institution=ENSAE ParisTech et Université Paris 7-Diderot;">
<meta name="citation_reference" content="citation_title=On two parameters for denoising with Non-Local Means;,citation_author=J. Salmon;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=17;,citation_journal_title=IEEE Trans. Signal Process. Lett.;">
<meta name="citation_reference" content="citation_title=Perspectives computationnelles et statistiques pour la régression en grande dimension;,citation_author=J. Salmon;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_dissertation_institution=École Normale Supérieure Paris-Saclay;">
<meta name="citation_reference" content="citation_title=Joint quantile regression in vector-valued RKHSs;,citation_author=M. Sangnier;,citation_author=O. Fercoq;,citation_author=F. d’Alché-Buc;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Identifying groups of strongly correlated variables through smoothed ordered weighted $\ell_1$-norms;,citation_author=R. Sankaran;,citation_author=F. Bach;,citation_author=C. Bhattacharyya;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Geometric partial differential equations and image analysis;,citation_author=G. Sapiro;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;">
<meta name="citation_reference" content="citation_title=Block coordinate relaxation methods for nonparametric wavelet denoising;,citation_author=S. Sardy;,citation_author=A. G. Bruce;,citation_author=P. Tseng;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=2;,citation_volume=9;,citation_journal_title=Journal of Computational and Graphical Statistics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Parallel non-local denoising of depth maps;,citation_author=T. Schairer;,citation_author=B. Huhle;,citation_author=P. Jenke;,citation_author=W. Straßer;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=LNLA;">
<meta name="citation_reference" content="citation_title=The strength of weak learnability;,citation_author=R. E. Schapire;,citation_publication_date=1990;,citation_cover_date=1990;,citation_year=1990;,citation_volume=5;,citation_journal_title=Mach. Learn.;">
<meta name="citation_reference" content="citation_title=Reliability of an $m$-out-of-$n$ system when component failure induces higher failure rates in survivors;,citation_author=E. M. Scheuer;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=1;,citation_volume=37;,citation_journal_title=IEEE Trans. Rel.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Minimizing finite sums with the stochastic average gradient;,citation_author=M. Schmidt;,citation_author=N. Le Roux;,citation_author=F. Bach;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1309.2388;">
<meta name="citation_reference" content="citation_title=Convex bodies: The brunn–minkowski theory;,citation_author=R. Schneider;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=151;,citation_series_title=Encyclopedia of mathematics and its applications;">
<meta name="citation_reference" content="citation_title=Nonlinear component analysis as a kernel eigenvalue problem;,citation_author=B. Schölkopf;,citation_author=A. J. Smola;,citation_author=K-R. Müller;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=5;,citation_volume=10;,citation_journal_title=Neural Comput.;">
<meta name="citation_reference" content="citation_title=Learning with kernels: Support vector machines, regularization, optimization, and beyond;,citation_author=B. Schölkopf;,citation_author=A. J. Smola;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;">
<meta name="citation_reference" content="citation_title=Matrix analysis for statistics;,citation_author=J. R. Schott;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_series_title=Wiley series in probability and statistics;">
<meta name="citation_reference" content="citation_title=Estimating the dimension of a model;,citation_author=G. Schwarz;,citation_publication_date=1978;,citation_cover_date=1978;,citation_year=1978;,citation_issue=2;,citation_volume=6;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Acceleration in optimization;,citation_author=D. Scieur;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_dissertation_institution=École normale supérieure;">
<meta name="citation_reference" content="citation_title=Regularized nonlinear acceleration;,citation_author=D. Scieur;,citation_author=A. Aspremont;,citation_author=F. Bach;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Minimax-optimal classification with dyadic decision trees;,citation_author=C. Scott;,citation_author=R. D. Nowak;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=4;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Multivariate density estimation;,citation_author=D. W. Scott;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=139;">
<meta name="citation_reference" content="citation_title=Variance components;,citation_author=S. R. Searle;,citation_author=G. Casella;,citation_author=C. E. McCulloch;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=391;">
<meta name="citation_reference" content="citation_title=Linear regression analysis, 2nd edition (wiley series in probability and statistics);,citation_author=G. A. F. Seber;,citation_author=A. J. Lee;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Covariance kernels from bayesian generative models;,citation_author=M. Seeger;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Pac-bayesian generalisation error bounds for gaussian process classification;,citation_author=M. Seeger;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_volume=3;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Sparse signal approximation via nonseparable regularization;,citation_author=I. Selesnick;,citation_author=M. Farshchian;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=10;,citation_volume=65;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Non-negative matrices and Markov chains;,citation_author=E. Seneta;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Training-free, generic object detection using locally adaptive regression kernels;,citation_author=H. J. Seo;,citation_author=P. Milanfar;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=9;,citation_volume=32;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Non-parametric bayesian annotator combination;,citation_author=M. Servajean;,citation_author=R. Chailan;,citation_author=A. Joly;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_volume=436;,citation_journal_title=Information Sciences;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Crowdsourcing thousands of specialized labels: A bayesian active training approach;,citation_author=M. Servajean;,citation_author=A. Joly;,citation_author=D. Shasha;,citation_author=J. Champ;,citation_author=E. Pacitti;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=6;,citation_volume=19;,citation_journal_title=IEEE Transactions on Multimedia;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Increasing coverage in distributed search and recommendation with profile diversity;,citation_author=M. Servajean;,citation_author=E. Pacitti;,citation_author=M. Liroz-Gistau;,citation_author=S. Amer-Yahia;,citation_author=A. El Abbadi;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_inbook_title=Transactions on large-scale data-and knowledge-centered systems XXII;">
<meta name="citation_reference" content="citation_title=Distributionally robust logistic regression;,citation_author=S. Shafieezadeh-Abadeh;,citation_author=P. M. Esfahani;,citation_author=D. Kuhn;,citation_editor=C. Cortes;,citation_editor=N. D. Lawrence;,citation_editor=D. D. Lee;,citation_editor=M. Sugiyama;,citation_editor=R. Garnett;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_inbook_title=NIPS;">
<meta name="citation_reference" content="citation_title=Variable selection with error control: Another look at stability selection;,citation_author=R. D. Shah;,citation_author=R. J. Samworth;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=1;,citation_volume=75;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Gossip algorithms;,citation_author=D. Shah;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=3;,citation_journal_title=Foundations and Trends in Networking;">
<meta name="citation_reference" content="citation_title=Understanding machine learning: From theory to algorithms;,citation_author=S. Shalev-Shwartz;,citation_author=S. Ben-David;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;">
<meta name="citation_reference" content="citation_title=Pegasos: Primal Estimated sub-GrAdient SOlver for SVM;,citation_author=S. Shalev-Shwartz;,citation_author=Y. Singer;,citation_author=N. Srebro;,citation_author=A. Cotter;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=1;,citation_volume=127;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization;,citation_author=S. Shalev-Shwartz;,citation_author=T. Zhang;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1309.2375;">
<meta name="citation_reference" content="citation_title=Accelerated proximal stochastic dual coordinate ascent for regularized loss minimization;,citation_author=S. Shalev-Shwartz;,citation_author=T. Zhang;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=1;,citation_volume=155;,citation_journal_title=Math. Program.;">
<meta name="citation_reference" content="citation_title=Online learning and online convex optimization;,citation_author=S. Shalev-Shwartz;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=4;,citation_journal_title=Foundations and Trends in Machine Learning;">
<meta name="citation_reference" content="citation_title=Combining regression quantile estimators;,citation_author=K. Shan;,citation_author=Y. Yang;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=19;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Estimation in high-dimensional linear models with deterministic design matrices;,citation_author=J. Shao;,citation_author=X. Deng;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=40;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Mathematical statistics: Exercises and solutions;,citation_author=J. Shao;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;">
<meta name="citation_reference" content="citation_title=An introduction to support vector machines : And other kernel-based learning methods;,citation_author=J. Shawe-Taylor;,citation_author=N. Cristianini;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;">
<meta name="citation_reference" content="citation_title=A PAC analysis of a bayesian estimator;,citation_author=J. Shawe-Taylor;,citation_author=R. C. Williamson;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_conference_title=COLT;,citation_conference=ACM;">
<meta name="citation_reference" content="citation_title=Outlier detection using nonconvex penalized regression;,citation_author=Y She;,citation_author=A. B. Owen;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=494;,citation_volume=106;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Thresholding-based iterative selection procedures for model selection and shrinkage;,citation_author=Y. She;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=3;,citation_journal_title=Electron. J. Stat.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=A simple and efficient algorithm for gene selection using sparse logistic regression;,citation_author=S. K. Shevade;,citation_author=S. S. Keerthi;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=17;,citation_volume=19;,citation_journal_title=Bioinformatics;,citation_publisher=Oxford Univ Press;">
<meta name="citation_reference" content="citation_title=A primer on coordinate descent algorithms;,citation_author=undefined M. Shi;,citation_author=S. Tu;,citation_author=Y. Xu;,citation_author=W. Yin;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=Simultaneous safe screening of features and samples in doubly sparse modeling;,citation_author=A. Shibagaki;,citation_author=M. Karasuyama;,citation_author=K. Hatano;,citation_author=I. Takeuchi;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=48;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Regularization path of cross-validation error lower bounds;,citation_author=A. Shibagaki;,citation_author=Y. Suzuki;,citation_author=M. Karasuyama;,citation_author=I. Takeuchi;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=AI models collapse when trained on recursively generated data;,citation_author=Ilia Shumailov;,citation_author=Zakhar Shumaylov;,citation_author=Yiren Zhao;,citation_author=Nicolas Papernot;,citation_author=Ross Anderson;,citation_author=Yarin Gal;,citation_publication_date=2024;,citation_cover_date=2024;,citation_year=2024;,citation_issue=8022;,citation_volume=631;,citation_journal_title=Nature;,citation_publisher=Nature Publishing Group UK London;">
<meta name="citation_reference" content="citation_title=Time series analysis and its applications: With r examples;,citation_author=R. H. Shumway;,citation_author=D. S. Stoffer;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;">
<meta name="citation_reference" content="citation_title=Density estimation for statistics and data analysis;,citation_author=B. W. Silverman;,citation_publication_date=1986;,citation_cover_date=1986;,citation_year=1986;,citation_series_title=Monographs on statistics and applied probability;">
<meta name="citation_reference" content="citation_title=A sparse-group lasso;,citation_author=N. Simon;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=2;,citation_volume=22;,citation_journal_title=J. Comput. Graph. Statist.;">
<meta name="citation_reference" content="citation_title=Standardization and the Group Lasso penalty;,citation_author=N. Simon;,citation_author=R. Tibshirani;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=3;,citation_volume=22;,citation_journal_title=Stat. Sin.;">
<meta name="citation_reference" content="citation_title=Universal linear prediction by model order weighting;,citation_author=A. C. Singer;,citation_author=M. Feder;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=47;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Diffusion interpretation of nonlocal neighborhood filters for signal denoising.;,citation_author=A. Singer;,citation_author=Y. Shkolnisky;,citation_author=B. Nadler;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=2;,citation_journal_title=SIAM J. Imaging Sci.;">
<meta name="citation_reference" content="citation_title=Batch and on-line parameter estimation of gaussian mixtures based on the joint entropy;,citation_author=Y. Singer;,citation_author=M. K. Warmuth;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=A unified view of matrix factorization models;,citation_author=A. P. Singh;,citation_author=G. J. Gordon;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_journal_title=Machine Learning and Knowledge Discovery in Databases;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Relational learning via collective matrix factorization;,citation_author=A. P. Singh;,citation_author=G. J. Gordon;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=Proceeding of the 14th ACM SIGKDD international conference on knowledge discovery and data mining;">
<meta name="citation_reference" content="citation_title=The algorithm design manual;,citation_author=S. S. Skiena;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_volume=1;">
<meta name="citation_reference" content="citation_title=Non-negative least squares for high-dimensional linear models: Consistency and sparse recovery without regularization;,citation_author=M. Slawski;,citation_author=M. Hein;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=arXiv preprint arXiv:1205.0953;">
<meta name="citation_reference" content="citation_title=SUSAN-a new approach to low level image processing;,citation_author=S. M. Smith;,citation_author=J. M. Brady;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;,citation_issue=1;,citation_volume=23;,citation_journal_title=Int. J. Comput. Vision;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Linearly combining density estimators via stacking;,citation_author=P. Smyth;,citation_author=D. H. Wolpert;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_issue=1-2;,citation_volume=36;,citation_journal_title=Mach. Learn.;,citation_publisher=Kluwer Academic publishers;">
<meta name="citation_reference" content="citation_title=Cheap and fast - but is it good? Evaluating non-expert annotations for natural language tasks;,citation_author=Rion Snow;,citation_author=Brendan O’Connor;,citation_author=Daniel Jurafsky;,citation_author=Andrew Ng;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=Proceedings of the 2008 conference on empirical methods in natural language processing;">
<meta name="citation_reference" content="citation_title=A sure-fired way to choose smoothing parameters in ill-conditioned inverse problems;,citation_author=V. Solo;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_volume=3;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Improved deep metric learning with multi-class n-pair loss objective;,citation_author=Kihyuk Sohn;,citation_editor=Daniel D. Lee;,citation_editor=Masashi Sugiyama;,citation_editor=Ulrike Luxburg;,citation_editor=Isabelle Guyon;,citation_editor=Roman Garnett;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NeurIPS;">
<meta name="citation_reference" content="citation_title=A unified view of exact continuous penalties for $\ell_2$-$\ell_0$ minimization;,citation_author=E. Soubies;,citation_author=L. Blanc-Féraud;,citation_author=G. Aubert;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=3;,citation_volume=27;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=Relaxation methods in engineering science : A treatise on approximate computation;,citation_author=R. V. Southwell;,citation_publication_date=1941;,citation_cover_date=1941;,citation_year=1941;,citation_issue=265;,citation_volume=25;,citation_journal_title=The Mathematical Gazette;,citation_publisher=Mathematical Association;">
<meta name="citation_reference" content="citation_title=Enhancing images painted on manifolds;,citation_author=A. Spira;,citation_author=R. Kimmel;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_conference_title=Scale space and PDF methods in computer vision;">
<meta name="citation_reference" content="citation_title=Estimation of a function with discontinuities via local polynomial fit with an adaptive window choice;,citation_author=V. G. Spokoiny;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_issue=4;,citation_volume=26;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Real-time online singing voice separation from monaural recordings using robust low-rank modeling;,citation_author=P. Sprechmann;,citation_author=A. Bronstein;,citation_author=G. Sapiro;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ISMIR;">
<meta name="citation_reference" content="citation_title=C-hilasso: A collaborative hierarchical sparse modeling framework;,citation_author=P. Sprechmann;,citation_author=I. Ramirez;,citation_author=G. Sapiro;,citation_author=Y. C. Eldar;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=9;,citation_volume=59;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=$\ell_1$-penalization for mixture regression models;,citation_author=N. Städler;,citation_author=P. Bühlmann;,citation_author=S. Geer;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=19;,citation_journal_title=TEST;">
<meta name="citation_reference" content="citation_title=The curvelet transform for image denoising;,citation_author=undefined Starck;,citation_author=E. J. Candès;,citation_author=D. L. Donoho;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_issue=6;,citation_volume=11;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Inadmissibility of the usual estimator for the mean of a multivariate normal distribution;,citation_author=C. Stein;,citation_publication_date=1956;,citation_cover_date=1956;,citation_year=1956;,citation_volume=1;,citation_conference_title=Proceeding of the 3rd Berkeley Symposium on Mathematical Statistics and Probability;">
<meta name="citation_reference" content="citation_title=Estimation of the mean of a multivariate distribution;,citation_author=C. M. Stein;,citation_publication_date=1973;,citation_cover_date=1973;,citation_year=1973;,citation_conference_title=Proc. Prague symp. Asymptotic statist.;">
<meta name="citation_reference" content="citation_title=Estimation of the mean of a multivariate normal distribution;,citation_author=C. M. Stein;,citation_publication_date=1981;,citation_cover_date=1981;,citation_year=1981;,citation_issue=6;,citation_volume=9;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Sur la division des corps matériels en parties;,citation_author=H. Steinhaus;,citation_publication_date=1956;,citation_cover_date=1956;,citation_year=1956;,citation_volume=4;,citation_journal_title=Bull. Acad. Polon. Sci. Cl. III.;">
<meta name="citation_reference" content="citation_title=Safe adaptive importance sampling;,citation_author=S. Stich;,citation_author=A. Raj;,citation_author=M. Jaggi;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Estimating WAIS IQ from Shipley Scale scores: Another cross-validation;,citation_author=L. R. A. Stone;,citation_author=J. C. Ramer;,citation_publication_date=1965;,citation_cover_date=1965;,citation_year=1965;,citation_issue=3;,citation_volume=21;,citation_journal_title=Journal of clinical psychology;,citation_publisher=John Wiley &amp;amp;amp; Sons;">
<meta name="citation_reference" content="citation_title=Introduction to linear algebra;,citation_author=G. Strang;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;">
<meta name="citation_reference" content="citation_title=Introduction to linear algebra;,citation_author=G. Strang;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Edge-preserving and scale-dependent properties of total variation regularization;,citation_author=D. M. Strong;,citation_author=T. F. Chan;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=6;,citation_volume=19;,citation_journal_title=Inverse Problems;">
<meta name="citation_reference" content="citation_title=Asymptotic confidence regions for high-dimensional structured sparsity;,citation_author=B. Stucky;,citation_author=S. Geer;,citation_publication_date=2018;,citation_cover_date=2018;,citation_year=2018;,citation_issue=8;,citation_volume=66;,citation_journal_title=IEEE Trans. Signal Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Using SeDuMi 1.02, a MATLAB toolbox for optimization over symmetric cones;,citation_author=J. F. Sturm;,citation_publication_date=1999;,citation_cover_date=1999;,citation_year=1999;,citation_volume=11–12;,citation_journal_title=Optimization Methods and Software;">
<meta name="citation_reference" content="citation_title=False discoveries occur early on the lasso path;,citation_author=W. Su;,citation_author=M. Bogdan;,citation_author=E. J. Candès;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=Ann. Statist.;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Are we there yet? Manifold identification of gradient-related proximal methods;,citation_author=Y. Sun;,citation_author=H. Jeong;,citation_author=J. Nutini;,citation_author=M. Schmidt;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_conference_title=AISTATS;">
<meta name="citation_reference" content="citation_title=Comments on: $\ell_1$-penalization for mixture regression models;,citation_author=T. Sun;,citation_author=undefined Zhang;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=19;,citation_journal_title=TEST;">
<meta name="citation_reference" content="citation_title=Scaled sparse linear regression;,citation_author=T. Sun;,citation_author=undefined Zhang;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=99;,citation_journal_title=Biometrika;">
<meta name="citation_reference" content="citation_title=Sparse matrix inversion with scaled lasso;,citation_author=T. Sun;,citation_author=undefined Zhang;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=14;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Regularization on graphs with function-adapted diffusion processes;,citation_author=A. D. Szlam;,citation_author=M. Maggioni;,citation_author=R. R. Coifman;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Kernel regression for image processing and reconstruction;,citation_author=H. Takeda;,citation_author=S. Farsiu;,citation_author=P. Milanfar;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Nonparametric quantile estimation;,citation_author=I. Takeuchi;,citation_author=Q. V. Le;,citation_author=T. D. Sears;,citation_author=A. J. Smola;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=Jul;,citation_volume=7;,citation_journal_title=Journal of Machine Learning Research;">
<meta name="citation_reference" content="citation_title=How to SAIF-ly boost denoising performance;,citation_author=H. Talebi;,citation_author=X. Zhu;,citation_author=P. Milanfar;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=22;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Global image denoising;,citation_author=H. Talebi;,citation_author=P. Milanfar;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=2;,citation_volume=23;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=Nearly optimal private lasso;,citation_author=K. Talwar;,citation_author=A. G. Thakurta;,citation_author=L. Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Near minimax line spectral estimation;,citation_author=G. Tang;,citation_author=B. N. Bhaskar;,citation_author=B. Recht;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_issue=1;,citation_volume=61;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Compressed sensing off the grid;,citation_author=G. Tang;,citation_author=B. N. Bhaskar;,citation_author=P. Shah;,citation_author=B. Recht;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=11;,citation_volume=59;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Principal components for non-local means image denoising;,citation_author=T. Tasdizen;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Principal neighborhood dictionaries for nonlocal means image denoising;,citation_author=T. Tasdizen;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=12;,citation_volume=18;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE Press;">
<meta name="citation_reference" content="citation_title=The geometry of signal and image patch-sets;,citation_author=K. M. Taylor;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_dissertation_institution=University of Colorado at Boulder;">
<meta name="citation_reference" content="citation_title=Deconvolution with the $\ell_1$ norm;,citation_author=H. L. Taylor;,citation_author=S. C. Banks;,citation_author=J. F. McCoy;,citation_publication_date=1979;,citation_cover_date=1979;,citation_year=1979;,citation_issue=1;,citation_volume=44;,citation_journal_title=Geophysics;,citation_publisher=Society of Exploration Geophysicists;">
<meta name="citation_reference" content="citation_title=A random walk on image patches;,citation_author=K. M. Taylor;,citation_author=F. G. Meyer;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_journal_title=Arxiv preprint arXiv:1107.0414;">
<meta name="citation_reference" content="citation_title=TensorFlow: Large-scale machine learning on heterogeneous systems;,citation_author=M. Abadi;,citation_author=A. Agarwal;,citation_author=P. Barham;,citation_author=E. Brevdo;,citation_author=Z. Chen;,citation_author=C. Citro;,citation_author=G. S. Corrado;,citation_author=A. Davis;,citation_author=J. Dean;,citation_author=M. Devin;,citation_author=S. Ghemawat;,citation_author=I. Goodfellow;,citation_author=A. Harp;,citation_author=G. Irving;,citation_author=M. Isard;,citation_author=Y. Jia;,citation_author=R. Jozefowicz;,citation_author=L. Kaiser;,citation_author=M. Kudlur;,citation_author=J. Levenberg;,citation_author=D. Mané;,citation_author=R. Monga;,citation_author=S. Moore;,citation_author=D. Murray;,citation_author=C. Olah;,citation_author=M. Schuster;,citation_author=J. Shlens;,citation_author=B. Steiner;,citation_author=I. Sutskever;,citation_author=K. Talwar;,citation_author=P. Tucker;,citation_author=V. Vanhoucke;,citation_author=V. Vasudevan;,citation_author=F. Viégas;,citation_author=O. Vinyals;,citation_author=P. Warden;,citation_author=M. Wattenberg;,citation_author=M. Wicke;,citation_author=Y. Yu;,citation_author=X. Zheng;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;">
<meta name="citation_reference" content="citation_title=Strong rules for discarding predictors in lasso-type problems;,citation_author=R. Tibshirani;,citation_author=J. Bien;,citation_author=J. Friedman;,citation_author=T. J. Hastie;,citation_author=N. Simon;,citation_author=J. Taylor;,citation_author=R. J. Tibshirani;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=74;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Sparsity and smoothness via the fused LASSO;,citation_author=R. Tibshirani;,citation_author=M. A. Saunders;,citation_author=S. Rosset;,citation_author=J. Zhu;,citation_author=K. Knight;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_volume=67;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=The solution path of the generalized lasso;,citation_author=R. J. Tibshirani;,citation_author=J. Taylor;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=3;,citation_volume=39;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Degrees of freedom in lasso problems;,citation_author=R. J. Tibshirani;,citation_author=J. Taylor;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=2;,citation_volume=40;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Estimating the number of clusters in a data set via the gap statistic;,citation_author=R. Tibshirani;,citation_author=G. Walther;,citation_author=T. J. Hastie;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=2;,citation_volume=63;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The lasso problem and uniqueness;,citation_author=R. J. Tibshirani;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_volume=7;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=Dykstra’s Algorithm, ADMM, and Coordinate Descent: Connections, Insights, and Extensions;,citation_author=R. J. Tibshirani;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Regression shrinkage and selection via the lasso;,citation_author=R. Tibshirani;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_issue=1;,citation_volume=58;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=On the stability of inverse problems;,citation_author=A. N. Tikhonov;,citation_publication_date=1943;,citation_cover_date=1943;,citation_year=1943;,citation_volume=39;,citation_journal_title=Dokl. Akad. Nauk SSSR;">
<meta name="citation_reference" content="citation_title=Sparse bayesian learning and the relevance vector machine;,citation_author=M. E. Tipping;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=1;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Probabilistic low-rank matrix completion with adaptive spectral regularization algorithms;,citation_author=A. Todeschini;,citation_author=F. Caron;,citation_author=M. Chavent;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Bilateral filtering for gray and color images;,citation_author=C. Tomasi;,citation_author=R. Manduchi;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_conference_title=ICCV;">
<meta name="citation_reference" content="citation_title=Numerical linear algebra;,citation_author=L. N. Trefethen;,citation_author=D. III Bau;,citation_publication_date=1997;,citation_cover_date=1997;,citation_year=1997;">
<meta name="citation_reference" content="citation_title=Greed is good: Algorithmic results for sparse approximation;,citation_author=J. A. Tropp;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=10;,citation_volume=50;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Just relax: Convex programming methods for identifying sparse signals in noise;,citation_author=J. A. Tropp;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=3;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=User-friendly tail bounds for sums of random matrices;,citation_author=J. A. Tropp;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=12;,citation_journal_title=Found. Comput. Math.;">
<meta name="citation_reference" content="citation_title=Asymptotic properties of kernel estimators based on local medians;,citation_author=Y. K. Truong;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=2;,citation_volume=17;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Image denoising and registration by PDE’s on the space of patches;,citation_author=D. Tschumperlé;,citation_author=L. Brun;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=LNLA;">
<meta name="citation_reference" content="citation_title=Non-local image smoothing by applying anisotropic diffusion PDE’s in the space of patches;,citation_author=D. Tschumperlé;,citation_author=L. Brun;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Block-coordinate gradient descent method for linearly constrained nonsmooth separable optimization;,citation_author=P. Tseng;,citation_author=S. Yun;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=3;,citation_volume=140;,citation_journal_title=J. Optim. Theory Appl.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Convergence of a block coordinate descent method for nondifferentiable minimization;,citation_author=P. Tseng;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=3;,citation_volume=109;,citation_journal_title=J. Optim. Theory Appl.;">
<meta name="citation_reference" content="citation_title=Dual coordinate ascent methods for non-strictly convex minimization;,citation_author=P. Tseng;,citation_publication_date=1993;,citation_cover_date=1993;,citation_year=1993;,citation_issue=1;,citation_volume=59;,citation_journal_title=Math. Program.;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Push-Sum distributed dual averaging for convex optimization;,citation_author=K. Tsianos;,citation_author=S. Lawlor;,citation_author=M. Rabbat;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=CDC;">
<meta name="citation_reference" content="citation_title=Problems in decentralized decision making and computation;,citation_author=J. N. Tsitsiklis;,citation_publication_date=1984;,citation_cover_date=1984;,citation_year=1984;,citation_dissertation_institution=Massachusetts Institute of Technology;">
<meta name="citation_reference" content="citation_title=Optimal rates of aggregation;,citation_author=A. B. Tsybakov;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=COLT;">
<meta name="citation_reference" content="citation_title=Introduction à l’estimation non-paramétrique;,citation_author=A. B. Tsybakov;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_volume=41;,citation_series_title=Mathématiques &amp;amp;amp; applications (berlin) [mathematics &amp; applications];">
<meta name="citation_reference" content="citation_title=Introduction to nonparametric estimation;,citation_author=A. B. Tsybakov;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Optimal orders of accuracy of the estimation of nonsmooth images;,citation_author=A. B. Tsybakov;,citation_publication_date=1989;,citation_cover_date=1989;,citation_year=1989;,citation_issue=3;,citation_volume=25;,citation_journal_title=Problemy Peredachi Informatsii;">
<meta name="citation_reference" content="citation_title=Mathematics and the picturing of data;,citation_author=J. W. Tukey;,citation_publication_date=1975;,citation_cover_date=1975;,citation_year=1975;,citation_volume=2;,citation_conference_title=Proceedings of the international congress of mathematicians, vancouver, 1975;">
<meta name="citation_reference" content="citation_title=Exploratory data analysis;,citation_author=J. W. Tukey;,citation_publication_date=1977;,citation_cover_date=1977;,citation_year=1977;">
<meta name="citation_reference" content="citation_title=Simultaneous variable selection;,citation_author=B. A. Turlach;,citation_author=W. N. Venables;,citation_author=S. J. Wright;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=3;,citation_volume=47;,citation_journal_title=Technometrics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Statistique appliquée;,citation_author=A. B. Tsybakov;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;">
<meta name="citation_reference" content="citation_title=Local smoothness in variance reduced optimization;,citation_author=D. Vainsencher;,citation_author=H. Liu;,citation_author=T. Zhang;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Local behavior of sparse analysis regularization: Applications to risk estimation;,citation_author=S. Vaiter;,citation_author=undefined Deledalle;,citation_author=G. Peyré;,citation_author=C. Dossal;,citation_author=J. Fadili;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=35;,citation_journal_title=Appl. Comput. Harmon. Anal.;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Robust sparse analysis regularization;,citation_author=S. Vaiter;,citation_author=G. Peyré;,citation_author=C. Dossal;,citation_author=J. Fadili;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=59;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Mauvaises pensées et autres;,citation_author=P. Valéry;,citation_publication_date=1942;,citation_cover_date=1942;,citation_year=1942;">
<meta name="citation_reference" content="citation_title=Minimum volume ellipsoid;,citation_author=S. Van Aelst;,citation_author=P. J. Rousseeuw;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=1;,citation_volume=1;,citation_journal_title=Wiley Interdisciplinary Reviews: Computational Statistics;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=On asymptotically optimal confidence regions and tests for high-dimensional models;,citation_author=S. Geer;,citation_author=P. Bühlmann;,citation_author=Y. Ritov;,citation_author=R. Dezeure;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=42;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=On the conditions used to prove oracle results for the Lasso;,citation_author=S. Geer;,citation_author=P. Bühlmann;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=3;,citation_journal_title=Electron. J. Stat.;">
<meta name="citation_reference" content="citation_title=The lasso, correlated design, and improved oracle inequalities;,citation_author=S. Geer;,citation_author=J. Lederer;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_inbook_title=From probability to statistics and back: High-dimensional models and processes–a festschrift in honor of jon a. wellner;">
<meta name="citation_reference" content="citation_title=Empirical processes in m-estimation;,citation_author=S. A. Geer;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;">
<meta name="citation_reference" content="citation_title=Estimation and testing under sparsity;,citation_author=S. Geer;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_volume=2159;,citation_series_title=Lecture notes in mathematics;">
<meta name="citation_reference" content="citation_title=$\chi$ 2-confidence sets in high-dimensional regression;,citation_author=S. Geer;,citation_author=B. Stucky;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_inbook_title=Statistical analysis for high-dimensional data;">
<meta name="citation_reference" content="citation_title=Probing transcription factor combinatorics in different promoter classes and in enhancers;,citation_author=J. Vandel;,citation_author=O. Cassan;,citation_author=S. Lèbre;,citation_author=C. H. Lecellier;,citation_author=L. Bréhélin;,citation_publication_date=2019;,citation_cover_date=2019;,citation_year=2019;,citation_issue=1;,citation_volume=20;,citation_journal_title=BMC Genomics;">
<meta name="citation_reference" content="citation_title=Visualizing data using t-SNE;,citation_author=L. Maaten;,citation_author=G. Hinton;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=Nov;,citation_volume=9;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Python data science handbook;,citation_author=J. VanderPlas;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;">
<meta name="citation_reference" content="citation_title=Weak convergence and empirical processes;,citation_author=A. W. Vaart;,citation_author=Jon A. Wellner;,citation_publication_date=1996;,citation_cover_date=1996;,citation_year=1996;,citation_series_title=Springer series in statistics;">
<meta name="citation_reference" content="citation_title=Asymptotic statistics;,citation_author=A. W. Vaart;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_series_title=Cambridge series in statistical and probabilistic mathematics;">
<meta name="citation_reference" content="citation_title=SURE-based Non-Local Means;,citation_author=D. Van De Ville;,citation_author=M. Kocher;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_volume=16;,citation_journal_title=IEEE Trans. Signal Process. Lett.;">
<meta name="citation_reference" content="citation_title=Non-local means with dimensionality reduction and SURE-based parameter selection;,citation_author=D. Van De Ville;,citation_author=M. Kocher;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=99;,citation_volume=99;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Local mode filtering;,citation_author=J. Weijer;,citation_author=R. Boomgaard;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=2;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=Statistical learning theory;,citation_author=V. N. Vapnik;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;">
<meta name="citation_reference" content="citation_title=Small-sample brain mapping: Sparse recovery on spatially correlated designs with randomization and clustering;,citation_author=G. Varoquaux;,citation_author=A. Gramfort;,citation_author=B. Thirion;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Rapid object detection using a boosted cascade of simple features;,citation_author=P. Viola;,citation_author=M. Jones;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_volume=1;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=SimpleSVM;,citation_author=S. V. N. Vishwanathan;,citation_author=A. J. Smola;,citation_author=M. N. Murty;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Theory of Games and Economic Behavior;,citation_author=J. Neumann;,citation_author=O. Morgenstern;,citation_publication_date=1944;,citation_cover_date=1944;,citation_year=1944;">
<meta name="citation_reference" content="citation_title=A splitting algorithm for dual monotone inclusions involving cocoercive operators;,citation_author=B. C. Vũ;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=3;,citation_volume=38;,citation_journal_title=Advances in Computational Mathematics;,citation_publisher=Springer;">
<meta name="citation_reference" content="citation_title=Bridge estimators and the adaptive Lasso under heteroscedasticity;,citation_author=J. Wagener;,citation_author=H. Dette;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=21;,citation_journal_title=Math. Methods Statist.;">
<meta name="citation_reference" content="citation_title=Decentralized frank–wolfe algorithm for convex and nonconvex problems;,citation_author=undefined Wai;,citation_author=J. Lafond;,citation_author=A. Scaglione;,citation_author=E. Moulines;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_issue=11;,citation_volume=62;,citation_journal_title=IEEE Transactions on Automatic Control;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Sharp thresholds for high-dimensional and noisy sparsity recovery using $\ell_1$-Constrained quadratic programming (lasso);,citation_author=M. J. Wainwright;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5;,citation_volume=55;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Kernel smoothing;,citation_author=M. P. Wand;,citation_author=M. C. Jones;,citation_publication_date=1995;,citation_cover_date=1995;,citation_year=1995;,citation_volume=60;,citation_series_title=Monographs on statistics and applied probability;">
<meta name="citation_reference" content="citation_title=Image quality assessment: From error visibility to structural similarity;,citation_author=Z. Wang;,citation_author=A. C. Bovik;,citation_author=H. R. Sheikh;,citation_author=E. P. Simoncelli;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=4;,citation_volume=13;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Projection onto the probability simplex: An efficient algorithm with a simple proof, and an application;,citation_author=W. Wang;,citation_author=M. Carreira-Perpiñán;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_journal_title=arXiv preprint arXiv:1309.1541;">
<meta name="citation_reference" content="citation_title=Fast non-local algorithm for image denoising;,citation_author=J. Wang;,citation_author=Y-W. Guo;,citation_author=Y. Ying;,citation_author=Y-L. Liu;,citation_author=Q-S. Peng;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Trend filtering on graphs;,citation_author=undefined Wang;,citation_author=J. Sharpnack;,citation_author=A. Smola;,citation_author=R. J. Tibshirani;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1410.7690;">
<meta name="citation_reference" content="citation_title=Lasso screening rules via dual polytope projection;,citation_author=J. Wang;,citation_author=P. Wonka;,citation_author=J. Ye;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=arXiv preprint arXiv:1211.3966;">
<meta name="citation_reference" content="citation_title=Two-layer feature reduction for sparse-group lasso via decomposition of convex sets;,citation_author=J. Wang;,citation_author=J. Ye;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=arXiv preprint arXiv:1410.4210;">
<meta name="citation_reference" content="citation_title=Multi-layer feature reduction for tree structured group lasso via hierarchical projection;,citation_author=J. Wang;,citation_author=J. Ye;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=A safe screening rule for sparse logistic regression;,citation_author=J. Wang;,citation_author=J. Zhou;,citation_author=J. Liu;,citation_author=P. Wonka;,citation_author=J. Ye;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Lasso screening rules via dual polytope projection;,citation_author=J. Wang;,citation_author=J. Zhou;,citation_author=P. Wonka;,citation_author=J. Ye;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=High-dimensional variable selection;,citation_author=L. Wasserman;,citation_author=K. Roeder;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=5A;,citation_volume=37;,citation_journal_title=Ann. Statist.;,citation_publisher=The Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=All of Nonparametric Statistics (springer texts in statistics);,citation_author=L. Wasserman;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;">
<meta name="citation_reference" content="citation_title=Smooth regression analysis;,citation_author=G. S. Watson;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_issue=4;,citation_volume=26;,citation_journal_title=Sankhya: The Indian Journal of Statistics, Series A;,citation_publisher=Indian Statistical Institute;">
<meta name="citation_reference" content="citation_title=Characterization of the subdifferential of some matrix norms;,citation_author=G. A. Watson;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_volume=170;,citation_journal_title=Linear Algebra and its Applications;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Estimation of the covariance structure of heavy-tailed distributions;,citation_author=X. Wei;,citation_author=S. Minsker;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Distributed alternating direction method of multipliers;,citation_author=E. Wei;,citation_author=A. Ozdaglar;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=CDC;">
<meta name="citation_reference" content="citation_title=On the O(1/k) convergence of asynchronous distributed alternating direction method of multipliers;,citation_author=E. Wei;,citation_author=A. Ozdaglar;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=IEEE GlobalSIP;">
<meta name="citation_reference" content="citation_title=Anisotropic diffusion in image processing;,citation_author=J. Weickert;,citation_publication_date=1998;,citation_cover_date=1998;,citation_year=1998;,citation_series_title=European consortium for mathematics in industry;">
<meta name="citation_reference" content="citation_title=Universal discrete denoising: Known channel;,citation_author=T. Weissman;,citation_author=E. Ordentlich;,citation_author=G. Seroussi;,citation_author=S. Verdú;,citation_author=M. J. Weinberger;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=1;,citation_volume=51;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Sur le point pour lequel la somme des distances de $n$ points donnés est minimum;,citation_author=E. Weiszfeld;,citation_publication_date=1937;,citation_cover_date=1937;,citation_year=1937;,citation_volume=43;,citation_journal_title=Tohoku Mathematical Journal, First Series;">
<meta name="citation_reference" content="citation_title=A simple automatic derivative evaluation program;,citation_author=R. E. Wengert;,citation_publication_date=1964;,citation_cover_date=1964;,citation_year=1964;,citation_issue=8;,citation_volume=7;,citation_journal_title=Communications of the ACM;,citation_publisher=ACM New York, NY, USA;">
<meta name="citation_reference" content="citation_title=Probability plotting methods for the analysis for the analysis of data;,citation_author=M. B. Wilk;,citation_author=R. Gnanadesikan;,citation_publication_date=1968;,citation_cover_date=1968;,citation_year=1968;,citation_issue=1;,citation_volume=55;,citation_journal_title=Biometrika;,citation_publisher=Oxford University Press;">
<meta name="citation_reference" content="citation_title=Platelets: A multiscale approach for recovering edges and surfaces in photon-limited medical imaging;,citation_author=R. Willett;,citation_author=R. D. Nowak;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=22;,citation_journal_title=IEEE Trans. Med. Imag.;">
<meta name="citation_reference" content="citation_title=Fast multiresolution photon-limited image reconstruction;,citation_author=R. Willett;,citation_author=R. D. Nowak;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_conference_title=Proc. IEEE int. Sym. Biomedical imaging — ISBI&nbsp;’04;">
<meta name="citation_reference" content="citation_title=Multiscale Analysis of Photon-Limited Astronomical Images;,citation_author=R. Willett;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_conference_title=Statistical challenges in modern astronomy (SCMA) IV;">
<meta name="citation_reference" content="citation_title=Probability with martingales;,citation_author=D. Williams;,citation_publication_date=1991;,citation_cover_date=1991;,citation_year=1991;,citation_series_title=Cambridge mathematical textbooks;">
<meta name="citation_reference" content="citation_title=Estimating the location and orientation of complex, correlated neural activity using MEG;,citation_author=D. P. Wipf;,citation_author=J. P. Owen;,citation_author=H. Attias;,citation_author=K. Sekihara;,citation_author=S. S. Nagarajan;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=The generalised product moment distribution in samples from a normal multivariate population;,citation_author=J. Wishart;,citation_publication_date=1928;,citation_cover_date=1928;,citation_year=1928;,citation_journal_title=Biometrika;,citation_publisher=JSTOR;">
<meta name="citation_reference" content="citation_title=Expressions for the distribution and percentiles of the sums and products of chi-squares;,citation_author=C. S. Withers;,citation_author=S. Nadarajah;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_journal_title=Statistics;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Iteratively reweighted least squares: Algorithms, convergence analysis, and numerical comparisons;,citation_author=R. Wolke;,citation_author=H. Schwetlick;,citation_publication_date=1988;,citation_cover_date=1988;,citation_year=1988;,citation_issue=5;,citation_volume=9;,citation_journal_title=SIAM Journal on Scientific and Statistical Computing;">
<meta name="citation_reference" content="citation_title=Stacked generalization;,citation_author=D. H. Wolpert;,citation_publication_date=1992;,citation_cover_date=1992;,citation_year=1992;,citation_issue=2;,citation_volume=5;,citation_journal_title=Neural Networks;">
<meta name="citation_reference" content="citation_title=Sparse reconstruction by separable approximation;,citation_author=S. J. Wright;,citation_author=R. D. Nowak;,citation_author=M. A. T. Figueiredo;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_issue=7;,citation_volume=57;,citation_journal_title=IEEE Trans. Signal Process.;">
<meta name="citation_reference" content="citation_title=Mechanical TA: Partially automated high-stakes peer grading;,citation_author=J. R. Wright;,citation_author=C. Thornton;,citation_author=K. Leyton-Brown;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=Proceedings of the 46th ACM technical symposium on computer science education;">
<meta name="citation_reference" content="citation_title=Accelerated block-coordinate relaxation for regularized optimization;,citation_author=S. J. Wright;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=1;,citation_volume=22;,citation_journal_title=SIAM J. Optim.;">
<meta name="citation_reference" content="citation_title=Coordinate descent algorithms for lasso penalized regression;,citation_author=T. T. Wu;,citation_author=K. Lange;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_journal_title=Ann. Appl. Stat.;">
<meta name="citation_reference" content="citation_title=Fast lasso screening tests based on correlations;,citation_author=Z. J. Xiang;,citation_author=P. J. Ramadge;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_conference_title=ICASSP;">
<meta name="citation_reference" content="citation_title=Screening tests for lasso problems;,citation_author=Z. J. Xiang;,citation_author=Y. Wang;,citation_author=P. J. Ramadge;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_issue=99;,citation_volume=PP;,citation_journal_title=IEEE Trans. Pattern Anal. Mach. Intell.;">
<meta name="citation_reference" content="citation_title=Learning sparse representations of high dimensional data on large scale dictionaries;,citation_author=Z. J. Xiang;,citation_author=H. Xu;,citation_author=P. J. Ramadge;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Dual averaging methods for regularized stochastic learning and online optimization;,citation_author=L. Xiao;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_volume=11;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Robust regression and lasso;,citation_author=H. Xu;,citation_author=C. Caramanis;,citation_author=S. Mannor;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=7;,citation_volume=56;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Linear Total Variation Approximate Regularized Nuclear Norm Optimization for Matrix Completion;,citation_author=H. Xu;,citation_author=W. Jiasong;,citation_author=W. Lu;,citation_author=C. Yang;,citation_author=L. Senhadji;,citation_author=H. Shu;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=Abstr. Appl. Anal.;">
<meta name="citation_reference" content="citation_title=Iterative regularization and nonlinear inverse scale space applied to wavelet-based denoising;,citation_author=J. Xu;,citation_author=S. Osher;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=2;,citation_volume=16;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Three structural results on the lasso problem;,citation_author=P. Xu;,citation_author=P. J. Ramadge;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_conference_title=ICASSP;">
<meta name="citation_reference" content="citation_title=Heterogeneous multitask learning with joint sparsity constraints;,citation_author=X. Yang;,citation_author=S. Kim;,citation_author=E. P. Xing;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Seismic data reconstruction via matrix completion;,citation_author=Y. Yang;,citation_author=J. Ma;,citation_author=S. Osher;,citation_publication_date=2013;,citation_cover_date=2013;,citation_year=2013;,citation_issue=4;,citation_volume=7;,citation_journal_title=Inverse Probl. Imaging;">
<meta name="citation_reference" content="citation_title=Deep ADMM-Net for Compressive Sensing MRI;,citation_author=Y. Yang;,citation_author=J. Sun;,citation_author=H. Li;,citation_author=Z. Xu;,citation_publication_date=2016;,citation_cover_date=2016;,citation_year=2016;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Combining different procedures for adaptive regression;,citation_author=Y. Yang;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1;,citation_volume=74;,citation_journal_title=J. Multivariate Anal.;">
<meta name="citation_reference" content="citation_title=Adaptive estimation in pattern recognition by combining different procedures;,citation_author=Y. Yang;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=4;,citation_volume=10;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Mixing strategies for density estimation;,citation_author=Y. Yang;,citation_publication_date=2000;,citation_cover_date=2000;,citation_year=2000;,citation_issue=1;,citation_volume=28;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Adaptive regression by mixing;,citation_author=Y. Yang;,citation_publication_date=2001;,citation_cover_date=2001;,citation_year=2001;,citation_issue=454;,citation_volume=96;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Regression with multiple candidate models: Selecting or mixing?;,citation_author=Y. Yang;,citation_publication_date=2003;,citation_cover_date=2003;,citation_year=2003;,citation_issue=3;,citation_volume=13;,citation_journal_title=Statist. Sinica;">
<meta name="citation_reference" content="citation_title=Aggregating regression procedures to improve performance;,citation_author=Y. Yang;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=1;,citation_volume=10;,citation_journal_title=Bernoulli;">
<meta name="citation_reference" content="citation_title=Combining forecasting procedures: Some theoretical results;,citation_author=Y. Yang;,citation_publication_date=2004;,citation_cover_date=2004;,citation_year=2004;,citation_issue=1;,citation_volume=20;,citation_journal_title=Econometric Theory;">
<meta name="citation_reference" content="citation_title=Combining linear regression models: When and how?;,citation_author=Zh. Yuan;,citation_author=Y. Yang;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=472;,citation_volume=100;,citation_journal_title=J. Amer. Statist. Assoc.;">
<meta name="citation_reference" content="citation_title=Digital picture processing;,citation_author=L. P. Yaroslavsky;,citation_publication_date=1985;,citation_cover_date=1985;,citation_year=1985;,citation_volume=9;,citation_series_title=Springer series in information sciences;">
<meta name="citation_reference" content="citation_title=Bregman iterative algorithms for l1-minimization with applications to compressed sensing;,citation_author=W. Yin;,citation_author=S. Osher;,citation_author=D. Goldfarb;,citation_author=J. Darbon;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=1;,citation_volume=1;,citation_journal_title=SIAM J. Imaging Sci.;,citation_publisher=Citeseer;">
<meta name="citation_reference" content="citation_title=Image modeling and enhancement via structured sparse model selection;,citation_author=G. Yu;,citation_author=G. Sapiro;,citation_author=S. Mallat;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_conference_title=ICIP;">
<meta name="citation_reference" content="citation_title=Solving inverse problems with piecewise linear estimators: From gaussian mixture models to structured sparsity;,citation_author=G. Yu;,citation_author=G. Sapiro;,citation_author=S. Mallat;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=5;,citation_volume=21;,citation_journal_title=IEEE Trans. Image Process.;">
<meta name="citation_reference" content="citation_title=An improved GLMNET for l1-regularized logistic regression;,citation_author=G Yuan;,citation_author=undefined Ho;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_volume=13;,citation_journal_title=J. Mach. Learn. Res.;">
<meta name="citation_reference" content="citation_title=Model selection and estimation in regression with grouped variables;,citation_author=M. Yuan;,citation_author=Y. Lin;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=1;,citation_volume=68;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;">
<meta name="citation_reference" content="citation_title=Distributed dual averaging method for multi-agent optimization with quantized communication;,citation_author=D. Yuan;,citation_author=S. Xu;,citation_author=H. Zhao;,citation_author=L. Rong;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=11;,citation_volume=61;,citation_journal_title=Systems &amp;amp;amp; Control Letters;,citation_publisher=Elsevier;">
<meta name="citation_reference" content="citation_title=Eigenvalues of several tridiagonal matrices;,citation_author=W. C. Yueh;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_volume=5;,citation_journal_title=Applied Mathematics E-Notes;">
<meta name="citation_reference" content="citation_title=On the iteration complexity of cyclic coordinate gradient descent methods;,citation_author=S. Yun;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=3;,citation_volume=24;,citation_journal_title=SIAM J. Optim.;,citation_publisher=SIAM;">
<meta name="citation_reference" content="citation_title=The biglasso package: A memory- and computation-efficient solver for lasso model fitting with big data in R;,citation_author=Y. Zeng;,citation_author=P. Breheny;,citation_publication_date=2017;,citation_cover_date=2017;,citation_year=2017;,citation_journal_title=arXiv preprint arXiv:1701.05936;">
<meta name="citation_reference" content="citation_title=The Ordered Weighted $\ell_1$ Norm: Atomic Formulation, Projections, and Algorithms;,citation_author=X. Zeng;,citation_author=M. A. T. Figueiredo;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_journal_title=ArXiv e-prints;">
<meta name="citation_reference" content="citation_title=4D electron microscopy: Imaging in space and time;,citation_author=A. H. Zewail;,citation_author=J. M. Thomas;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Two-stage image denoising by principal component analysis with local pixel grouping;,citation_author=L. Zhang;,citation_author=W. Dong;,citation_author=D. Zhang;,citation_author=G. Shi;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=4;,citation_volume=43;,citation_journal_title=Pattern Recogn.;,citation_publisher=Elsevier Science Inc.;">
<meta name="citation_reference" content="citation_title=Wavelets, ridgelets, and curvelets for Poisson noise removal;,citation_author=B. Zhang;,citation_author=J. Fadili;,citation_author=J-L. Starck;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_issue=7;,citation_volume=17;,citation_journal_title=IEEE Trans. Image Process.;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Complexity of finding stationary points of nonsmooth nonconvex functions;,citation_author=J. Zhang;,citation_author=H. Lin;,citation_author=S. Jegelka;,citation_author=A. Jadbabaie;,citation_author=S. Sra;,citation_publication_date=2020;,citation_cover_date=2020;,citation_year=2020;,citation_volume=abs/2002.04130;,citation_journal_title=CoRR;">
<meta name="citation_reference" content="citation_title=A general theory of concave regularization for high-dimensional sparse estimation problems;,citation_author=undefined Zhang;,citation_author=T. Zhang;,citation_publication_date=2012;,citation_cover_date=2012;,citation_year=2012;,citation_issue=4;,citation_volume=27;,citation_journal_title=Statist. Sci.;,citation_publisher=Institute of Mathematical Statistics;">
<meta name="citation_reference" content="citation_title=Confidence intervals for low dimensional parameters in high dimensional linear models;,citation_author=undefined Zhang;,citation_author=S. S. Zhang;,citation_publication_date=2014;,citation_cover_date=2014;,citation_year=2014;,citation_issue=1;,citation_volume=76;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=Information-theoretic upper and lower bounds for statistical estimation;,citation_author=T. Zhang;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=4;,citation_volume=52;,citation_journal_title=IEEE Trans. Inf. Theory;">
<meta name="citation_reference" content="citation_title=Nearly unbiased variable selection under minimax concave penalty;,citation_author=undefined Zhang;,citation_publication_date=2010;,citation_cover_date=2010;,citation_year=2010;,citation_issue=2;,citation_volume=38;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Adaptive forward-backward greedy algorithm for learning sparse representations;,citation_author=T. Zhang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_issue=7;,citation_volume=57;,citation_journal_title=IEEE Trans. Inf. Theory;,citation_publisher=IEEE;">
<meta name="citation_reference" content="citation_title=Online AUC Maximization;,citation_author=P. Zhao;,citation_author=S. Hoi;,citation_author=R. Jin;,citation_author=T. Yang;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICML;">
<meta name="citation_reference" content="citation_title=Thresholding procedures for high dimensional variable selection and statistical estimation;,citation_author=S. Zhou;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Support vector machines, kernel logistic regression and boosting;,citation_author=J. Zhu;,citation_author=T. J. Hastie;,citation_publication_date=2002;,citation_cover_date=2002;,citation_year=2002;,citation_volume=2364;,citation_journal_title=Multiple Classifier Systems;">
<meta name="citation_reference" content="citation_title=A rotationally invariant block matching strategy improving image denoising with non-local means;,citation_author=S. Zimmer;,citation_author=S. Didas;,citation_author=J. Weickert;,citation_publication_date=2008;,citation_cover_date=2008;,citation_year=2008;,citation_conference_title=LNLA;">
<meta name="citation_reference" content="citation_title=Safe screening for support vector machines;,citation_author=J. Zimmert;,citation_author=C. S. Witt;,citation_author=G. Kerg;,citation_author=M. Kloft;,citation_publication_date=2015;,citation_cover_date=2015;,citation_year=2015;,citation_conference_title=NIPS 2015 workshop on optimization in machine learning (OPT);">
<meta name="citation_reference" content="citation_title=Internal statistics of a single natural image;,citation_author=M. Zontak;,citation_author=M. Irani;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=CVPR;">
<meta name="citation_reference" content="citation_title=From learning models of natural image patches to whole image restoration;,citation_author=D. Zoran;,citation_author=Y. Weiss;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_conference_title=ICCV;">
<meta name="citation_reference" content="citation_title=Sparse principal component analysis;,citation_author=H. Zou;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=2;,citation_volume=15;,citation_journal_title=J. Comput. Graph. Statist.;">
<meta name="citation_reference" content="citation_title=On the “degrees of freedom” of the lasso;,citation_author=H. Zou;,citation_author=T. J. Hastie;,citation_author=R. Tibshirani;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_issue=5;,citation_volume=35;,citation_journal_title=Ann. Statist.;">
<meta name="citation_reference" content="citation_title=Regularization and variable selection via the elastic net;,citation_author=H. Zou;,citation_author=T. J. Hastie;,citation_publication_date=2005;,citation_cover_date=2005;,citation_year=2005;,citation_issue=2;,citation_volume=67;,citation_journal_title=J. R. Stat. Soc. Ser. B Stat. Methodol.;,citation_publisher=Wiley Online Library;">
<meta name="citation_reference" content="citation_title=The adaptive lasso and its oracle properties;,citation_author=H. Zou;,citation_publication_date=2006;,citation_cover_date=2006;,citation_year=2006;,citation_issue=476;,citation_volume=101;,citation_journal_title=J. Amer. Statist. Assoc.;,citation_publisher=Taylor &amp;amp;amp; Francis;">
<meta name="citation_reference" content="citation_title=Subsampling estimates of the Lasso distribution.;,citation_author=E. P. Zoua;,citation_publication_date=2011;,citation_cover_date=2011;,citation_year=2011;,citation_dissertation_institution=ETH;">
<meta name="citation_reference" content="citation_title=A probabilistic algorithm integrating source localization and noise suppression of MEG and EEG data;,citation_author=J. M. Zumer;,citation_author=H. T. Attias;,citation_author=K. Sekihara;,citation_author=S. S. Nagarajan;,citation_publication_date=2007;,citation_cover_date=2007;,citation_year=2007;,citation_conference_title=NIPS;">
<meta name="citation_reference" content="citation_title=Mixed effects models and extensions in ecology with r;,citation_author=A. Zuur;,citation_author=E. N. Ieno;,citation_author=N. Walker;,citation_author=A. A. Saveliev;,citation_author=G. M. Smith;,citation_publication_date=2009;,citation_cover_date=2009;,citation_year=2009;">
<meta name="citation_reference" content="citation_title=Isotonic Regression;,citation_author=Joseph Salmon;,citation_publication_date=2024-11-10;,citation_cover_date=2024-11-10;,citation_year=2024;,citation_fulltext_html_url=https://josephsalmon.eu/blog/isotonic/;,citation_language=en;">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    <img src="../../img/Flag_of_Occitania.svg" alt="" class="navbar-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Joseph Salmon</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../Courses/index.html"> 
<span class="menu-text">Courses</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../publications/index.html"> 
<span class="menu-text">Articles</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../talks/index.html"> 
<span class="menu-text">Talks</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../team/index.html"> 
<span class="menu-text">Team</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../code_new/index.html"> 
<span class="menu-text">Code</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../misc/index.html"> 
<span class="menu-text">Misc</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog/index.xml"> <i class="bi bi-rss" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/josephsalmon"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://sigmoid.social/@josephsalmon" rel="me"> <i class="bi bi-mastodon" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:joseph.salmon@inria.fr"> <i class="bi bi-envelope" role="img" aria-label="email">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default blog-post page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Isotonic regression</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          Iso, Iso, Iso … Tonic! Or how to fit a non-decreasing signal.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">Quadratic programming</div>
                <div class="quarto-category">Calibration</div>
                <div class="quarto-category">PAVA</div>
                <div class="quarto-category">Optimization</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://josephsalmon.eu/">Joseph Salmon</a> <a href="https://orcid.org/0000-0002-3181-0634" class="quarto-title-author-orcid"> <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg=="></a></p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">November 10, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#introduction-formulation" id="toc-introduction-formulation" class="nav-link active" data-scroll-target="#introduction-formulation">Introduction &amp; formulation</a>
  <ul class="collapse">
  <li><a href="#visualization" id="toc-visualization" class="nav-link" data-scroll-target="#visualization">Visualization</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a></li>
  </ul></li>
  <li><a href="#optimization-duality-etc." id="toc-optimization-duality-etc." class="nav-link" data-scroll-target="#optimization-duality-etc.">Optimization, duality, etc.</a>
  <ul class="collapse">
  <li><a href="#notation" id="toc-notation" class="nav-link" data-scroll-target="#notation">Notation</a></li>
  <li><a href="#conic-duality-fenchel-transform" id="toc-conic-duality-fenchel-transform" class="nav-link" data-scroll-target="#conic-duality-fenchel-transform">Conic duality / Fenchel transform</a></li>
  <li><a href="#dual-problem" id="toc-dual-problem" class="nav-link" data-scroll-target="#dual-problem">Dual problem</a></li>
  <li><a href="#karush-kuhn-tucker-kkt-conditions" id="toc-karush-kuhn-tucker-kkt-conditions" class="nav-link" data-scroll-target="#karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) conditions</a></li>
  </ul></li>
  <li><a href="#algorithm" id="toc-algorithm" class="nav-link" data-scroll-target="#algorithm">Algorithm</a>
  <ul class="collapse">
  <li><a href="#pseudo-code-and-python-implementation" id="toc-pseudo-code-and-python-implementation" class="nav-link" data-scroll-target="#pseudo-code-and-python-implementation">Pseudo-code and Python implementation</a></li>
  <li><a href="#convergence" id="toc-convergence" class="nav-link" data-scroll-target="#convergence">Convergence</a></li>
  </ul></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references"><i class="fa-solid fa-link" title="link" aria-label="link"></i> References</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">
<div class="no-row-height column-margin column-container">
  <div class="">
    <img src="isotonic.png" style="width:100%">
  </div>
</div>





<div class="hidden">
{{
<p>% thin space, limits underneath in displays % thin space, limits underneath in displays }}</p>
</div>
<p><strong><u>Note</u></strong>: This blog is mainly inspired by the post by <span class="citation" data-cites="Pedregosa13">Pedregosa (<a href="#ref-Pedregosa13" role="doc-biblioref">2013</a>)</span> on Isotonic regression, a version of the PAVA algorithm provided by <span class="citation" data-cites="Best_Chakravarti90">Best and Chakravarti (<a href="#ref-Best_Chakravarti90" role="doc-biblioref">1990</a>)</span>.</p>
<section id="introduction-formulation" class="level1">
<h1>Introduction &amp; formulation</h1>
<p>Isotonic regression is a technique used to fit a non-decreasing function to a set of data points. We can think of isotonic regression as a generalization of linear regression where the function is constrained to be non-decreasing.</p>
<p>More formally suppose that one collects <span class="math inline">n</span> sample points <span class="math inline">y_1,\dots, y_n</span> and has weights <span class="math inline">w_1, \dots, w_n</span> associated with each data point.</p>
<p><strong><u>Note</u></strong>: when no a priori weights are given, we can set <span class="math inline">w_i = 1</span> for all <span class="math inline">i \in \llbracket 1, n \rrbracket</span>.</p>
<p>Then, the isotonic regression problem can be formulated as follows: <span id="eq-isotonic"><span class="math display">
\begin{align}
\min_{x \in \mathbb{R}^n}
\frac{1}{2}
&amp; \sum_{i=1}^{n} w_i (x_i - y_i)^2 \\
\text{s.t.} &amp; \quad x_1 \leq x_2 \leq \ldots \leq x_n \nonumber
\end{align}
\tag{1}</span></span></p>
<section id="visualization" class="level2">
<h2 class="anchored" data-anchor-id="visualization">Visualization</h2>
<p>Below you’ll find a visualization, on a synthetic dataset, of the most common algorithm, the Pools Adjacent Violators Algorithm (PAVA) to solve isotonic regression algorithm. The top plot shows the evolution of the PAVA algorithm, while the bottom plot shows the primal and dual objectives until convergence. Note that the essence of the algorithm is simple: it Pools Adjacent Violators, <em>i.e.,</em> it replaces adjacent points that are not in increasing order by averaging.</p>
<div id="338640cf" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>                            <div id="18aaee70-0e7b-4480-b878-1689ff5312a2" class="plotly-graph-div" style="height:600px; width:100%;"></div>            <script type="text/javascript">                require(["plotly"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("18aaee70-0e7b-4480-b878-1689ff5312a2")) {                    Plotly.newPlot(                        "18aaee70-0e7b-4480-b878-1689ff5312a2",                        [{"legendgroup":"1","marker":{"color":"black","opacity":1,"size":10},"mode":"markers","name":"Raw data","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter","xaxis":"x","yaxis":"y"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","name":"PAVA iterations","showlegend":true,"x":[0],"y":[-3.0],"type":"scatter","xaxis":"x","yaxis":"y"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","name":"Duals","showlegend":true,"x":[0],"y":[0],"type":"scatter","xaxis":"x2","yaxis":"y2"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","name":"Primals","showlegend":true,"x":[0],"y":[19218.89901471994],"type":"scatter","xaxis":"x2","yaxis":"y2"}],                        {"template":{"data":{"barpolar":[{"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"bar":[{"error_x":{"color":"rgb(36,36,36)"},"error_y":{"color":"rgb(36,36,36)"},"marker":{"line":{"color":"white","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"carpet":[{"aaxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"baxis":{"endlinecolor":"rgb(36,36,36)","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"rgb(36,36,36)"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"choropleth"}],"contourcarpet":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"contourcarpet"}],"contour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"contour"}],"heatmapgl":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmapgl"}],"heatmap":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"heatmap"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2dcontour"}],"histogram2d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"histogram2d"}],"histogram":[{"marker":{"line":{"color":"white","width":0.6}},"type":"histogram"}],"mesh3d":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scattermapbox"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolargl"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterpolar"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"},"colorscale":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"rgb(237,237,237)"},"line":{"color":"white"}},"header":{"fill":{"color":"rgb(217,217,217)"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":1,"tickcolor":"rgb(36,36,36)","ticks":"outside"}},"colorscale":{"diverging":[[0.0,"rgb(103,0,31)"],[0.1,"rgb(178,24,43)"],[0.2,"rgb(214,96,77)"],[0.3,"rgb(244,165,130)"],[0.4,"rgb(253,219,199)"],[0.5,"rgb(247,247,247)"],[0.6,"rgb(209,229,240)"],[0.7,"rgb(146,197,222)"],[0.8,"rgb(67,147,195)"],[0.9,"rgb(33,102,172)"],[1.0,"rgb(5,48,97)"]],"sequential":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]],"sequentialminus":[[0.0,"#440154"],[0.1111111111111111,"#482878"],[0.2222222222222222,"#3e4989"],[0.3333333333333333,"#31688e"],[0.4444444444444444,"#26828e"],[0.5555555555555556,"#1f9e89"],[0.6666666666666666,"#35b779"],[0.7777777777777778,"#6ece58"],[0.8888888888888888,"#b5de2b"],[1.0,"#fde725"]]},"colorway":["#1F77B4","#FF7F0E","#2CA02C","#D62728","#9467BD","#8C564B","#E377C2","#7F7F7F","#BCBD22","#17BECF"],"font":{"color":"rgb(36,36,36)"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"white","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30},"paper_bgcolor":"white","plot_bgcolor":"white","polar":{"angularaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","radialaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"scene":{"xaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"zaxis":{"backgroundcolor":"white","gridcolor":"rgb(232,232,232)","gridwidth":2,"linecolor":"rgb(36,36,36)","showbackground":true,"showgrid":false,"showline":true,"ticks":"outside","zeroline":false,"zerolinecolor":"rgb(36,36,36)"}},"shapedefaults":{"fillcolor":"black","line":{"width":0},"opacity":0.3},"ternary":{"aaxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"baxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"},"bgcolor":"white","caxis":{"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside"}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"},"yaxis":{"automargin":true,"gridcolor":"rgb(232,232,232)","linecolor":"rgb(36,36,36)","showgrid":false,"showline":true,"ticks":"outside","title":{"standoff":15},"zeroline":false,"zerolinecolor":"rgb(36,36,36)"}}},"xaxis":{"anchor":"y","domain":[0.0,1.0],"title":{"text":"X"},"range":[-0.5,25.5]},"yaxis":{"anchor":"x","domain":[0.625,1.0],"title":{"text":"Y"},"range":[0,250]},"xaxis2":{"anchor":"y2","domain":[0.0,1.0],"range":[0,25]},"yaxis2":{"anchor":"x2","domain":[0.0,0.375],"range":[0,25000]},"annotations":[{"font":{"size":16},"showarrow":false,"text":"PAVA output evolution","x":0.5,"xanchor":"center","xref":"paper","y":1.0,"yanchor":"bottom","yref":"paper"},{"font":{"size":16},"showarrow":false,"text":"Primal and dual objectives","x":0.5,"xanchor":"center","xref":"paper","y":0.375,"yanchor":"bottom","yref":"paper"}],"legend":{"tracegroupgap":180},"height":600,"sliders":[{"active":1,"currentvalue":{"prefix":"Iteration: #"},"steps":[{"args":[["0"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"0","method":"animate"},{"args":[["1"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"1","method":"animate"},{"args":[["2"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"2","method":"animate"},{"args":[["3"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"3","method":"animate"},{"args":[["4"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"4","method":"animate"},{"args":[["5"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"5","method":"animate"},{"args":[["6"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"6","method":"animate"},{"args":[["7"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"7","method":"animate"},{"args":[["8"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"8","method":"animate"},{"args":[["9"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"9","method":"animate"},{"args":[["10"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"10","method":"animate"},{"args":[["11"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"11","method":"animate"},{"args":[["12"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"12","method":"animate"},{"args":[["13"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"13","method":"animate"},{"args":[["14"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"14","method":"animate"},{"args":[["15"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"15","method":"animate"},{"args":[["16"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"16","method":"animate"},{"args":[["17"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"17","method":"animate"},{"args":[["18"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"18","method":"animate"},{"args":[["19"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"19","method":"animate"},{"args":[["20"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"20","method":"animate"},{"args":[["21"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"21","method":"animate"},{"args":[["22"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"22","method":"animate"},{"args":[["23"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"23","method":"animate"},{"args":[["24"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"24","method":"animate"},{"args":[["25"],{"mode":"immediate","frame":{"duration":300,"redraw":true},"transition":{"duration":0}}],"label":"25","method":"animate"}]}],"updatemenus":[{"buttons":[{"args":[null,{"frame":{"duration":500,"redraw":false},"fromcurrent":true,"transition":{"duration":50,"easing":"linear"}}],"label":"Play","method":"animate"},{"args":[[null],{"frame":{"duration":0,"redraw":false},"mode":"immediate","transition":{"duration":0}}],"label":"Pause","method":"animate"}],"direction":"left","pad":{"b":20,"r":5,"t":5},"showactive":false,"type":"buttons","x":0.5,"xanchor":"center","y":-0.28,"yanchor":"top"}]},                        {"responsive": true}                    ).then(function(){
                            Plotly.addFrames('18aaee70-0e7b-4480-b878-1689ff5312a2', [{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0],"y":[-3.0],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0],"y":[0.0],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0],"y":[19218.899014719937],"type":"scatter"}],"name":"0"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1],"y":[-3.0,35.657359027997266],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1],"y":[0.0,0.0],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1],"y":[19218.899014719937,19218.899014719937],"type":"scatter"}],"name":"1"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2],"y":[-3.0,35.657359027997266,79.93061443340548],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2],"y":[0.0,0.0,0.0],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2],"y":[19218.899014719937,19218.899014719937,19218.899014719937],"type":"scatter"}],"name":"2"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3],"y":[0.0,0.0,0.0,0.0],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937],"type":"scatter"}],"name":"3"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4],"y":[-3.0,35.657359027997266,75.90574270370168,75.90574270370168,75.90574270370168],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4],"y":[0.0,0.0,0.0,0.0,1646.040179115953],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995],"type":"scatter"}],"name":"4"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002],"type":"scatter"}],"name":"5"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,129.29550745276566],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002],"type":"scatter"}],"name":"6"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,129.29550745276566,147.9720770839918],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002],"type":"scatter"}],"name":"7"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,120.37627113452281,120.37627113452281,120.37627113452281],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108],"type":"scatter"}],"name":"8"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918],"type":"scatter"}],"name":"9"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,155.89476363991855],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918],"type":"scatter"}],"name":"10"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,136.0700480646593,136.0700480646593],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058],"type":"scatter"}],"name":"11"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347],"type":"scatter"}],"name":"12"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,163.9528664807629],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347],"type":"scatter"}],"name":"13"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,137.1776882679367,137.1776882679367],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713],"type":"scatter"}],"name":"14"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,134.3282708826208,134.3282708826208,134.3282708826208],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913],"type":"scatter"}],"name":"15"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,134.3282708826208,134.3282708826208,134.3282708826208,155.6606672028108],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913],"type":"scatter"}],"name":"16"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,134.3282708826208,134.3282708826208,134.3282708826208,152.08962754880952,152.08962754880952],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003],"type":"scatter"}],"name":"17"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,134.3282708826208,134.3282708826208,134.3282708826208,136.467068018647,136.467068018647,136.467068018647],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017],"type":"scatter"}],"name":"18"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706],"type":"scatter"}],"name":"19"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,188.22612188617114],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706],"type":"scatter"}],"name":"20"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,183.88912227704347,183.88912227704347],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984,5842.813704752596],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706,6068.430622939655],"type":"scatter"}],"name":"21"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,183.88912227704347,183.88912227704347,189.7747107964575],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984,5842.813704752596,5842.813704752596],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706,6068.430622939655,6068.430622939655],"type":"scatter"}],"name":"22"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,179.86391171698543,179.86391171698543,179.86391171698543,179.86391171698543],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984,5842.813704752596,5842.813704752596,6069.430709531298],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706,6068.430622939655,6068.430622939655,6069.430709531276],"type":"scatter"}],"name":"23"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,179.86391171698543,179.86391171698543,179.86391171698543,179.86391171698543,191.94379124341003],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984,5842.813704752596,5842.813704752596,6069.430709531298,6069.430709531298],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706,6068.430622939655,6068.430622939655,6069.430709531276,6069.430709531276],"type":"scatter"}],"name":"24"},{"data":[{"legendgroup":"1","marker":{"color":"black","opacity":1},"mode":"markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,79.93061443340548,114.31471805599453,33.471895621705016,53.587973461402754,129.29550745276566,147.9720770839918,83.86122886681098,96.12925464970229,155.89476363991855,116.24533248940001,105.24746787307683,163.9528664807629,110.4025100551105,128.62943611198907,155.6606672028108,148.51858789480823,105.221948958322,101.78661367769953,188.22612188617114,179.5521226679158,189.7747107964575,161.9026915173973,191.94379124341003],"type":"scatter"},{"legendgroup":"1","marker":{"color":"red"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[-3.0,35.657359027997266,70.32630039312696,70.32630039312696,70.32630039312696,70.32630039312696,114.31451701331767,114.31451701331767,114.31451701331767,114.31451701331767,125.79585466746512,125.79585466746512,125.79585466746512,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,130.59609005450042,179.86391171698546,179.86391171698546,179.86391171698546,179.86391171698546,191.94379124341003],"type":"scatter"},{"legendgroup":"2","marker":{"color":"green"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[0.0,0.0,0.0,0.0,1646.040179115953,1832.821238098084,1832.821238098084,1832.821238098084,2920.0360352551797,3140.5052134108846,3140.5052134108846,3533.5245610508136,3850.20171093964,3850.20171093964,4567.111879268254,4591.469417575514,4591.469417575514,4604.221741785936,5336.414840606332,5824.004139142984,5824.004139142984,5842.813704752596,5842.813704752596,6069.430709531298,6069.430709531298],"type":"scatter"},{"legendgroup":"2","marker":{"color":"blue"},"mode":"lines+markers","showlegend":true,"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24],"y":[19218.899014719937,19218.899014719937,19218.899014719937,19218.899014719937,15889.415926489995,12439.088303163002,12439.088303163002,12439.088303163002,11841.668995911108,10811.879845480918,10811.879845480918,10721.13678514058,9947.091120346347,9947.091120346347,9754.99983674713,9386.194758063913,9386.194758063913,9343.53676762003,8339.863786042017,6105.701541579706,6105.701541579706,6068.430622939655,6068.430622939655,6069.430709531276,6069.430709531276],"type":"scatter"}],"name":"24"}]);
                        }).then(function(){
                            
var gd = document.getElementById('18aaee70-0e7b-4480-b878-1689ff5312a2');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                });            </script>        </div>
</div>
</div>
</section>
<section id="applications" class="level2">
<h2 class="anchored" data-anchor-id="applications">Applications</h2>
<p>Isotonic regression is used in a variety of applications, including:</p>
<ul>
<li><p><strong>Monotonicity constraints</strong>: In many applications, it is important to ensure that the relationship between two variables is monotonic. This is the case in physics or biology for instance.</p></li>
<li><p><strong>Calibration</strong> for machine learning models: Isotonic regression can be used to calibrate the output of a machine learning model to ensure that it is well-calibrated. It is common for binary classifiers to output probabilities that are not well-calibrated, and isotonic regression can be used to correct this. You will find a some details and examples in the <a href="https://scikit-learn.org/1.5/modules/calibration.html" target="_blank">scikit-learn documentation</a>.</p></li>
<li><p><strong>Sparse regression</strong>: isotonic regression has some links with the Slope penalty <span class="citation" data-cites="Bogdan_vandenBerg_Sabatti_Su_Candes15">Bogdan et al. (<a href="#ref-Bogdan_vandenBerg_Sabatti_Su_Candes15" role="doc-biblioref">2015</a>)</span>, a generalization of the Lasso penalty. The Slope estimator has been introduced to improve False Discovery Rate control in high-dimensional settings. It is a weighted ordered <span class="math inline">\ell_1</span> penalty, whose proximity operator can be computing thanks to the PAVA algorithm <span class="citation" data-cites="Zeng_Figueiredo14">Zeng and Figueiredo (<a href="#ref-Zeng_Figueiredo14" role="doc-biblioref">2014</a>)</span> (using Moreau’s identity). I became aware of this while working on <span class="citation" data-cites="Bellec_Salmon_Vaiter17">Bellec, Salmon, and Vaiter (<a href="#ref-Bellec_Salmon_Vaiter17" role="doc-biblioref">2017</a>)</span> : we were using that property to compute efficiently the GSlope estimator (and to control duality gap in this context).</p></li>
</ul>
</section>
</section>
<section id="optimization-duality-etc." class="level1">
<h1>Optimization, duality, etc.</h1>
<p>The formulation of the isotonic regression problem given in <a href="#eq-isotonic" class="quarto-xref">Equation&nbsp;1</a> is a quadratic program (QP) with linear constraints. Using a matrix notation, introducing the matrix <span class="math display">A = \begin{pmatrix} 1 &amp; -1 &amp;                       &amp;                       &amp;    \\
  &amp; 1  &amp; -1                    &amp;                       &amp;    \\
  &amp;    &amp; \ddots &amp; \ddots &amp;    \\
  &amp;    &amp;                       &amp; 1                     &amp; -1\end{pmatrix}
=
\begin{pmatrix}
a_1^\top \\
\vdots   \\
a_{n-1}^\top
\end{pmatrix}
\in \mathbb{R}^{n-1 \times n}\enspace,
</span> the isotonic regression problem can be formulated as follows: <span id="eq-isotonic-matrix"><span class="math display">
\begin{align}
\min_{x \in \mathbb{R}^n}
\frac{1}{2}
&amp; \sum_{i=1}^{n} w_i (x_i - y_i)^2 \\
\text{s.t.} &amp; \quad Ax \leq 0 \nonumber
\end{align}
\tag{2}</span></span></p>
<p>In what follows we will write <span class="math inline">W=\mathop{\mathrm{diag}}(w_1,\dots,w_n)</span>, assuming that <span class="math inline">w_i &gt; 0</span> for all <span class="math inline">i \in \llbracket 1, n \rrbracket</span>, so <span class="math inline">W^{-1}= \mathop{\mathrm{diag}}(1/w_1,\dots,1/w_n)</span>. Hence, we can rewrite the isotonic regression problem as</p>
<p><span id="eq-isotonic-matrix-2"><span class="math display">
\begin{align}
\min_{x \in \mathbb{R}^n}
\frac{1}{2}
&amp; (x-y)^\top W (x-y) \\
\text{s.t.} &amp; \quad Ax \leq 0 \enspace.
\end{align}
\tag{3}</span></span></p>
<p>Hence, the isotonic regression problem can be formulated as a convex quadratic program with linear constraints.</p>
<section id="notation" class="level3">
<h3 class="anchored" data-anchor-id="notation">Notation</h3>
<p>The set of <strong>isotonic vectors</strong> <span class="math inline">\mathcal{K} = \left\{ x \in \mathbb{R}^n : Ax \leq 0 \right\}</span> is a cone (stable by positive scalar multiplication). We remind also that the <strong>polar cone</strong> of <span class="math inline">\mathcal{K}</span> is <span class="math inline">\mathcal{K}^\circ= \left\{v \in \mathbb{R}^n : \langle v, x \rangle \leq 0 \text{ for all } x \in \mathcal{K}\right\}</span>.</p>
<p>For any set <span class="math inline">S \subset \llbracket 1, n\rrbracket</span>, the weighted average of <span class="math inline">y_i</span> over the indices in <span class="math inline">i \in S</span> reads: <span class="math display">
\bar{y}_S \triangleq \frac{\sum_{i \in S} w_i y_i}{\sum_{i' \in S} w_{'i'}} \enspace.
</span></p>
<div id="lem-polar" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 1 (Polar cone of the isotonic cone)</strong></span> The polar cone of <span class="math inline">\mathcal{K}</span> is <span class="math display">
\mathcal{K}^\circ =\left\{ \sum_{i=1}^{n-1} \alpha_i a_i, \text{ for } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right\} = A^\top \mathbb{R}_+^{n-1}\enspace.
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>Let <span class="math inline">x \in \mathcal{K}</span> and <span class="math inline">v = \sum_{i=1}^{n-1} \alpha_i a_i</span> with <span class="math inline">\alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0</span>. Then, note that <span class="math inline">A x \leq 0</span> is equivalent to <span class="math inline">\langle a_i, x \rangle \leq 0</span> for all <span class="math inline">i \in \llbracket 1, n-1 \rrbracket</span>. Hence, we have <span class="math display">
\begin{align*}
\langle v, x \rangle
&amp; = \sum_{i=1}^{n-1} \alpha_i \langle a_i, x \rangle\\
&amp; \leq 0 \enspace.
\end{align*}
</span> So <span class="math inline">\left\{ \sum_{i=1}^{n-1} \alpha_i a_i, \text{ with } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right\} \subset \mathcal{K}^\circ</span>.</p>
<p>For the converse, let <span class="math inline">v \in \mathcal{K}^\circ</span>. One can check that <span class="math inline">(a_i)_{i=1,\dots,n-1}</span> are linearly independant, so adding the vector <span class="math inline">\mathbf{1}_n=(1,\dots,1)^\top/n</span> create a basis of <span class="math inline">\mathbb{R}^n</span>.</p>
<p>Hence one can write <span class="math inline">v= \alpha_n \mathbf{1}_n + \sum_{i=1}^{n-1} \alpha_i a_i</span>. Now choosing <span class="math inline">x=\mathbf{1}_n \in \mathcal{K}</span> yields <span class="math inline">\langle v, \mathbf{1}_n \rangle = \alpha_n \leq 0</span>. Choosing <span class="math inline">x = - \mathbf{1}_n \in \mathcal{K}</span> yields <span class="math inline">\langle v, - \mathbf{1}_n \rangle = - \alpha_n \leq 0</span>. Hence, <span class="math inline">\alpha_n = 0</span>.</p>
<p>Now, for all <span class="math inline">i \in \llbracket 1, n-1 \rrbracket</span>, choosing <span class="math inline">x = \sum_{k=i}^n e_i</span> for <span class="math inline">i \in \llbracket 2,n\rrbracket</span> yields <span class="math inline">\langle v, x \rangle = -\alpha_{i}\leq 0</span>. Hence, for all $ i, n-1 $, we have <span class="math inline">\alpha_i \geq 0</span>, so <span class="math inline">\mathcal{K}^\circ \subset \left\{ \sum_{i=1}^{n-1} \alpha_i a_i, \text{ with } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right\}</span> and the lemma is proved.</p>
</div>
</section>
<section id="conic-duality-fenchel-transform" class="level2">
<h2 class="anchored" data-anchor-id="conic-duality-fenchel-transform">Conic duality / Fenchel transform</h2>
<p>Here we remind the definition of the Fenchel transform of a function <span class="math inline">f</span> defined on <span class="math inline">\mathbb{R}^n</span>: <span class="math display">
f^*(v) = \sup_{x \in \mathbb{R}^n} \left\{ \langle v, x \rangle - f(x) \right\}\enspace.
</span></p>
<p>We also write <span class="math inline">\iota_{\mathcal{K}}</span> the indicator function of the set <span class="math inline">\mathcal{K}</span>, that is <span class="math inline">\iota_{\mathcal{K}}(x) = 0</span> if <span class="math inline">x \in \mathcal{K}</span> and <span class="math inline">+\infty</span> otherwise.</p>
<div id="lem-fenchel" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 2 (Fenchel transform of indicator of a cone)</strong></span> The Fenchel transform of the indicator function of a convex cone <span class="math inline">\mathcal{K}</span> is <span class="math display">
\iota_{\mathcal{K}}^*(v) = \iota_{\mathcal{K}^\circ}(v)\enspace,
</span> where <span class="math inline">\iota_{\mathcal{K}^\circ}</span> is the indicator function of the set <span class="math inline">\mathcal{K}^\circ</span>.</p>
</div>
</section>
<section id="dual-problem" class="level2">
<h2 class="anchored" data-anchor-id="dual-problem">Dual problem</h2>
<p>Let us now derive the dual problem of the isotonic regression problem given in <a href="#eq-isotonic-matrix" class="quarto-xref">Equation&nbsp;2</a>.</p>
<div id="thm-dual" class="theorem">
<p><span class="theorem-title"><strong>Theorem 1 (Dual problem of isotonic regression&gt;)</strong></span> The dual problem of the isotonic regression problem given in <a href="#eq-isotonic-matrix" class="quarto-xref">Equation&nbsp;2</a> is <span class="math display">
\begin{align*}
\max_{\alpha \in \mathbb{R}_+^{n-1}} &amp;
\left[
    - \frac{1}{2} (A^\top \alpha-W y)^\top W^{-1} (A^\top \alpha-W y)
    + \frac{1}{2} y^\top W y
\right] \enspace.
\end{align*}
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>With such ingredient we can write the isotonic regression problem as: <span id="eq-isotonic-matrix-2"><span class="math display">
\begin{align}
\min_{x \in \mathbb{R}^n}
\frac{1}{2}
(y-x)^\top W (y-x) + \iota_{\mathcal{K}}(x) \enspace.
\end{align}
\tag{4}</span></span> We can now rewrite the formulation as</p>
<p><span class="math display">
\begin{align*}
\min_{x \in \mathbb{R}^n} &amp;
\frac{1}{2}
z^\top W z + \iota_{\mathcal{K}}(x)\\
\text{s.t.} &amp; \quad z = y - x  \enspace.
\end{align*}
</span> We can now introduce the Lagrangian of the problem: <span class="math display">
\begin{align*}
\mathcal{L}(x, z, \lambda) &amp; = \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top (y - z - x)\\
&amp; = \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top y - \lambda^\top z - \lambda^\top x \enspace.
\end{align*}
</span> Assuming strong duality holds, we can write the dual problem as <span class="math display">
\begin{align*}
\min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} \max_{\lambda \in \mathbb{R}^n} ~
\mathcal{L}(x, z, \lambda) =
\max_{\lambda \in \mathbb{R}^n} \min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} &amp;
\mathcal{L}(x, z, \lambda) \enspace.
\end{align*}
</span> Now, one can check that the dual problem is equivalent to</p>
<p><span class="math display">
\max_{\lambda \in \mathbb{R}^n} \min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} \left\{ \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top y - \lambda^\top z - \lambda^\top x \right\} \enspace.
</span> Separating the terms in <span class="math inline">x</span> and <span class="math inline">z</span> yields <span class="math display">
\max_{\lambda \in \mathbb{R}^n}
\left[
    \min_{x \in \mathbb{R}^n} \left\{ \iota_{\mathcal{K}}(x) - \lambda^\top x + \lambda^\top y \right\} + \min_{z \in \mathbb{R}^n} \left\{ \frac{1}{2} z^\top W z - \lambda^\top z \right\}
\right]
\enspace.
</span> The second term is a simple quadratic problem with a unique solution given by <span class="math inline">z = W^{-1} \lambda</span>, hence this can be rewritten as <span class="math display">
\left[
- \frac{1}{2} \lambda^\top W^{-1} \lambda
\right]
\enspace.
</span> The first term is linked to the Fenchel transform of the indicator function of the cone <span class="math inline">\mathcal{K}</span>, and reads <span class="math display">
\left[
    - \iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top y = - \iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top W^{-1} W y
\right]
\enspace.
</span></p>
<p>Hence the dual problem reads: <span class="math display">
\begin{align*}
\max_{\lambda \in \mathbb{R}^n} &amp;
\left[
    - \iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top y - \frac{1}{2} \lambda^\top W^{-1} \lambda
\right] \enspace,
\end{align*}
</span> the later can be rewritten as</p>
<p><span class="math display">
\begin{align*}
\max_{\lambda \in \mathcal{K}^{\circ}} &amp;
\left[
    - \frac{1}{2} (\lambda-W y)^\top W^{-1} (\lambda-W y)
    + \frac{1}{2} y^\top W y
\right] \enspace.
\end{align*}
</span> Eventually, using the formulation of <span class="math inline">\mathcal{K}^{\circ}</span> given in <a href="#lem-polar" class="quarto-xref">Lemma&nbsp;1</a>, the dual problem can be rewritten as <span class="math display">
\begin{align*}
\max_{\alpha \in \mathbb{R}_+^{n-1}} &amp;
\left[
    - \frac{1}{2} (A^\top \alpha-W y)^\top W^{-1} (A^\top \alpha-W y)
    + \frac{1}{2} y^\top W y
\right] \enspace,
\end{align*}
</span> which is the targeted formulation.</p>
</div>
</section>
<section id="karush-kuhn-tucker-kkt-conditions" class="level2">
<h2 class="anchored" data-anchor-id="karush-kuhn-tucker-kkt-conditions">Karush-Kuhn-Tucker (KKT) conditions</h2>
<p>The KKT conditions for the isotonic regression problem are given by</p>
<div id="thm-kkt" class="theorem">
<p><span class="theorem-title"><strong>Theorem 2 (KKT conditions for isotonic regression)</strong></span> Let <span class="math inline">x^{\star} \in \mathcal{K}</span> and <span class="math inline">\alpha^{\star} \in \mathbb{R}_+^{n-1}</span> be primal and dual optimal solutions, then the KKT conditions for the isotonic regression problem reads <span class="math display">
\begin{align*}
W (x^{\star}-y) + A^\top \alpha^{\star} &amp; = 0 &amp; ~ (\textbf{stationarity})\\
\langle \alpha^{\star} , A x^{\star} \rangle &amp; = 0 &amp; ~ (\textbf{complementary slackness})\\
\alpha^{\star} &amp; \geq 0 &amp; ~ (\textbf{dual feasibility})\\
A x^{\star} &amp; \leq 0 &amp; ~  (\textbf{primal feasibility})
\end{align*}
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>See <span class="citation" data-cites="Boyd_Vandenberghe04">(<a href="#ref-Boyd_Vandenberghe04" role="doc-biblioref">Boyd and Vandenberghe 2004, sec. 5.5.3</a>)</span></p>
</div>
<p>In this convex setting (a primal strictly feasible point exists, say <span class="math inline">x=(1,\dots,n)^\top</span>, so the Slater condition holds), the KKT conditions are necessary and sufficient for optimality.</p>
<p><strong>Stationarity</strong> can be rephrased as:</p>
<p><span class="math display">
\begin{align*}
w_1 (x^{\star}_1- y_1) + \alpha^{\star}_1 &amp; = 0 \\
w_i (x^{\star}_i- y_i) + \alpha^{\star}_{i} - \alpha^{\star}_{i-1} &amp; = 0, \quad \text{for all } i \in \llbracket 2, n-1 \rrbracket\\
w_n (x^{\star}_n - y_n) - \alpha^{\star}_{n-1} &amp; = 0 \enspace.
\end{align*}
</span> With the convention <span class="math inline">\alpha_0^{\star} = \alpha_n^{\star} = 0</span>, this reduces to <span id="eq-stationarity"><span class="math display">
\begin{align*}
w_i (x^{\star}_i - y_i) + \alpha^{\star}_{i} - \alpha^{\star}_{i-1} &amp; = 0, \quad \text{for all } i \in \llbracket 1, n \rrbracket\\
\end{align*}
\tag{5}</span></span></p>
<p><strong>Complementarity slackness</strong> can also be rephrased: <span class="math display">
\begin{align*}
&amp; \alpha_i^{\star} (A x^{\star})_i  = 0 \quad \text{for all } i \in \llbracket 1, n-1 \rrbracket \\
\iff &amp; \alpha_i^{\star} (x^{\star}_i-x^{\star}_{i+1})  = 0 \quad \text{for all } i \in \llbracket 1, n-1 \rrbracket \enspace.
\end{align*}
</span></p>
<p>A simple consequence of the complementarity slackness is as follows: if <span class="math inline">\alpha_i^{\star} &gt; 0</span> for some <span class="math inline">i \in \llbracket 1, n-1 \rrbracket</span>, then <span class="math inline">x^{\star}_i = x^{\star}_{i+1}</span>. Hence, the set of (<span class="math inline">n-1</span>) constraints can be partitioned into contiguous blocks where <span class="math inline">x^\star</span> has constant value. Each block B can be written as <span class="math inline">B = \llbracket \underline{b}, \overline{b} \rrbracket</span> for some <span class="math inline">\underline{b} \leq \overline{b}</span> and <span class="math inline">x^{\star}_{\underline{b}} = x^{\star}_{\underline{b}+1} = \ldots = x^{\star}_{\overline{b}}</span>. When needed we use the convention <span class="math inline">x^{\star}_{0}=0</span> and <span class="math inline">x^{\star}_{n+1}=n+1</span>. and <span class="math inline">x^{\star}_{n+1}=0</span>. Then, note that by definition of a block, <span class="math inline">x^{\star}_{\underline{b}-1}&lt;x^{\star}_{\underline{b}}</span> and <span class="math inline">x^{\star}_{\overline{b}}&lt;x^{\star}_{\overline{b}+1}</span>, and by complementarity <span class="math inline">\alpha^{\star}_{\underline{b}-1} = \alpha^{\star}_{\overline{b}+1} = 0</span>.</p>
<p>Summing over the elements of <span class="math inline">B</span> in <a href="#eq-stationarity" class="quarto-xref">Equation&nbsp;5</a> yields (telescopic sum): <span class="math display">
\begin{align*}
\sum_{i \in B }w_i (x^{\star}_i - y_i) +  \alpha_{\overline{b}+1}^{\star} - \alpha_{\underline{b}-1}^{\star} &amp; = 0 \enspace.
\end{align*}
</span> Hence, noticing that the <span class="math inline">x_i^{\star}</span> in block <span class="math inline">B</span> are all equal, we have that:</p>
<p><span class="math display">
\begin{align*}
x^{\star}_{\underline{b}} = \ldots = x^{\star}_{\overline{b}} = \bar{y}_B  \big(= \bar{y}_{\llbracket \underline{b}, \overline{b} \rrbracket} \big)\enspace.
\end{align*}
</span></p>
<p>Now, from the values of <span class="math inline">x^{\star}_{\underline{b}} = \ldots = x^{\star}_{\overline{b}}</span> on the block <span class="math inline">B</span>, one can infer (by recursion) the <span class="math inline">\alpha_i</span>’s for <span class="math inline">i\in B</span>.</p>
<div id="lem-lambda" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3 (Expression of the dual variables)</strong></span> Let <span class="math inline">B =\llbracket \underline{b}, \overline{b} \rrbracket</span> be partitionning block for <span class="math inline">x^\star</span> (into constants pieces). For any <span class="math inline">i \in B</span>:</p>
<p><span class="math display">
\begin{align*}
\alpha^{\star}_{i} &amp; = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i+1 \rrbracket} - \bar{y}_{B}\right) \enspace.
\end{align*}
</span></p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>The proof is a simple induction on the element of block <span class="math inline">B</span>. For <span class="math inline">i=\underline{b}</span> then <a href="#eq-stationarity" class="quarto-xref">Equation&nbsp;5</a> leads to <span class="math inline">\alpha^{\star}_{\underline{b}} = w_{\underline{b}} (\bar{y}_{\underline{b}} - x^{\star}_{\underline{b}}) = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B} \right)</span>. Now by induction assume the result for <span class="math inline">i\in B</span>, <span class="math inline">\alpha^{\star}_{i}  = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B}\right)</span>. Using <a href="#eq-stationarity" class="quarto-xref">Equation&nbsp;5</a> for <span class="math inline">i+1 \in B</span> yields</p>
<p><span class="math display">
\begin{align*}
\alpha^{\star}_{i+1}
&amp; = w_{i+1} (y_{i+1} - x^{\star}_{i+1}) + \alpha^{\star}_i\\
&amp; = w_{i+1} (y_{i+1} - \overline{y}_{B}) + \alpha^{\star}_i\\
&amp; = w_{i+1} (y_{i+1} - \overline{y}_{B}) + \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j  \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} -\bar{y}_{B}\right)\\
&amp; = \Big(\sum_{j \in B \cap \llbracket 1, i + 1 \rrbracket} w_j  \Big)\left(\bar{y}_{B \cap \llbracket 1, i+1 \rrbracket} - \bar{y}_{B}\right) \enspace,
\end{align*}
</span> hence the result.</p>
</div>
</section>
</section>
<section id="algorithm" class="level1">
<h1>Algorithm</h1>
<p>The intuition behind the PAVA algorithm is to merge adjacent blocks of constant values in the primal vector, as the targeted solution is simply the average of the observe signal over each block. Hence, the algorithm aims at creating the blocks of constant values in the primal vector. The dual variables can be inferred from the solution from the previous lemma.</p>
<section id="pseudo-code-and-python-implementation" class="level2">
<h2 class="anchored" data-anchor-id="pseudo-code-and-python-implementation">Pseudo-code and Python implementation</h2>
<div class="pseudocode-container quarto-float" data-pseudocode-number="1" data-no-end="false" data-line-number-punc=":" data-indent-size="1.2em" data-line-number="true" data-comment-delimiter="//" data-caption-prefix="Algorithm">
<div class="pseudocode">
\begin{algorithm} \caption{PAVA} \begin{algorithmic} \REQUIRE $y \in\mathbb{R}^n, w \in \mathbb{R}^n_{+}$ \STATE $r \leftarrow y$ \STATE $W \leftarrow y$ \STATE $J = [\{1\},\dots, \{n\}]$ \COMMENT{lists of blocks} \STATE $i=1$ (index of list start at 0 here) \WHILE{$i&lt;n$} \IF{$r_i &lt; r_{i-1}$} \COMMENT{Find adjacent violators and merge groups} \STATE $r_i \leftarrow \frac{W_i r_i + W_{i-1} r_{i-1}}{W_i + W_{i-1}}$ \STATE $W_i \leftarrow W_i + W_{i-1}$ \STATE $J_i \leftarrow J_i \cup J_{i-1}$ \STATE Remove $r_{i-1}$, $W_{i-1}$ and $J_{i-1}$ from the lists \IF{$i &gt; 1$} \STATE{$i\leftarrow i-1$} \ENDIF \ELSE \STATE{$i \leftarrow i + 1$} \ENDIF \ENDWHILE \FOR{$i=1$ to len($J$)} \STATE{$r_{J_i} \leftarrow \bar{y}_{J_i} \mathbf{1}_{J_i}$} \COMMENT{Set the block to the average value} \ENDFOR \RETURN{$r, J$} \end{algorithmic} \end{algorithm}
</div>
</div>
<p>Below you will find a simple version of the PAVA algorithm coded in Python. The <code>sklearn</code> version (in particular the <code>_isotonic.pyx</code> file, as available in October 2024, see <a href="https://github.com/scikit-learn/scikit-learn/blob/04fbe04fedda0e86e67867854900a49fb53c4c01/sklearn/_isotonic.pyx" target="_blank">source</a>). is more efficient but a little less readable.</p>
<div id="7a4c51fb" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> PAVA(y, w):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> y.copy()</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    ws <span class="op">=</span> w.copy()</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> [[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> r[i] <span class="op">&lt;</span> r[i <span class="op">-</span> <span class="dv">1</span>]:  <span class="co"># Find adjacent violators</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pool the violators</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>            r[i] <span class="op">=</span> (ws[i] <span class="op">*</span> r[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>] <span class="op">*</span> r[i <span class="op">-</span> <span class="dv">1</span>]) <span class="op">/</span> (ws[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>            ws[i] <span class="op">+=</span> ws[i <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>            target[i] <span class="op">=</span> target[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> target[i]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>            r.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>            ws.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>            target.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>            n <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move back one step if possible</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>                i <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>            counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>    sol <span class="op">=</span> np.zeros_like(y)</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, block <span class="kw">in</span> <span class="bu">enumerate</span>(target):</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>        sol[block] <span class="op">=</span> r[i]</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sol, ws, target</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Below is a version of the algorithm similar to the one implemented in <code>sklearn</code> (yet in pure Python here). Moreover, it can be made an inplace method (as in <code>sklearn</code>), which is more memory efficient.</p>
<div id="38edd9f0" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> isotonic_regression(z, w):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> z.copy()</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span><span class="bu">len</span>(y)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> np.arange(<span class="bu">len</span>(y))</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> [target.copy()]</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> target[i] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> k <span class="op">==</span> n:</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y[i] <span class="op">&lt;</span> y[k]:</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We are in an increasing subsequence.</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>            i <span class="op">=</span> k</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>            targets.append(target.copy())</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>            idx.append(k)</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>        sum_wy <span class="op">=</span> w[i] <span class="op">*</span> y[i]</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>        sum_w <span class="op">=</span> w[i]</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We are within a decreasing subsequence.</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>            prev_y <span class="op">=</span> y[k]</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>            sum_wy <span class="op">+=</span> w[k] <span class="op">*</span> y[k]</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>            sum_w <span class="op">+=</span> w[k]</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>            k <span class="op">=</span> target[k] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> k <span class="op">==</span> n <span class="kw">or</span> prev_y <span class="op">&lt;</span> y[k]:</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>                targets.append(target.copy())</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>                idx.append(k)</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Non-singleton decreasing subsequence is finished,</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>                <span class="co"># update first entry.</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>                y[i] <span class="op">=</span> sum_wy <span class="op">/</span> sum_w</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>                w[i] <span class="op">=</span> sum_w</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>                target[i] <span class="op">=</span> k <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>                target[k <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> i</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Backtrack if we can.  This makes the algorithm</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># single-pass and ensures O(n) complexity.</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">=</span> target[i <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Otherwise, restart from the same point.</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reconstruct the solution.</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> target[i] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>        y[i <span class="op">+</span> <span class="dv">1</span> : k] <span class="op">=</span> y[i]</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> k</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y, targets, idx</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="convergence" class="level2">
<h2 class="anchored" data-anchor-id="convergence">Convergence</h2>
<div id="thm-convergence" class="theorem">
<p><span class="theorem-title"><strong>Theorem 3 (Convergence of the PAVA algorithm)</strong></span> The PAVA algorithm converges in a finite number of iterations and output the primal solution of the isotonic regression problem.</p>
</div>
<div class="proof">
<p><span class="proof-title"><em>Proof</em>. </span>To show the convergence we will create a dual variable <span class="math inline">\alpha</span>, show that it is dual feasible, and that at the end of the algorithm it satisfies KKT along with the output of the PAVA algorithm.</p>
<p>For that let us first prove the following result:</p>
<p><strong>Fact 1</strong>. Let <span class="math inline">B \in J</span> be a block at some stage of the algorithm. Then, <span class="math display">\forall i \in B, \overline{y}_{B \cap \llbracket 1, i \rrbracket} \geq \overline{y}_{B} \enspace.
</span></p>
<p>To show this result, we will use induction and show that the merging process does maintain this condition. First, at initialization, the condition is true as the blocks have all size 1. Now, assume that the condition is true, and check what happen when we merge two consecutive groups <span class="math inline">J_i</span> and <span class="math inline">J_{i-1}</span> into <span class="math inline">B=J_{i-1} \cup J_{i}</span>. First the condition is true for <span class="math inline">J_i</span> and <span class="math inline">J_{i-1}</span>, so <span class="math inline">\overline{y}_{J_i \cap \llbracket 1, k \rrbracket} \geq \overline{y}_{J_i}</span> and <span class="math inline">\overline{y}_{J_{i-1} \cap \llbracket 1, k' \rrbracket} \geq \overline{y}_{J_{i-1}}</span> for any <span class="math inline">k \in J_i</span> and <span class="math inline">k' \in J_{i-1}</span>. Then, the test <span class="math inline">r_i &lt; r_{i-1}</span> is equivalent to <span class="math inline">\overline{y}_{J_i} &lt; \overline{y}_{J_{i-1}}</span>. So for any <span class="math inline">k \in J_{i-1}</span>, we have <span class="math inline">\overline{y}_{J_i \cap \llbracket k, n \rrbracket} \geq \overline{y}_{J_i}</span> using the induction hypothesis. For <span class="math inline">k'\in J_{i}</span>, <span class="math inline">\overline{y}_{B \cap \llbracket 1, k \rrbracket} = \overline{y}_{J_{i-1} \cap \llbracket 1, k \rrbracket} \geq \overline{y}_{J_{i-1}} \geq \overline{y}_{B}</span> (where the last inequality is due to the test <span class="math inline">r_i &lt; r_{i-1}</span>). For the case <span class="math inline">k' \in J_i</span>, we have</p>
<p><span class="math display">
\begin{align*}
\overline{y}_{B \cap \llbracket 1, k' \rrbracket}
&amp; = \overline{y}_{ J_{i-1} \cup (J_{i} \cap \llbracket 1, k' \rrbracket)} \\
&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i} \cap \llbracket 1, k' \rrbracket}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i}\\
&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i} \quad (\text{induction})\\
&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i} \quad (\text{PAVA})\\
\end{align*}
</span> Now, remember that <span class="math inline">\overline{y}_{B} = \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} } w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i}} w_i}</span> and that <span class="math inline">\overline{y}_{J_{i-1}} \geq  \overline{y}_{B} \geq \overline{y}_{J_{i}}</span> (since <span class="math inline">\overline{y}_{B}</span> is a convex combination of <span class="math inline">\overline{y}_{J_{i-1}}</span> and <span class="math inline">\overline{y}_{J_i}</span>), so the last inequality is true. One can check that the weight of <span class="math inline">J_{i}</span> is larger in the definition of <span class="math inline">\overline{y}_{B}</span> than in the last inequality above, and so among the two convex combinations, the larger is the former. Hence, the fact is proved by induction.</p>
<p><strong>Fact 2.</strong> If you update <span class="math inline">\alpha</span> recursively, starting from <span class="math inline">\alpha = \mathbf{0}_{n-1}</span> and for if for each updated block <span class="math inline">B \in J</span> you update <span class="math inline">\alpha</span> (as in <a href="#lem-lambda" class="quarto-xref">Lemma&nbsp;3</a>) by</p>
<p><span class="math display">
\begin{align*}
\forall i \in B, \alpha_i &amp; = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left( \bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B}\right) \enspace,
\end{align*}
</span> then <span class="math inline">\alpha</span> is dual feasible for all steps of the algorithm</p>
<p>The proof is a direct consequence of Fact 1 and the fact that the weights <span class="math inline">w_i</span> are non-negative.</p>
<p><strong>Fact 3.</strong> <span class="math inline">\forall i \in B, \alpha_i=\alpha_{i-1} +w_i(x_i - y_i)</span> (where we assume that <span class="math inline">x_i = \overline{y}_B</span>), which means that <span class="math inline">\alpha</span> and <span class="math inline">x</span> hence created satsfies.</p>
<p>Again this result is simple to prove, by following the exact same line encountered in the proof of <a href="#lem-lambda" class="quarto-xref">Lemma&nbsp;3</a>.</p>
<p><strong>Fact 4.</strong> When you exit the while loop, the output of the PAVA algorithm is a primal feasible point.</p>
<p>Indeed, the only way to exist is to have all blocks mean values ordered. Hence, when the algorithm stops the primal point create (after the block averaging step) is primal feasible.</p>
<p>Leveraging Fact 1. to 4. ensures that the KKT conditions are satisfied with the primal and dual points created. Hence, at the end of the algorithm, and the optimal solution is found.</p>
<section id="duality-gap" class="level2">
<h2 class="anchored" data-anchor-id="duality-gap">Duality Gap</h2>
<p>Given a primal feasible point <span class="math inline">x \in \mathcal{K}</span> and a dual feasible point <span class="math inline">\alpha \in \mathbb{R}_+^{n-1}</span>, we can obtain upper and lower bounds on the optimal value of the primal problem .</p>
<p>Note that at optimality <span class="math inline">W x^\star = W y - A^\top \alpha^\star</span> Hence, using a value of <span class="math inline">x</span> at some stage of the algorithm (corresponding to a feasible <span class="math inline">\alpha</span>), the dual reads <span class="math inline">\frac{1}{2} y^\top W y - \frac{1}{2} x^\top W x</span>. For creating a primal feasible point, one can simply take the ordered version of the output, making the last element constant to create a non-decreasing vector. The later is coded in Python with the following function:</p>
<div id="e69ced72" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace_after_first_non_increasing(x, w<span class="op">=</span>w):</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x[i] <span class="op">&lt;</span> x[i <span class="op">-</span> <span class="dv">1</span>]:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>            mean_value <span class="op">=</span> np.<span class="bu">sum</span>(x[i:] <span class="op">*</span> w[i:]) <span class="op">/</span> np.<span class="bu">sum</span>(w[i:])</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>            x[i:] <span class="op">=</span> mean_value</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>As can be seen in the preliminary animation, the primal and dual objectives converge to the same value, which is the optimal value of the primal problem.</p>
</section>
</div>
</section>
</section>
<section id="references" class="level1">
<h1><i class="fa-solid fa-link" title="link" aria-label="link"></i> References</h1>
<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-Bellec_Salmon_Vaiter17" class="csl-entry" role="listitem">
Bellec, P. C., J. Salmon, and S. Vaiter. 2017. <span>“A Sharp Oracle Inequality for <span>Graph-Slope</span>.”</span> <em>Electron. J. Statist.</em> 11 (2): 4851–70. <a href="https://arxiv.org/pdf/1706.06977.pdf">https://arxiv.org/pdf/1706.06977.pdf</a>.
</div>
<div id="ref-Best_Chakravarti90" class="csl-entry" role="listitem">
Best, M. J., and N. Chakravarti. 1990. <span>“Active Set Algorithms for Isotonic Regression; a Unifying Framework.”</span> <em>Math. Programming</em> 47 (3): 425–39.
</div>
<div id="ref-Bogdan_vandenBerg_Sabatti_Su_Candes15" class="csl-entry" role="listitem">
Bogdan, M., E. van den Berg, C. Sabatti, W. Su, and E. J. Candès. 2015. <span>“<span class="nocase">SLOPE-adaptive</span> Variable Selection via Convex Optimization.”</span> <em>Ann. Appl. Stat.</em> 9 (3): 1103.
</div>
<div id="ref-Boyd_Vandenberghe04" class="csl-entry" role="listitem">
Boyd, S., and L. Vandenberghe. 2004. <em>Convex Optimization</em>. Cambridge University Press.
</div>
<div id="ref-Pedregosa13" class="csl-entry" role="listitem">
Pedregosa, F. 2013. <span>“Isotonic Regression.”</span> <a href="https://fa.bianp.net/blog/2013/isotonic-regression/" class="uri">https://fa.bianp.net/blog/2013/isotonic-regression/</a>.
</div>
<div id="ref-Zeng_Figueiredo14" class="csl-entry" role="listitem">
Zeng, X., and M. A. T. Figueiredo. 2014. <span>“<span class="nocase">The Ordered Weighted <span class="math inline">\ell_1</span> Norm: Atomic Formulation, Projections, and Algorithms</span>.”</span> <em>ArXiv e-Prints</em>.
</div>
</div>


<!-- -->

</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" id="quarto-citation"><h2 class="anchored quarto-appendix-heading">Citation</h2><div><div class="quarto-appendix-secondary-label">BibTeX citation:</div><pre class="sourceCode code-with-copy quarto-appendix-bibtex"><code class="sourceCode bibtex">@online{salmon2024,
  author = {Salmon, Joseph},
  title = {Isotonic Regression},
  date = {2024-11-10},
  url = {https://josephsalmon.eu/blog/isotonic/},
  langid = {en}
}
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div></section></div></main> <!-- /main -->
<hr>

<span style="margin-top:20px; margin-bottom: 20px"></span>

<!-- <img style="width:100%;" src="/img/marvins_log_thumbnail.png"> -->

<!-- <p style="margin: 20px"> Do you enjoy my blog? Subscribe here to get notifications and updates (it's free!):</p> -->

<!-- <div class="grid">
  <div class=".d-none .d-md-block g-col-md-1"></div>
  <div class="g-col-12 g-col-md-10">
    <iframe src="https://embeds.beehiiv.com/c7111066-479b-43db-ad92-8d703fe96bf0?slim=true" data-test-id="beehiiv-embed" frameborder="0" scrolling="no" style="margin: 0; border-radius: 0px !important; background-color: transparent; width:100%; padding: 20px"></iframe>
  </div>
  <div class=".d-none .d-md-block g-col-md-1"></div>
</div> -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/josephsalmon\.eu\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb4" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Isotonic regression"</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">  - name: Joseph Salmon</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co">    url: https://josephsalmon.eu/</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="co">    orcid: 0000-0002-3181-0634</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> "2024-11-10"</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "Iso, Iso, Iso ... Tonic! Or how to fit a non-decreasing signal."</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> [Quadratic programming, Calibration, PAVA, Optimization]</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> "isotonic.png"</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="an">reference-location:</span><span class="co"> document</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="an">fig-cap-location:</span><span class="co"> bottom</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="an">filters:</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">  - pseudocode</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>::: {.hidden}</span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>{{</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>\usepackage{amssymb, amsmath, amsthm}</span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>\usepackage{stmaryrd}</span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator*{\argmin}{arg\,min} % thin space, limits underneath in displays</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator*{\argmax}{arg\,max} % thin space, limits underneath in displays</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>\DeclareMathOperator{\diag}{diag}</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>}}</span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>**[Note]{.underline}**: This blog is mainly inspired by the post by  @Pedregosa13 on Isotonic regression, a version of the PAVA algorithm provided by @Best_Chakravarti90.</span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="fu"># Introduction &amp; formulation</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>Isotonic regression is a technique used to fit a non-decreasing function to a set of data points.</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>We can think of isotonic regression as a generalization of linear regression where the function is constrained to be non-decreasing.</span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>More formally suppose that one collects $n$ sample points $y_1,\dots, y_n$ and has weights $w_1, \dots, w_n$ associated with each data point.</span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>**[Note]{.underline}**: when no a priori weights are given, we can set $w_i = 1$ for all $i \in \llbracket 1, n \rrbracket$.</span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>Then, the isotonic regression problem can be formulated as follows:</span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n}</span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a>\frac{1}{2}</span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a>&amp; \sum_{i=1}^{n} w_i (x_i - y_i)^2 <span class="sc">\\</span></span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>\text{s.t.} &amp; \quad x_1 \leq x_2 \leq \ldots \leq x_n \nonumber</span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>$$ {#eq-isotonic}</span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a><span class="fu">## Visualization</span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>Below you'll find a visualization, on a synthetic dataset, of the most common algorithm, the Pools Adjacent Violators Algorithm (PAVA) to solve isotonic regression algorithm.</span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>The top plot shows the evolution of the PAVA algorithm, while the bottom plot shows the primal and dual objectives until convergence.</span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>Note that the essence of the algorithm is simple: it Pools Adjacent Violators, *i.e.,* it replaces adjacent points that are not in increasing order by averaging.</span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotly.subplots <span class="im">import</span> make_subplots</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a><span class="co"># Easy to read code:</span></span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> isotonic_regression(y, w):</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> y.copy()</span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>    ws <span class="op">=</span> w.copy()</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> [[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> [target.copy()]</span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> r[i] <span class="op">&lt;</span> r[i <span class="op">-</span> <span class="dv">1</span>]:  <span class="co"># Find adjacent violators</span></span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pool the violators</span></span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>            r[i] <span class="op">=</span> (ws[i] <span class="op">*</span> r[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>] <span class="op">*</span> r[i <span class="op">-</span> <span class="dv">1</span>]) <span class="op">/</span> (ws[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>            ws[i] <span class="op">+=</span> ws[i <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>            target[i] <span class="op">=</span> target[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> target[i]</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>            r.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>            ws.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>            target.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>            n <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move back one step if possible</span></span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>                i <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>            counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>            targets.append(target.copy())</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a>    sol <span class="op">=</span> np.zeros_like(y)</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, block <span class="kw">in</span> <span class="bu">enumerate</span>(target):</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>        sol[block] <span class="op">=</span> r[i]</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sol, ws, targets</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>rng <span class="op">=</span> np.random.default_rng(<span class="dv">1</span>)</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>n_sample <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.arange(n_sample)</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.ones(n_sample)</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> rng.integers(<span class="op">-</span><span class="dv">50</span>, <span class="dv">50</span>, size<span class="op">=</span>(n_sample,)) <span class="op">+</span> <span class="fl">50.</span> <span class="op">*</span> np.log(<span class="dv">1</span> <span class="op">+</span> np.arange(n_sample))</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace_after_first_non_increasing(x, w<span class="op">=</span>w):</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x[i] <span class="op">&lt;</span> x[i <span class="op">-</span> <span class="dv">1</span>]:</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>            mean_value <span class="op">=</span> np.<span class="bu">sum</span>(x[i:] <span class="op">*</span> w[i:]) <span class="op">/</span> np.<span class="bu">sum</span>(w[i:])</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>            x[i:] <span class="op">=</span> mean_value</span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> create_signal_from_target(target, y, w<span class="op">=</span>w):</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>    signal <span class="op">=</span> np.zeros_like(y)</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, block <span class="kw">in</span> <span class="bu">enumerate</span>(target):</span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>        signal[block] <span class="op">=</span> np.<span class="bu">sum</span>(y[block] <span class="op">*</span> w[block]) <span class="op">/</span> np.<span class="bu">sum</span>(w[block])</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> signal</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>sol, ws, targets <span class="op">=</span> isotonic_regression(z.tolist(), w.tolist())</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>primals, duals <span class="op">=</span> [], []</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> plotly.graph_objects <span class="im">as</span> go</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> plotly.subplots <span class="im">import</span> make_subplots</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>primals, duals <span class="op">=</span> [], []</span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_targets(y, targets, x):</span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Create subplots</span></span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>    fig <span class="op">=</span> make_subplots(rows<span class="op">=</span><span class="dv">2</span>, cols<span class="op">=</span><span class="dv">1</span>, subplot_titles<span class="op">=</span>(<span class="st">"PAVA output evolution"</span>, <span class="st">"Primal and dual objectives"</span>))</span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Initial plot</span></span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>    fig.add_trace(go.Scatter(x<span class="op">=</span>x, y<span class="op">=</span>y, mode<span class="op">=</span><span class="st">'markers'</span>, name<span class="op">=</span><span class="st">'Raw data'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'black'</span>, opacity<span class="op">=</span><span class="dv">1</span>, size<span class="op">=</span><span class="dv">10</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>), row<span class="op">=</span><span class="dv">1</span>, col<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>    fig.add_trace(go.Scatter(x<span class="op">=</span>[x[<span class="dv">0</span>]], y<span class="op">=</span>[y[<span class="dv">0</span>]], mode<span class="op">=</span><span class="st">'lines+markers'</span>, name<span class="op">=</span><span class="st">'PAVA iterations'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'red'</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>), row<span class="op">=</span><span class="dv">1</span>, col<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>    fig.add_trace(go.Scatter(x<span class="op">=</span>[<span class="dv">0</span>], y<span class="op">=</span>[<span class="dv">0</span>], mode<span class="op">=</span><span class="st">'lines+markers'</span>, name<span class="op">=</span><span class="st">'Duals'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'green'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>), row<span class="op">=</span><span class="dv">2</span>, col<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>    yy <span class="op">=</span> create_signal_from_target(targets[<span class="dv">0</span>], y)</span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>    primal <span class="op">=</span> replace_after_first_non_increasing(np.array(yy))</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a>    fig.add_trace(go.Scatter(x<span class="op">=</span>[<span class="dv">0</span>], y<span class="op">=</span>[<span class="fl">0.5</span> <span class="op">*</span> np.linalg.norm(primal <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>], mode<span class="op">=</span><span class="st">'lines+markers'</span>, name<span class="op">=</span><span class="st">'Primals'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'blue'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>), row<span class="op">=</span><span class="dv">2</span>, col<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(</span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>    legend_tracegroupgap <span class="op">=</span> <span class="dv">180</span>,</span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a>    height<span class="op">=</span><span class="dv">600</span>,</span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>    frames <span class="op">=</span> []</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> iteration, target <span class="kw">in</span> <span class="bu">enumerate</span>(targets):</span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a>        yy <span class="op">=</span> create_signal_from_target(target, y)</span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a>        duals.append(<span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>( w <span class="op">*</span> y<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> <span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>(w<span class="op">*</span>yy<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>        primal <span class="op">=</span> replace_after_first_non_increasing(yy.copy())</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a>        primals.append(<span class="fl">0.5</span> <span class="op">*</span> np.<span class="bu">sum</span>( w<span class="op">*</span>(primal <span class="op">-</span> y)<span class="op">**</span><span class="dv">2</span>))</span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a>        frames.append(go.Frame(data<span class="op">=</span>[</span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a>            go.Scatter(x<span class="op">=</span>x, y<span class="op">=</span>y, mode<span class="op">=</span><span class="st">'markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'black'</span>, opacity<span class="op">=</span><span class="dv">1</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>            go.Scatter(x<span class="op">=</span>x[:iteration<span class="op">+</span><span class="dv">1</span>], y<span class="op">=</span>yy[:iteration<span class="op">+</span><span class="dv">1</span>], mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'red'</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a>            go.Scatter(x<span class="op">=</span>np.arange(iteration<span class="op">+</span><span class="dv">1</span>), y<span class="op">=</span>duals[:iteration<span class="op">+</span><span class="dv">1</span>], mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'green'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a>            go.Scatter(x<span class="op">=</span>np.arange(iteration<span class="op">+</span><span class="dv">1</span>), y<span class="op">=</span>primals[:iteration<span class="op">+</span><span class="dv">1</span>], mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'blue'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a>        ], name<span class="op">=</span><span class="bu">str</span>(iteration)))</span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a>    frames.append(go.Frame(data<span class="op">=</span>[</span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>        go.Scatter(x<span class="op">=</span>x, y<span class="op">=</span>y, mode<span class="op">=</span><span class="st">'markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'black'</span>, opacity<span class="op">=</span><span class="dv">1</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a>        go.Scatter(x<span class="op">=</span>x, y<span class="op">=</span>sol, mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'red'</span>), legendgroup<span class="op">=</span><span class="st">'1'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>        go.Scatter(x<span class="op">=</span>np.arange(<span class="bu">len</span>(duals)), y<span class="op">=</span>duals, mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'green'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>),</span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a>        go.Scatter(x<span class="op">=</span>np.arange(<span class="bu">len</span>(primals)), y<span class="op">=</span>primals, mode<span class="op">=</span><span class="st">'lines+markers'</span>, marker<span class="op">=</span><span class="bu">dict</span>(color<span class="op">=</span><span class="st">'blue'</span>), legendgroup<span class="op">=</span><span class="st">'2'</span>, showlegend<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>    ], name<span class="op">=</span><span class="bu">str</span>(iteration)))</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a>    fig.frames <span class="op">=</span> frames</span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a>    steps <span class="op">=</span> [<span class="bu">dict</span>(method<span class="op">=</span><span class="st">"animate"</span>, args<span class="op">=</span>[[<span class="bu">str</span>(i)], <span class="bu">dict</span>(mode<span class="op">=</span><span class="st">"immediate"</span>, frame<span class="op">=</span><span class="bu">dict</span>(duration<span class="op">=</span><span class="dv">300</span>, redraw<span class="op">=</span><span class="va">True</span>), transition<span class="op">=</span><span class="bu">dict</span>(duration<span class="op">=</span><span class="dv">0</span>))], label<span class="op">=</span><span class="bu">str</span>(i)) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(frames))]</span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>    sliders <span class="op">=</span> [<span class="bu">dict</span>(active<span class="op">=</span><span class="dv">1</span>, steps<span class="op">=</span>steps, currentvalue<span class="op">=</span>{<span class="st">"prefix"</span>: <span class="st">"Iteration: #"</span>})]</span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a>    fig.update_layout(</span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>        sliders<span class="op">=</span>sliders,</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>        updatemenus<span class="op">=</span>[{</span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>            <span class="st">"buttons"</span>: [</span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"args"</span>: [<span class="va">None</span>, {<span class="st">"frame"</span>: {<span class="st">"duration"</span>: <span class="dv">500</span>, <span class="st">"redraw"</span>: <span class="va">False</span>}, <span class="st">"fromcurrent"</span>: <span class="va">True</span>, <span class="st">"transition"</span>: {<span class="st">"duration"</span>: <span class="dv">50</span>, <span class="st">"easing"</span>: <span class="st">"linear"</span>}}], <span class="st">"label"</span>: <span class="st">"Play"</span>, <span class="st">"method"</span>: <span class="st">"animate"</span>},</span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>                {<span class="st">"args"</span>: [[<span class="va">None</span>], {<span class="st">"frame"</span>: {<span class="st">"duration"</span>: <span class="dv">0</span>, <span class="st">"redraw"</span>: <span class="va">False</span>}, <span class="st">"mode"</span>: <span class="st">"immediate"</span>, <span class="st">"transition"</span>: {<span class="st">"duration"</span>: <span class="dv">0</span>}}], <span class="st">"label"</span>: <span class="st">"Pause"</span>, <span class="st">"method"</span>: <span class="st">"animate"</span>}</span>
<span id="cb4-194"><a href="#cb4-194" aria-hidden="true" tabindex="-1"></a>            ],</span>
<span id="cb4-195"><a href="#cb4-195" aria-hidden="true" tabindex="-1"></a>            <span class="st">"direction"</span>: <span class="st">"left"</span>, <span class="st">"pad"</span>: {<span class="st">"r"</span>: <span class="dv">5</span>, <span class="st">"t"</span>: <span class="dv">5</span>, <span class="st">"b"</span>: <span class="dv">20</span>}, <span class="st">"showactive"</span>: <span class="va">False</span>, <span class="st">"type"</span>: <span class="st">"buttons"</span>, <span class="st">"x"</span>: <span class="fl">0.5</span>, <span class="st">"xanchor"</span>: <span class="st">"center"</span>, <span class="st">"y"</span>: <span class="op">-</span><span class="fl">0.28</span>, <span class="st">"yanchor"</span>: <span class="st">"top"</span></span>
<span id="cb4-196"><a href="#cb4-196" aria-hidden="true" tabindex="-1"></a>        }],</span>
<span id="cb4-197"><a href="#cb4-197" aria-hidden="true" tabindex="-1"></a>    xaxis_title<span class="op">=</span><span class="st">"X"</span>, yaxis_title<span class="op">=</span><span class="st">"Y"</span>, template<span class="op">=</span><span class="st">'simple_white'</span>, xaxis<span class="op">=</span><span class="bu">dict</span>(<span class="bu">range</span><span class="op">=</span>[<span class="op">-</span><span class="fl">0.5</span>, n<span class="op">+</span><span class="fl">0.5</span>]), yaxis<span class="op">=</span><span class="bu">dict</span>(<span class="bu">range</span><span class="op">=</span>[<span class="dv">0</span>, <span class="dv">250</span>]), xaxis2<span class="op">=</span><span class="bu">dict</span>(<span class="bu">range</span><span class="op">=</span>[<span class="dv">0</span>, <span class="bu">len</span>(targets)]), yaxis2<span class="op">=</span><span class="bu">dict</span>(<span class="bu">range</span><span class="op">=</span>[<span class="dv">0</span>, <span class="dv">25000</span>]),</span>
<span id="cb4-198"><a href="#cb4-198" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-199"><a href="#cb4-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-200"><a href="#cb4-200" aria-hidden="true" tabindex="-1"></a>    fig.show()</span>
<span id="cb4-201"><a href="#cb4-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-202"><a href="#cb4-202" aria-hidden="true" tabindex="-1"></a>plot_targets(z, targets, x)</span>
<span id="cb4-203"><a href="#cb4-203" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-204"><a href="#cb4-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-205"><a href="#cb4-205" aria-hidden="true" tabindex="-1"></a><span class="fu">## Applications</span></span>
<span id="cb4-206"><a href="#cb4-206" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-207"><a href="#cb4-207" aria-hidden="true" tabindex="-1"></a>Isotonic regression is used in a variety of applications, including:</span>
<span id="cb4-208"><a href="#cb4-208" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-209"><a href="#cb4-209" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Monotonicity constraints**: In many applications, it is important to ensure that the relationship between two variables is monotonic. This is the case in physics or biology for instance.</span>
<span id="cb4-210"><a href="#cb4-210" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-211"><a href="#cb4-211" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Calibration** for machine learning models: Isotonic regression can be used to calibrate the output of a machine learning model to ensure that it is well-calibrated. It is common for binary classifiers to output probabilities that are not well-calibrated, and isotonic regression can be used to correct this.</span>
<span id="cb4-212"><a href="#cb4-212" aria-hidden="true" tabindex="-1"></a>You will find a some details and examples in the <span class="co">[</span><span class="ot">scikit-learn documentation</span><span class="co">](https://scikit-learn.org/1.5/modules/calibration.html)</span>.</span>
<span id="cb4-213"><a href="#cb4-213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-214"><a href="#cb4-214" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Sparse regression**: isotonic regression has some links with the Slope penalty @Bogdan_vandenBerg_Sabatti_Su_Candes15, a generalization of the Lasso penalty. The Slope estimator has been introduced to improve False Discovery Rate control in high-dimensional settings. It is a weighted ordered $\ell_1$ penalty, whose proximity operator can be computing thanks to the PAVA algorithm @Zeng_Figueiredo14 (using Moreau's identity). I became aware of this while working on @Bellec_Salmon_Vaiter17 : we were using that property to compute efficiently the GSlope estimator (and to control duality gap in this context).</span>
<span id="cb4-215"><a href="#cb4-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-216"><a href="#cb4-216" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-217"><a href="#cb4-217" aria-hidden="true" tabindex="-1"></a><span class="fu"># Optimization, duality, etc.</span></span>
<span id="cb4-218"><a href="#cb4-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-219"><a href="#cb4-219" aria-hidden="true" tabindex="-1"></a>The formulation of the isotonic regression problem given in @eq-isotonic is a quadratic program (QP) with linear constraints.</span>
<span id="cb4-220"><a href="#cb4-220" aria-hidden="true" tabindex="-1"></a>Using a matrix notation, introducing the matrix</span>
<span id="cb4-221"><a href="#cb4-221" aria-hidden="true" tabindex="-1"></a>$$A = \begin{pmatrix} 1 &amp; -1 &amp;                       &amp;                       &amp;    <span class="sc">\\</span></span>
<span id="cb4-222"><a href="#cb4-222" aria-hidden="true" tabindex="-1"></a>  &amp; 1  &amp; -1                    &amp;                       &amp;    <span class="sc">\\</span></span>
<span id="cb4-223"><a href="#cb4-223" aria-hidden="true" tabindex="-1"></a>  &amp;    &amp; \ddots &amp; \ddots &amp;    <span class="sc">\\</span></span>
<span id="cb4-224"><a href="#cb4-224" aria-hidden="true" tabindex="-1"></a>  &amp;    &amp;                       &amp; 1                     &amp; -1\end{pmatrix}</span>
<span id="cb4-225"><a href="#cb4-225" aria-hidden="true" tabindex="-1"></a> =</span>
<span id="cb4-226"><a href="#cb4-226" aria-hidden="true" tabindex="-1"></a>\begin{pmatrix}</span>
<span id="cb4-227"><a href="#cb4-227" aria-hidden="true" tabindex="-1"></a>a_1^\top <span class="sc">\\</span></span>
<span id="cb4-228"><a href="#cb4-228" aria-hidden="true" tabindex="-1"></a>\vdots   <span class="sc">\\</span></span>
<span id="cb4-229"><a href="#cb4-229" aria-hidden="true" tabindex="-1"></a>a_{n-1}^\top</span>
<span id="cb4-230"><a href="#cb4-230" aria-hidden="true" tabindex="-1"></a>\end{pmatrix}</span>
<span id="cb4-231"><a href="#cb4-231" aria-hidden="true" tabindex="-1"></a> \in \mathbb{R}^{n-1 \times n}\enspace,</span>
<span id="cb4-232"><a href="#cb4-232" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-233"><a href="#cb4-233" aria-hidden="true" tabindex="-1"></a>the isotonic regression problem can be formulated as follows:</span>
<span id="cb4-234"><a href="#cb4-234" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-235"><a href="#cb4-235" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb4-236"><a href="#cb4-236" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n}</span>
<span id="cb4-237"><a href="#cb4-237" aria-hidden="true" tabindex="-1"></a>\frac{1}{2}</span>
<span id="cb4-238"><a href="#cb4-238" aria-hidden="true" tabindex="-1"></a>&amp; \sum_{i=1}^{n} w_i (x_i - y_i)^2 <span class="sc">\\</span></span>
<span id="cb4-239"><a href="#cb4-239" aria-hidden="true" tabindex="-1"></a>\text{s.t.} &amp; \quad Ax \leq 0 \nonumber</span>
<span id="cb4-240"><a href="#cb4-240" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb4-241"><a href="#cb4-241" aria-hidden="true" tabindex="-1"></a>$$ {#eq-isotonic-matrix}</span>
<span id="cb4-242"><a href="#cb4-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-243"><a href="#cb4-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-244"><a href="#cb4-244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-245"><a href="#cb4-245" aria-hidden="true" tabindex="-1"></a>In what follows we will write $W=\diag(w_1,\dots,w_n)$, assuming that $w_i &gt; 0$ for all $i \in \llbracket 1, n \rrbracket$, so $W^{-1}= \diag(1/w_1,\dots,1/w_n)$.</span>
<span id="cb4-246"><a href="#cb4-246" aria-hidden="true" tabindex="-1"></a>Hence, we can rewrite the isotonic regression problem as</span>
<span id="cb4-247"><a href="#cb4-247" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-248"><a href="#cb4-248" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-249"><a href="#cb4-249" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb4-250"><a href="#cb4-250" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n}</span>
<span id="cb4-251"><a href="#cb4-251" aria-hidden="true" tabindex="-1"></a>\frac{1}{2}</span>
<span id="cb4-252"><a href="#cb4-252" aria-hidden="true" tabindex="-1"></a>&amp; (x-y)^\top W (x-y) <span class="sc">\\</span></span>
<span id="cb4-253"><a href="#cb4-253" aria-hidden="true" tabindex="-1"></a>\text{s.t.} &amp; \quad Ax \leq 0 \enspace.</span>
<span id="cb4-254"><a href="#cb4-254" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb4-255"><a href="#cb4-255" aria-hidden="true" tabindex="-1"></a>$$ {#eq-isotonic-matrix-2}</span>
<span id="cb4-256"><a href="#cb4-256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-257"><a href="#cb4-257" aria-hidden="true" tabindex="-1"></a>Hence, the isotonic regression problem can be formulated as a convex quadratic program with linear constraints.</span>
<span id="cb4-258"><a href="#cb4-258" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-259"><a href="#cb4-259" aria-hidden="true" tabindex="-1"></a><span class="fu">### Notation</span></span>
<span id="cb4-260"><a href="#cb4-260" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-261"><a href="#cb4-261" aria-hidden="true" tabindex="-1"></a>The set of **isotonic vectors** $\mathcal{K} = \left<span class="sc">\{</span> x \in \mathbb{R}^n : Ax \leq 0 \right<span class="sc">\}</span>$</span>
<span id="cb4-262"><a href="#cb4-262" aria-hidden="true" tabindex="-1"></a>is a cone (stable by positive scalar multiplication).</span>
<span id="cb4-263"><a href="#cb4-263" aria-hidden="true" tabindex="-1"></a>We remind also that the **polar cone** of $\mathcal{K}$ is $\mathcal{K}^\circ= \left<span class="sc">\{</span>v \in \mathbb{R}^n : \langle v, x \rangle \leq 0 \text{ for all } x \in \mathcal{K}\right<span class="sc">\}</span>$.</span>
<span id="cb4-264"><a href="#cb4-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-265"><a href="#cb4-265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-266"><a href="#cb4-266" aria-hidden="true" tabindex="-1"></a>For any set $S \subset \llbracket 1, n\rrbracket$, the weighted average of $y_i$ over the indices in $i \in S$ reads:</span>
<span id="cb4-267"><a href="#cb4-267" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-268"><a href="#cb4-268" aria-hidden="true" tabindex="-1"></a>\bar{y}_S \triangleq \frac{\sum_{i \in S} w_i y_i}{\sum_{i' \in S} w_{'i'}} \enspace.</span>
<span id="cb4-269"><a href="#cb4-269" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-270"><a href="#cb4-270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-271"><a href="#cb4-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-272"><a href="#cb4-272" aria-hidden="true" tabindex="-1"></a>::: {#lem-polar}</span>
<span id="cb4-273"><a href="#cb4-273" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-274"><a href="#cb4-274" aria-hidden="true" tabindex="-1"></a><span class="fu">## Polar cone of the isotonic cone</span></span>
<span id="cb4-275"><a href="#cb4-275" aria-hidden="true" tabindex="-1"></a>The polar cone of $\mathcal{K}$ is</span>
<span id="cb4-276"><a href="#cb4-276" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-277"><a href="#cb4-277" aria-hidden="true" tabindex="-1"></a>\mathcal{K}^\circ =\left<span class="sc">\{</span> \sum_{i=1}^{n-1} \alpha_i a_i, \text{ for } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right<span class="sc">\}</span> = A^\top \mathbb{R}_+^{n-1}\enspace.</span>
<span id="cb4-278"><a href="#cb4-278" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-279"><a href="#cb4-279" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-280"><a href="#cb4-280" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-281"><a href="#cb4-281" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-282"><a href="#cb4-282" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb4-283"><a href="#cb4-283" aria-hidden="true" tabindex="-1"></a>Let $x \in \mathcal{K}$ and $v = \sum_{i=1}^{n-1} \alpha_i a_i$ with $\alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0$.</span>
<span id="cb4-284"><a href="#cb4-284" aria-hidden="true" tabindex="-1"></a>Then, note that $A x \leq 0$ is equivalent to $\langle a_i, x \rangle \leq 0$ for all $i \in \llbracket 1, n-1 \rrbracket$. Hence, we have</span>
<span id="cb4-285"><a href="#cb4-285" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-286"><a href="#cb4-286" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-287"><a href="#cb4-287" aria-hidden="true" tabindex="-1"></a>\langle v, x \rangle</span>
<span id="cb4-288"><a href="#cb4-288" aria-hidden="true" tabindex="-1"></a>&amp; = \sum_{i=1}^{n-1} \alpha_i \langle a_i, x \rangle<span class="sc">\\</span></span>
<span id="cb4-289"><a href="#cb4-289" aria-hidden="true" tabindex="-1"></a>&amp; \leq 0 \enspace.</span>
<span id="cb4-290"><a href="#cb4-290" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-291"><a href="#cb4-291" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-292"><a href="#cb4-292" aria-hidden="true" tabindex="-1"></a>So $\left<span class="sc">\{</span> \sum_{i=1}^{n-1} \alpha_i a_i, \text{ with } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right<span class="sc">\}</span> \subset \mathcal{K}^\circ$.</span>
<span id="cb4-293"><a href="#cb4-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-294"><a href="#cb4-294" aria-hidden="true" tabindex="-1"></a>For the converse, let $v \in \mathcal{K}^\circ$.</span>
<span id="cb4-295"><a href="#cb4-295" aria-hidden="true" tabindex="-1"></a>One can check that $(a_i)_{i=1,\dots,n-1}$ are linearly independant, so adding the vector $\mathbf{1}_n=(1,\dots,1)^\top/n$ create a basis of $\mathbb{R}^n$.</span>
<span id="cb4-296"><a href="#cb4-296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-297"><a href="#cb4-297" aria-hidden="true" tabindex="-1"></a>Hence one can write $v= \alpha_n \mathbf{1}_n + \sum_{i=1}^{n-1} \alpha_i a_i$.</span>
<span id="cb4-298"><a href="#cb4-298" aria-hidden="true" tabindex="-1"></a>Now choosing $x=\mathbf{1}_n \in \mathcal{K}$ yields $\langle v, \mathbf{1}_n \rangle = \alpha_n \leq 0$. Choosing $x = - \mathbf{1}_n \in \mathcal{K}$ yields $\langle v, - \mathbf{1}_n \rangle = - \alpha_n \leq 0$. Hence, $\alpha_n = 0$.</span>
<span id="cb4-299"><a href="#cb4-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-300"><a href="#cb4-300" aria-hidden="true" tabindex="-1"></a>Now, for all $i \in \llbracket 1, n-1 \rrbracket$, choosing $x = \sum_{k=i}^n e_i$ for $i \in \llbracket 2,n\rrbracket$ yields $\langle v, x \rangle = -\alpha_{i}\leq 0$. Hence, for all $ i\in \llbracket 1, n-1 \rrbracket$, we have $\alpha_i \geq 0$, so $\mathcal{K}^\circ \subset \left<span class="sc">\{</span> \sum_{i=1}^{n-1} \alpha_i a_i, \text{ with } \alpha_1 \geq 0, \dots, \alpha_{n-1} \geq 0 \right<span class="sc">\}</span>$ and the lemma is proved.</span>
<span id="cb4-301"><a href="#cb4-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-302"><a href="#cb4-302" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-303"><a href="#cb4-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-304"><a href="#cb4-304" aria-hidden="true" tabindex="-1"></a><span class="fu">## Conic duality / Fenchel transform</span></span>
<span id="cb4-305"><a href="#cb4-305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-306"><a href="#cb4-306" aria-hidden="true" tabindex="-1"></a>Here we remind the definition of the Fenchel transform of a function $f$ defined on $\mathbb{R}^n$:</span>
<span id="cb4-307"><a href="#cb4-307" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-308"><a href="#cb4-308" aria-hidden="true" tabindex="-1"></a>f^*(v) = \sup_{x \in \mathbb{R}^n} \left<span class="sc">\{</span> \langle v, x \rangle - f(x) \right<span class="sc">\}</span>\enspace.</span>
<span id="cb4-309"><a href="#cb4-309" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-310"><a href="#cb4-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-311"><a href="#cb4-311" aria-hidden="true" tabindex="-1"></a>We also write $\iota_{\mathcal{K}}$ the indicator function of the set $\mathcal{K}$, that is $\iota_{\mathcal{K}}(x) = 0$ if $x \in \mathcal{K}$ and $+\infty$ otherwise.</span>
<span id="cb4-312"><a href="#cb4-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-313"><a href="#cb4-313" aria-hidden="true" tabindex="-1"></a>::: {#lem-fenchel}</span>
<span id="cb4-314"><a href="#cb4-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-315"><a href="#cb4-315" aria-hidden="true" tabindex="-1"></a><span class="fu">## Fenchel transform of indicator of a cone</span></span>
<span id="cb4-316"><a href="#cb4-316" aria-hidden="true" tabindex="-1"></a>The Fenchel transform of the indicator function of a convex cone $\mathcal{K}$ is</span>
<span id="cb4-317"><a href="#cb4-317" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-318"><a href="#cb4-318" aria-hidden="true" tabindex="-1"></a>\iota_{\mathcal{K}}^*(v) = \iota_{\mathcal{K}^\circ}(v)\enspace,</span>
<span id="cb4-319"><a href="#cb4-319" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-320"><a href="#cb4-320" aria-hidden="true" tabindex="-1"></a>where $\iota_{\mathcal{K}^\circ}$ is the indicator function of the set $\mathcal{K}^\circ$.</span>
<span id="cb4-321"><a href="#cb4-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-322"><a href="#cb4-322" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-323"><a href="#cb4-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-324"><a href="#cb4-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-325"><a href="#cb4-325" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dual problem</span></span>
<span id="cb4-326"><a href="#cb4-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-327"><a href="#cb4-327" aria-hidden="true" tabindex="-1"></a>Let us now derive the dual problem of the isotonic regression problem given in @eq-isotonic-matrix.</span>
<span id="cb4-328"><a href="#cb4-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-329"><a href="#cb4-329" aria-hidden="true" tabindex="-1"></a>::: {#thm-dual}</span>
<span id="cb4-330"><a href="#cb4-330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-331"><a href="#cb4-331" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dual problem of isotonic regression&gt;</span></span>
<span id="cb4-332"><a href="#cb4-332" aria-hidden="true" tabindex="-1"></a>The dual problem of the isotonic regression problem given in @eq-isotonic-matrix is</span>
<span id="cb4-333"><a href="#cb4-333" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-334"><a href="#cb4-334" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-335"><a href="#cb4-335" aria-hidden="true" tabindex="-1"></a>\max_{\alpha \in \mathbb{R}_+^{n-1}} &amp;</span>
<span id="cb4-336"><a href="#cb4-336" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-337"><a href="#cb4-337" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>\frac{1}{2} (A^\top \alpha-W y)^\top W^{-1} (A^\top \alpha-W y)</span>
<span id="cb4-338"><a href="#cb4-338" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>\frac{1}{2} y^\top W y</span>
<span id="cb4-339"><a href="#cb4-339" aria-hidden="true" tabindex="-1"></a>\right] \enspace.</span>
<span id="cb4-340"><a href="#cb4-340" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-341"><a href="#cb4-341" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-342"><a href="#cb4-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-343"><a href="#cb4-343" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-344"><a href="#cb4-344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-345"><a href="#cb4-345" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb4-346"><a href="#cb4-346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-347"><a href="#cb4-347" aria-hidden="true" tabindex="-1"></a>With such ingredient we can write the isotonic regression problem as:</span>
<span id="cb4-348"><a href="#cb4-348" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-349"><a href="#cb4-349" aria-hidden="true" tabindex="-1"></a>\begin{align}</span>
<span id="cb4-350"><a href="#cb4-350" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n}</span>
<span id="cb4-351"><a href="#cb4-351" aria-hidden="true" tabindex="-1"></a>\frac{1}{2}</span>
<span id="cb4-352"><a href="#cb4-352" aria-hidden="true" tabindex="-1"></a>(y-x)^\top W (y-x) + \iota_{\mathcal{K}}(x) \enspace.</span>
<span id="cb4-353"><a href="#cb4-353" aria-hidden="true" tabindex="-1"></a>\end{align}</span>
<span id="cb4-354"><a href="#cb4-354" aria-hidden="true" tabindex="-1"></a>$$ {#eq-isotonic-matrix-2}</span>
<span id="cb4-355"><a href="#cb4-355" aria-hidden="true" tabindex="-1"></a>We can now rewrite the formulation as</span>
<span id="cb4-356"><a href="#cb4-356" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-357"><a href="#cb4-357" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-358"><a href="#cb4-358" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-359"><a href="#cb4-359" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n} &amp;</span>
<span id="cb4-360"><a href="#cb4-360" aria-hidden="true" tabindex="-1"></a>\frac{1}{2}</span>
<span id="cb4-361"><a href="#cb4-361" aria-hidden="true" tabindex="-1"></a>z^\top W z + \iota_{\mathcal{K}}(x)<span class="sc">\\</span></span>
<span id="cb4-362"><a href="#cb4-362" aria-hidden="true" tabindex="-1"></a>\text{s.t.} &amp; \quad z = y - x  \enspace.</span>
<span id="cb4-363"><a href="#cb4-363" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-364"><a href="#cb4-364" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-365"><a href="#cb4-365" aria-hidden="true" tabindex="-1"></a>We can now introduce the Lagrangian of the problem:</span>
<span id="cb4-366"><a href="#cb4-366" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-367"><a href="#cb4-367" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-368"><a href="#cb4-368" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(x, z, \lambda) &amp; = \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top (y - z - x)<span class="sc">\\</span></span>
<span id="cb4-369"><a href="#cb4-369" aria-hidden="true" tabindex="-1"></a>&amp; = \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top y - \lambda^\top z - \lambda^\top x \enspace.</span>
<span id="cb4-370"><a href="#cb4-370" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-371"><a href="#cb4-371" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-372"><a href="#cb4-372" aria-hidden="true" tabindex="-1"></a>Assuming strong duality holds, we can write the dual problem as</span>
<span id="cb4-373"><a href="#cb4-373" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-374"><a href="#cb4-374" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-375"><a href="#cb4-375" aria-hidden="true" tabindex="-1"></a>\min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} \max_{\lambda \in \mathbb{R}^n} ~</span>
<span id="cb4-376"><a href="#cb4-376" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(x, z, \lambda) =</span>
<span id="cb4-377"><a href="#cb4-377" aria-hidden="true" tabindex="-1"></a>\max_{\lambda \in \mathbb{R}^n} \min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} &amp;</span>
<span id="cb4-378"><a href="#cb4-378" aria-hidden="true" tabindex="-1"></a>\mathcal{L}(x, z, \lambda) \enspace.</span>
<span id="cb4-379"><a href="#cb4-379" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-380"><a href="#cb4-380" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-381"><a href="#cb4-381" aria-hidden="true" tabindex="-1"></a>Now, one can check that the dual problem is equivalent to</span>
<span id="cb4-382"><a href="#cb4-382" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-383"><a href="#cb4-383" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-384"><a href="#cb4-384" aria-hidden="true" tabindex="-1"></a>\max_{\lambda \in \mathbb{R}^n} \min_{x \in \mathbb{R}^n, z \in \mathbb{R}^n} \left<span class="sc">\{</span> \frac{1}{2} z^\top W z + \iota_{\mathcal{K}}(x) + \lambda^\top y - \lambda^\top z - \lambda^\top x \right<span class="sc">\}</span> \enspace.</span>
<span id="cb4-385"><a href="#cb4-385" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-386"><a href="#cb4-386" aria-hidden="true" tabindex="-1"></a>Separating the terms in $x$ and $z$ yields</span>
<span id="cb4-387"><a href="#cb4-387" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-388"><a href="#cb4-388" aria-hidden="true" tabindex="-1"></a>\max_{\lambda \in \mathbb{R}^n}</span>
<span id="cb4-389"><a href="#cb4-389" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-390"><a href="#cb4-390" aria-hidden="true" tabindex="-1"></a>    \min_{x \in \mathbb{R}^n} \left<span class="sc">\{</span> \iota_{\mathcal{K}}(x) - \lambda^\top x + \lambda^\top y \right<span class="sc">\}</span> + \min_{z \in \mathbb{R}^n} \left<span class="sc">\{</span> \frac{1}{2} z^\top W z - \lambda^\top z \right<span class="sc">\}</span></span>
<span id="cb4-391"><a href="#cb4-391" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb4-392"><a href="#cb4-392" aria-hidden="true" tabindex="-1"></a>\enspace.</span>
<span id="cb4-393"><a href="#cb4-393" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-394"><a href="#cb4-394" aria-hidden="true" tabindex="-1"></a>The second term is a simple quadratic problem with a unique solution given by $z = W^{-1} \lambda$, hence this can be rewritten as</span>
<span id="cb4-395"><a href="#cb4-395" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-396"><a href="#cb4-396" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-397"><a href="#cb4-397" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>\frac{1}{2} \lambda^\top W^{-1} \lambda</span>
<span id="cb4-398"><a href="#cb4-398" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb4-399"><a href="#cb4-399" aria-hidden="true" tabindex="-1"></a>\enspace.</span>
<span id="cb4-400"><a href="#cb4-400" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-401"><a href="#cb4-401" aria-hidden="true" tabindex="-1"></a>The first term is linked to the Fenchel transform of the indicator function of the cone $\mathcal{K}$, and reads</span>
<span id="cb4-402"><a href="#cb4-402" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-403"><a href="#cb4-403" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-404"><a href="#cb4-404" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>\iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top y = - \iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top W^{-1} W y</span>
<span id="cb4-405"><a href="#cb4-405" aria-hidden="true" tabindex="-1"></a>\right]</span>
<span id="cb4-406"><a href="#cb4-406" aria-hidden="true" tabindex="-1"></a>\enspace.</span>
<span id="cb4-407"><a href="#cb4-407" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-408"><a href="#cb4-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-409"><a href="#cb4-409" aria-hidden="true" tabindex="-1"></a>Hence the dual problem reads:</span>
<span id="cb4-410"><a href="#cb4-410" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-411"><a href="#cb4-411" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-412"><a href="#cb4-412" aria-hidden="true" tabindex="-1"></a>\max_{\lambda \in \mathbb{R}^n} &amp;</span>
<span id="cb4-413"><a href="#cb4-413" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-414"><a href="#cb4-414" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>\iota_{\mathcal{K}^\circ}(\lambda) + \lambda^\top y - \frac{1}{2} \lambda^\top W^{-1} \lambda</span>
<span id="cb4-415"><a href="#cb4-415" aria-hidden="true" tabindex="-1"></a>\right] \enspace,</span>
<span id="cb4-416"><a href="#cb4-416" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-417"><a href="#cb4-417" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-418"><a href="#cb4-418" aria-hidden="true" tabindex="-1"></a>the later can be rewritten as</span>
<span id="cb4-419"><a href="#cb4-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-420"><a href="#cb4-420" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-421"><a href="#cb4-421" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-422"><a href="#cb4-422" aria-hidden="true" tabindex="-1"></a>\max_{\lambda \in \mathcal{K}^{\circ}} &amp;</span>
<span id="cb4-423"><a href="#cb4-423" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-424"><a href="#cb4-424" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>\frac{1}{2} (\lambda-W y)^\top W^{-1} (\lambda-W y)</span>
<span id="cb4-425"><a href="#cb4-425" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>\frac{1}{2} y^\top W y</span>
<span id="cb4-426"><a href="#cb4-426" aria-hidden="true" tabindex="-1"></a>\right] \enspace.</span>
<span id="cb4-427"><a href="#cb4-427" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-428"><a href="#cb4-428" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-429"><a href="#cb4-429" aria-hidden="true" tabindex="-1"></a>Eventually, using the formulation of $\mathcal{K}^{\circ}$ given in @lem-polar, the dual problem can be rewritten as</span>
<span id="cb4-430"><a href="#cb4-430" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-431"><a href="#cb4-431" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-432"><a href="#cb4-432" aria-hidden="true" tabindex="-1"></a>\max_{\alpha \in \mathbb{R}_+^{n-1}} &amp;</span>
<span id="cb4-433"><a href="#cb4-433" aria-hidden="true" tabindex="-1"></a>\left[</span>
<span id="cb4-434"><a href="#cb4-434" aria-hidden="true" tabindex="-1"></a><span class="ss">    - </span>\frac{1}{2} (A^\top \alpha-W y)^\top W^{-1} (A^\top \alpha-W y)</span>
<span id="cb4-435"><a href="#cb4-435" aria-hidden="true" tabindex="-1"></a><span class="ss">    + </span>\frac{1}{2} y^\top W y</span>
<span id="cb4-436"><a href="#cb4-436" aria-hidden="true" tabindex="-1"></a>\right] \enspace,</span>
<span id="cb4-437"><a href="#cb4-437" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-438"><a href="#cb4-438" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-439"><a href="#cb4-439" aria-hidden="true" tabindex="-1"></a>which is the targeted formulation.</span>
<span id="cb4-440"><a href="#cb4-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-441"><a href="#cb4-441" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-442"><a href="#cb4-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-443"><a href="#cb4-443" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-444"><a href="#cb4-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-445"><a href="#cb4-445" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-446"><a href="#cb4-446" aria-hidden="true" tabindex="-1"></a><span class="fu">## Karush-Kuhn-Tucker (KKT) conditions</span></span>
<span id="cb4-447"><a href="#cb4-447" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-448"><a href="#cb4-448" aria-hidden="true" tabindex="-1"></a>The KKT conditions for the isotonic regression problem are given by</span>
<span id="cb4-449"><a href="#cb4-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-450"><a href="#cb4-450" aria-hidden="true" tabindex="-1"></a>::: {#thm-kkt}</span>
<span id="cb4-451"><a href="#cb4-451" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-452"><a href="#cb4-452" aria-hidden="true" tabindex="-1"></a><span class="fu">## KKT conditions for isotonic regression</span></span>
<span id="cb4-453"><a href="#cb4-453" aria-hidden="true" tabindex="-1"></a>Let $x^{\star} \in \mathcal{K}$ and $\alpha^{\star} \in \mathbb{R}_+^{n-1}$ be primal and dual optimal solutions, then the KKT conditions for the isotonic regression problem reads</span>
<span id="cb4-454"><a href="#cb4-454" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-455"><a href="#cb4-455" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-456"><a href="#cb4-456" aria-hidden="true" tabindex="-1"></a>W (x^{\star}-y) + A^\top \alpha^{\star} &amp; = 0 &amp; ~ (\textbf{stationarity})<span class="sc">\\</span></span>
<span id="cb4-457"><a href="#cb4-457" aria-hidden="true" tabindex="-1"></a>\langle \alpha^{\star} , A x^{\star} \rangle &amp; = 0 &amp; ~ (\textbf{complementary slackness})<span class="sc">\\</span></span>
<span id="cb4-458"><a href="#cb4-458" aria-hidden="true" tabindex="-1"></a>\alpha^{\star} &amp; \geq 0 &amp; ~ (\textbf{dual feasibility})<span class="sc">\\</span></span>
<span id="cb4-459"><a href="#cb4-459" aria-hidden="true" tabindex="-1"></a>A x^{\star} &amp; \leq 0 &amp; ~  (\textbf{primal feasibility})</span>
<span id="cb4-460"><a href="#cb4-460" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-461"><a href="#cb4-461" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-462"><a href="#cb4-462" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-463"><a href="#cb4-463" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-464"><a href="#cb4-464" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-465"><a href="#cb4-465" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb4-466"><a href="#cb4-466" aria-hidden="true" tabindex="-1"></a>See <span class="co">[</span><span class="ot">@Boyd_Vandenberghe04, Sec. 5.5.3 </span><span class="co">]</span></span>
<span id="cb4-467"><a href="#cb4-467" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-468"><a href="#cb4-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-469"><a href="#cb4-469" aria-hidden="true" tabindex="-1"></a>In this convex setting (a primal strictly feasible point exists, say $x=(1,\dots,n)^\top$, so the Slater condition holds), the KKT conditions are necessary and sufficient for optimality.</span>
<span id="cb4-470"><a href="#cb4-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-471"><a href="#cb4-471" aria-hidden="true" tabindex="-1"></a>**Stationarity** can be rephrased as:</span>
<span id="cb4-472"><a href="#cb4-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-473"><a href="#cb4-473" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-474"><a href="#cb4-474" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-475"><a href="#cb4-475" aria-hidden="true" tabindex="-1"></a>w_1 (x^{\star}_1- y_1) + \alpha^{\star}_1 &amp; = 0 <span class="sc">\\</span></span>
<span id="cb4-476"><a href="#cb4-476" aria-hidden="true" tabindex="-1"></a>w_i (x^{\star}_i- y_i) + \alpha^{\star}_{i} - \alpha^{\star}_{i-1} &amp; = 0, \quad \text{for all } i \in \llbracket 2, n-1 \rrbracket<span class="sc">\\</span></span>
<span id="cb4-477"><a href="#cb4-477" aria-hidden="true" tabindex="-1"></a>w_n (x^{\star}_n - y_n) - \alpha^{\star}_{n-1} &amp; = 0 \enspace.</span>
<span id="cb4-478"><a href="#cb4-478" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-479"><a href="#cb4-479" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-480"><a href="#cb4-480" aria-hidden="true" tabindex="-1"></a>With the convention $\alpha_0^{\star} = \alpha_n^{\star} = 0$, this reduces to</span>
<span id="cb4-481"><a href="#cb4-481" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-482"><a href="#cb4-482" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-483"><a href="#cb4-483" aria-hidden="true" tabindex="-1"></a>w_i (x^{\star}_i - y_i) + \alpha^{\star}_{i} - \alpha^{\star}_{i-1} &amp; = 0, \quad \text{for all } i \in \llbracket 1, n \rrbracket<span class="sc">\\</span></span>
<span id="cb4-484"><a href="#cb4-484" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-485"><a href="#cb4-485" aria-hidden="true" tabindex="-1"></a>$$ {#eq-stationarity}</span>
<span id="cb4-486"><a href="#cb4-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-487"><a href="#cb4-487" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-488"><a href="#cb4-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-489"><a href="#cb4-489" aria-hidden="true" tabindex="-1"></a>**Complementarity slackness** can also be rephrased:</span>
<span id="cb4-490"><a href="#cb4-490" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-491"><a href="#cb4-491" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-492"><a href="#cb4-492" aria-hidden="true" tabindex="-1"></a>&amp; \alpha_i^{\star} (A x^{\star})_i  = 0 \quad \text{for all } i \in \llbracket 1, n-1 \rrbracket <span class="sc">\\</span></span>
<span id="cb4-493"><a href="#cb4-493" aria-hidden="true" tabindex="-1"></a>\iff &amp; \alpha_i^{\star} (x^{\star}_i-x^{\star}_{i+1})  = 0 \quad \text{for all } i \in \llbracket 1, n-1 \rrbracket \enspace.</span>
<span id="cb4-494"><a href="#cb4-494" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-495"><a href="#cb4-495" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-496"><a href="#cb4-496" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-497"><a href="#cb4-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-498"><a href="#cb4-498" aria-hidden="true" tabindex="-1"></a>A simple consequence of the complementarity slackness is as follows: if $\alpha_i^{\star} &gt; 0$ for some $i \in \llbracket 1, n-1 \rrbracket$, then $x^{\star}_i = x^{\star}_{i+1}$.</span>
<span id="cb4-499"><a href="#cb4-499" aria-hidden="true" tabindex="-1"></a>Hence, the set of ($n-1$) constraints can be partitioned into contiguous blocks where $x^\star$ has constant value.</span>
<span id="cb4-500"><a href="#cb4-500" aria-hidden="true" tabindex="-1"></a>Each block B can be written as $B = \llbracket \underline{b}, \overline{b} \rrbracket$ for some $\underline{b} \leq \overline{b}$ and $x^{\star}_{\underline{b}} = x^{\star}_{\underline{b}+1} = \ldots = x^{\star}_{\overline{b}}$. When needed we use the convention $x^{\star}_{0}=0$ and $x^{\star}_{n+1}=n+1$. and $x^{\star}_{n+1}=0$. Then, note that by definition of a block, $x^{\star}_{\underline{b}-1}&lt;x^{\star}_{\underline{b}}$ and $x^{\star}_{\overline{b}}&lt;x^{\star}_{\overline{b}+1}$, and by complementarity $\alpha^{\star}_{\underline{b}-1} = \alpha^{\star}_{\overline{b}+1} = 0$.</span>
<span id="cb4-501"><a href="#cb4-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-502"><a href="#cb4-502" aria-hidden="true" tabindex="-1"></a>Summing over the elements of $B$ in @eq-stationarity yields (telescopic sum):</span>
<span id="cb4-503"><a href="#cb4-503" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-504"><a href="#cb4-504" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-505"><a href="#cb4-505" aria-hidden="true" tabindex="-1"></a>\sum_{i \in B }w_i (x^{\star}_i - y_i) +  \alpha_{\overline{b}+1}^{\star} - \alpha_{\underline{b}-1}^{\star} &amp; = 0 \enspace.</span>
<span id="cb4-506"><a href="#cb4-506" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-507"><a href="#cb4-507" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-508"><a href="#cb4-508" aria-hidden="true" tabindex="-1"></a>Hence, noticing that the $x_i^{\star}$  in block $B$ are all equal, we have that:</span>
<span id="cb4-509"><a href="#cb4-509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-510"><a href="#cb4-510" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-511"><a href="#cb4-511" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-512"><a href="#cb4-512" aria-hidden="true" tabindex="-1"></a>x^{\star}_{\underline{b}} = \ldots = x^{\star}_{\overline{b}} = \bar{y}_B  \big(= \bar{y}_{\llbracket \underline{b}, \overline{b} \rrbracket} \big)\enspace.</span>
<span id="cb4-513"><a href="#cb4-513" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-514"><a href="#cb4-514" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-515"><a href="#cb4-515" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-516"><a href="#cb4-516" aria-hidden="true" tabindex="-1"></a>Now, from the values of $x^{\star}_{\underline{b}} = \ldots = x^{\star}_{\overline{b}}$ on the block $B$, one can infer (by recursion) the $\alpha_i$'s for $i\in B$.</span>
<span id="cb4-517"><a href="#cb4-517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-518"><a href="#cb4-518" aria-hidden="true" tabindex="-1"></a>::: {#lem-lambda}</span>
<span id="cb4-519"><a href="#cb4-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-520"><a href="#cb4-520" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expression of the dual variables</span></span>
<span id="cb4-521"><a href="#cb4-521" aria-hidden="true" tabindex="-1"></a>Let $B =\llbracket \underline{b}, \overline{b} \rrbracket$ be partitionning block for $x^\star$ (into constants pieces).</span>
<span id="cb4-522"><a href="#cb4-522" aria-hidden="true" tabindex="-1"></a>For any $i \in B$:</span>
<span id="cb4-523"><a href="#cb4-523" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-524"><a href="#cb4-524" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-525"><a href="#cb4-525" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-526"><a href="#cb4-526" aria-hidden="true" tabindex="-1"></a>\alpha^{\star}_{i} &amp; = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i+1 \rrbracket} - \bar{y}_{B}\right) \enspace.</span>
<span id="cb4-527"><a href="#cb4-527" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-528"><a href="#cb4-528" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-529"><a href="#cb4-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-530"><a href="#cb4-530" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-531"><a href="#cb4-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-532"><a href="#cb4-532" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb4-533"><a href="#cb4-533" aria-hidden="true" tabindex="-1"></a>The proof is a simple induction on the element of block $B$.</span>
<span id="cb4-534"><a href="#cb4-534" aria-hidden="true" tabindex="-1"></a>For $i=\underline{b}$ then @eq-stationarity leads to $\alpha^{\star}_{\underline{b}} = w_{\underline{b}} (\bar{y}_{\underline{b}} - x^{\star}_{\underline{b}}) = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B} \right)$.</span>
<span id="cb4-535"><a href="#cb4-535" aria-hidden="true" tabindex="-1"></a>Now by induction assume the result for $i\in B$, \emph{e.g.,} $\alpha^{\star}_{i}  = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B}\right)$.</span>
<span id="cb4-536"><a href="#cb4-536" aria-hidden="true" tabindex="-1"></a>Using @eq-stationarity for $i+1 \in B$ yields</span>
<span id="cb4-537"><a href="#cb4-537" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-538"><a href="#cb4-538" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-539"><a href="#cb4-539" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-540"><a href="#cb4-540" aria-hidden="true" tabindex="-1"></a>\alpha^{\star}_{i+1}</span>
<span id="cb4-541"><a href="#cb4-541" aria-hidden="true" tabindex="-1"></a>&amp; = w_{i+1} (y_{i+1} - x^{\star}_{i+1}) + \alpha^{\star}_i<span class="sc">\\</span></span>
<span id="cb4-542"><a href="#cb4-542" aria-hidden="true" tabindex="-1"></a>&amp; = w_{i+1} (y_{i+1} - \overline{y}_{B}) + \alpha^{\star}_i<span class="sc">\\</span></span>
<span id="cb4-543"><a href="#cb4-543" aria-hidden="true" tabindex="-1"></a>&amp; = w_{i+1} (y_{i+1} - \overline{y}_{B}) + \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j  \Big)\left(\bar{y}_{B \cap \llbracket 1, i \rrbracket} -\bar{y}_{B}\right)<span class="sc">\\</span></span>
<span id="cb4-544"><a href="#cb4-544" aria-hidden="true" tabindex="-1"></a>&amp; = \Big(\sum_{j \in B \cap \llbracket 1, i + 1 \rrbracket} w_j  \Big)\left(\bar{y}_{B \cap \llbracket 1, i+1 \rrbracket} - \bar{y}_{B}\right) \enspace,</span>
<span id="cb4-545"><a href="#cb4-545" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-546"><a href="#cb4-546" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-547"><a href="#cb4-547" aria-hidden="true" tabindex="-1"></a>hence the result.</span>
<span id="cb4-548"><a href="#cb4-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-549"><a href="#cb4-549" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-550"><a href="#cb4-550" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-551"><a href="#cb4-551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-552"><a href="#cb4-552" aria-hidden="true" tabindex="-1"></a><span class="fu"># Algorithm</span></span>
<span id="cb4-553"><a href="#cb4-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-554"><a href="#cb4-554" aria-hidden="true" tabindex="-1"></a>The intuition behind the PAVA algorithm is to merge adjacent blocks of constant values in the primal vector, as the targeted solution is simply the average of the observe signal over each block.</span>
<span id="cb4-555"><a href="#cb4-555" aria-hidden="true" tabindex="-1"></a>Hence, the algorithm aims at creating the blocks of constant values in the primal vector. The dual variables can be inferred from the  solution from the previous lemma.</span>
<span id="cb4-556"><a href="#cb4-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-557"><a href="#cb4-557" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-558"><a href="#cb4-558" aria-hidden="true" tabindex="-1"></a><span class="fu">## Pseudo-code and Python implementation</span></span>
<span id="cb4-559"><a href="#cb4-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-560"><a href="#cb4-560" aria-hidden="true" tabindex="-1"></a><span class="in">```pseudocode</span></span>
<span id="cb4-561"><a href="#cb4-561" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-indent-size: "1.2em"</span></span>
<span id="cb4-562"><a href="#cb4-562" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-comment-delimiter: "//"</span></span>
<span id="cb4-563"><a href="#cb4-563" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number: true</span></span>
<span id="cb4-564"><a href="#cb4-564" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-line-number-punc: ":"</span></span>
<span id="cb4-565"><a href="#cb4-565" aria-hidden="true" tabindex="-1"></a><span class="in">#| html-no-end: false</span></span>
<span id="cb4-566"><a href="#cb4-566" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-placement: "htb!"</span></span>
<span id="cb4-567"><a href="#cb4-567" aria-hidden="true" tabindex="-1"></a><span class="in">#| pdf-line-number: true</span></span>
<span id="cb4-568"><a href="#cb4-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-569"><a href="#cb4-569" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithm}</span></span>
<span id="cb4-570"><a href="#cb4-570" aria-hidden="true" tabindex="-1"></a><span class="in">\caption{PAVA}</span></span>
<span id="cb4-571"><a href="#cb4-571" aria-hidden="true" tabindex="-1"></a><span class="in">\begin{algorithmic}</span></span>
<span id="cb4-572"><a href="#cb4-572" aria-hidden="true" tabindex="-1"></a><span class="in">\REQUIRE $y \in\mathbb{R}^n, w \in \mathbb{R}^n_{+}$</span></span>
<span id="cb4-573"><a href="#cb4-573" aria-hidden="true" tabindex="-1"></a><span class="in">\STATE $r \leftarrow y$</span></span>
<span id="cb4-574"><a href="#cb4-574" aria-hidden="true" tabindex="-1"></a><span class="in">\STATE $W \leftarrow y$</span></span>
<span id="cb4-575"><a href="#cb4-575" aria-hidden="true" tabindex="-1"></a><span class="in">\STATE $J = [\{1\},\dots, \{n\}]$ \COMMENT{lists of blocks}</span></span>
<span id="cb4-576"><a href="#cb4-576" aria-hidden="true" tabindex="-1"></a><span class="in">\STATE $i=1$ (index of list start at 0 here)</span></span>
<span id="cb4-577"><a href="#cb4-577" aria-hidden="true" tabindex="-1"></a><span class="in">\WHILE{$i&lt;n$}</span></span>
<span id="cb4-578"><a href="#cb4-578" aria-hidden="true" tabindex="-1"></a><span class="in">    \IF{$r_i &lt; r_{i-1}$} \COMMENT{Find adjacent violators and merge groups}</span></span>
<span id="cb4-579"><a href="#cb4-579" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE $r_i \leftarrow \frac{W_i r_i + W_{i-1} r_{i-1}}{W_i + W_{i-1}}$</span></span>
<span id="cb4-580"><a href="#cb4-580" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE $W_i \leftarrow W_i + W_{i-1}$</span></span>
<span id="cb4-581"><a href="#cb4-581" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE $J_i \leftarrow J_i \cup J_{i-1}$</span></span>
<span id="cb4-582"><a href="#cb4-582" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE Remove $r_{i-1}$, $W_{i-1}$ and $J_{i-1}$ from the lists</span></span>
<span id="cb4-583"><a href="#cb4-583" aria-hidden="true" tabindex="-1"></a><span class="in">        \IF{$i &gt; 1$}</span></span>
<span id="cb4-584"><a href="#cb4-584" aria-hidden="true" tabindex="-1"></a><span class="in">            \STATE{$i\leftarrow i-1$}</span></span>
<span id="cb4-585"><a href="#cb4-585" aria-hidden="true" tabindex="-1"></a><span class="in">        \ENDIF</span></span>
<span id="cb4-586"><a href="#cb4-586" aria-hidden="true" tabindex="-1"></a><span class="in">    \ELSE</span></span>
<span id="cb4-587"><a href="#cb4-587" aria-hidden="true" tabindex="-1"></a><span class="in">        \STATE{$i  \leftarrow i + 1$}</span></span>
<span id="cb4-588"><a href="#cb4-588" aria-hidden="true" tabindex="-1"></a><span class="in">    \ENDIF</span></span>
<span id="cb4-589"><a href="#cb4-589" aria-hidden="true" tabindex="-1"></a><span class="in">\ENDWHILE</span></span>
<span id="cb4-590"><a href="#cb4-590" aria-hidden="true" tabindex="-1"></a><span class="in">\FOR{$i=1$ to len($J$)}</span></span>
<span id="cb4-591"><a href="#cb4-591" aria-hidden="true" tabindex="-1"></a><span class="in">    \STATE{$r_{J_i} \leftarrow \bar{y}_{J_i} \mathbf{1}_{J_i}$}</span></span>
<span id="cb4-592"><a href="#cb4-592" aria-hidden="true" tabindex="-1"></a><span class="in">    \COMMENT{Set the block to the average value}</span></span>
<span id="cb4-593"><a href="#cb4-593" aria-hidden="true" tabindex="-1"></a><span class="in">\ENDFOR</span></span>
<span id="cb4-594"><a href="#cb4-594" aria-hidden="true" tabindex="-1"></a><span class="in">\RETURN{$r, J$}</span></span>
<span id="cb4-595"><a href="#cb4-595" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithmic}</span></span>
<span id="cb4-596"><a href="#cb4-596" aria-hidden="true" tabindex="-1"></a><span class="in">\end{algorithm}</span></span>
<span id="cb4-597"><a href="#cb4-597" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-598"><a href="#cb4-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-599"><a href="#cb4-599" aria-hidden="true" tabindex="-1"></a>Below you will find a simple version of the PAVA algorithm coded in Python.</span>
<span id="cb4-600"><a href="#cb4-600" aria-hidden="true" tabindex="-1"></a>The <span class="in">`sklearn`</span> version (in particular the <span class="in">`_isotonic.pyx`</span> file, as available in October 2024, see <span class="co">[</span><span class="ot">source</span><span class="co">](https://github.com/scikit-learn/scikit-learn/blob/04fbe04fedda0e86e67867854900a49fb53c4c01/sklearn/_isotonic.pyx)</span>). is more efficient but a little less readable.</span>
<span id="cb4-601"><a href="#cb4-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-604"><a href="#cb4-604" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-605"><a href="#cb4-605" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb4-606"><a href="#cb4-606" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb4-607"><a href="#cb4-607" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb4-608"><a href="#cb4-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-609"><a href="#cb4-609" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> PAVA(y, w):</span>
<span id="cb4-610"><a href="#cb4-610" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(y)</span>
<span id="cb4-611"><a href="#cb4-611" aria-hidden="true" tabindex="-1"></a>    r <span class="op">=</span> y.copy()</span>
<span id="cb4-612"><a href="#cb4-612" aria-hidden="true" tabindex="-1"></a>    ws <span class="op">=</span> w.copy()</span>
<span id="cb4-613"><a href="#cb4-613" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> [[i] <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb4-614"><a href="#cb4-614" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb4-615"><a href="#cb4-615" aria-hidden="true" tabindex="-1"></a>    counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-616"><a href="#cb4-616" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb4-617"><a href="#cb4-617" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> r[i] <span class="op">&lt;</span> r[i <span class="op">-</span> <span class="dv">1</span>]:  <span class="co"># Find adjacent violators</span></span>
<span id="cb4-618"><a href="#cb4-618" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Pool the violators</span></span>
<span id="cb4-619"><a href="#cb4-619" aria-hidden="true" tabindex="-1"></a>            r[i] <span class="op">=</span> (ws[i] <span class="op">*</span> r[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>] <span class="op">*</span> r[i <span class="op">-</span> <span class="dv">1</span>]) <span class="op">/</span> (ws[i] <span class="op">+</span> ws[i <span class="op">-</span> <span class="dv">1</span>])</span>
<span id="cb4-620"><a href="#cb4-620" aria-hidden="true" tabindex="-1"></a>            ws[i] <span class="op">+=</span> ws[i <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb4-621"><a href="#cb4-621" aria-hidden="true" tabindex="-1"></a>            target[i] <span class="op">=</span> target[i<span class="op">-</span><span class="dv">1</span>] <span class="op">+</span> target[i]</span>
<span id="cb4-622"><a href="#cb4-622" aria-hidden="true" tabindex="-1"></a>            r.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-623"><a href="#cb4-623" aria-hidden="true" tabindex="-1"></a>            ws.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-624"><a href="#cb4-624" aria-hidden="true" tabindex="-1"></a>            target.pop(i <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb4-625"><a href="#cb4-625" aria-hidden="true" tabindex="-1"></a>            n <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb4-626"><a href="#cb4-626" aria-hidden="true" tabindex="-1"></a>            <span class="co"># Move back one step if possible</span></span>
<span id="cb4-627"><a href="#cb4-627" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">1</span>:</span>
<span id="cb4-628"><a href="#cb4-628" aria-hidden="true" tabindex="-1"></a>                i <span class="op">-=</span> <span class="dv">1</span></span>
<span id="cb4-629"><a href="#cb4-629" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb4-630"><a href="#cb4-630" aria-hidden="true" tabindex="-1"></a>            i <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-631"><a href="#cb4-631" aria-hidden="true" tabindex="-1"></a>            counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb4-632"><a href="#cb4-632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-633"><a href="#cb4-633" aria-hidden="true" tabindex="-1"></a>    sol <span class="op">=</span> np.zeros_like(y)</span>
<span id="cb4-634"><a href="#cb4-634" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, block <span class="kw">in</span> <span class="bu">enumerate</span>(target):</span>
<span id="cb4-635"><a href="#cb4-635" aria-hidden="true" tabindex="-1"></a>        sol[block] <span class="op">=</span> r[i]</span>
<span id="cb4-636"><a href="#cb4-636" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sol, ws, target</span>
<span id="cb4-637"><a href="#cb4-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-638"><a href="#cb4-638" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-639"><a href="#cb4-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-640"><a href="#cb4-640" aria-hidden="true" tabindex="-1"></a>Below is a version of the algorithm similar to the one implemented in <span class="in">`sklearn`</span> (yet in pure Python here). Moreover, it can be made an inplace method (as in <span class="in">`sklearn`</span>), which is more memory efficient.</span>
<span id="cb4-641"><a href="#cb4-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-644"><a href="#cb4-644" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-645"><a href="#cb4-645" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb4-646"><a href="#cb4-646" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb4-647"><a href="#cb4-647" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> isotonic_regression(z, w):</span>
<span id="cb4-648"><a href="#cb4-648" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> z.copy()</span>
<span id="cb4-649"><a href="#cb4-649" aria-hidden="true" tabindex="-1"></a>    n<span class="op">=</span><span class="bu">len</span>(y)</span>
<span id="cb4-650"><a href="#cb4-650" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-651"><a href="#cb4-651" aria-hidden="true" tabindex="-1"></a>    target <span class="op">=</span> np.arange(<span class="bu">len</span>(y))</span>
<span id="cb4-652"><a href="#cb4-652" aria-hidden="true" tabindex="-1"></a>    targets <span class="op">=</span> [target.copy()]</span>
<span id="cb4-653"><a href="#cb4-653" aria-hidden="true" tabindex="-1"></a>    idx <span class="op">=</span> [<span class="dv">0</span>]</span>
<span id="cb4-654"><a href="#cb4-654" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb4-655"><a href="#cb4-655" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> target[i] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb4-656"><a href="#cb4-656" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> k <span class="op">==</span> n:</span>
<span id="cb4-657"><a href="#cb4-657" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb4-658"><a href="#cb4-658" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> y[i] <span class="op">&lt;</span> y[k]:</span>
<span id="cb4-659"><a href="#cb4-659" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We are in an increasing subsequence.</span></span>
<span id="cb4-660"><a href="#cb4-660" aria-hidden="true" tabindex="-1"></a>            i <span class="op">=</span> k</span>
<span id="cb4-661"><a href="#cb4-661" aria-hidden="true" tabindex="-1"></a>            targets.append(target.copy())</span>
<span id="cb4-662"><a href="#cb4-662" aria-hidden="true" tabindex="-1"></a>            idx.append(k)</span>
<span id="cb4-663"><a href="#cb4-663" aria-hidden="true" tabindex="-1"></a>            <span class="cf">continue</span></span>
<span id="cb4-664"><a href="#cb4-664" aria-hidden="true" tabindex="-1"></a>        sum_wy <span class="op">=</span> w[i] <span class="op">*</span> y[i]</span>
<span id="cb4-665"><a href="#cb4-665" aria-hidden="true" tabindex="-1"></a>        sum_w <span class="op">=</span> w[i]</span>
<span id="cb4-666"><a href="#cb4-666" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb4-667"><a href="#cb4-667" aria-hidden="true" tabindex="-1"></a>            <span class="co"># We are within a decreasing subsequence.</span></span>
<span id="cb4-668"><a href="#cb4-668" aria-hidden="true" tabindex="-1"></a>            prev_y <span class="op">=</span> y[k]</span>
<span id="cb4-669"><a href="#cb4-669" aria-hidden="true" tabindex="-1"></a>            sum_wy <span class="op">+=</span> w[k] <span class="op">*</span> y[k]</span>
<span id="cb4-670"><a href="#cb4-670" aria-hidden="true" tabindex="-1"></a>            sum_w <span class="op">+=</span> w[k]</span>
<span id="cb4-671"><a href="#cb4-671" aria-hidden="true" tabindex="-1"></a>            k <span class="op">=</span> target[k] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb4-672"><a href="#cb4-672" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> k <span class="op">==</span> n <span class="kw">or</span> prev_y <span class="op">&lt;</span> y[k]:</span>
<span id="cb4-673"><a href="#cb4-673" aria-hidden="true" tabindex="-1"></a>                targets.append(target.copy())</span>
<span id="cb4-674"><a href="#cb4-674" aria-hidden="true" tabindex="-1"></a>                idx.append(k)</span>
<span id="cb4-675"><a href="#cb4-675" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-676"><a href="#cb4-676" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Non-singleton decreasing subsequence is finished,</span></span>
<span id="cb4-677"><a href="#cb4-677" aria-hidden="true" tabindex="-1"></a>                <span class="co"># update first entry.</span></span>
<span id="cb4-678"><a href="#cb4-678" aria-hidden="true" tabindex="-1"></a>                y[i] <span class="op">=</span> sum_wy <span class="op">/</span> sum_w</span>
<span id="cb4-679"><a href="#cb4-679" aria-hidden="true" tabindex="-1"></a>                w[i] <span class="op">=</span> sum_w</span>
<span id="cb4-680"><a href="#cb4-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-681"><a href="#cb4-681" aria-hidden="true" tabindex="-1"></a>                target[i] <span class="op">=</span> k <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb4-682"><a href="#cb4-682" aria-hidden="true" tabindex="-1"></a>                target[k <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> i</span>
<span id="cb4-683"><a href="#cb4-683" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-684"><a href="#cb4-684" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb4-685"><a href="#cb4-685" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># Backtrack if we can.  This makes the algorithm</span></span>
<span id="cb4-686"><a href="#cb4-686" aria-hidden="true" tabindex="-1"></a>                    <span class="co"># single-pass and ensures O(n) complexity.</span></span>
<span id="cb4-687"><a href="#cb4-687" aria-hidden="true" tabindex="-1"></a>                    i <span class="op">=</span> target[i <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb4-688"><a href="#cb4-688" aria-hidden="true" tabindex="-1"></a>                <span class="co"># Otherwise, restart from the same point.</span></span>
<span id="cb4-689"><a href="#cb4-689" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb4-690"><a href="#cb4-690" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-691"><a href="#cb4-691" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Reconstruct the solution.</span></span>
<span id="cb4-692"><a href="#cb4-692" aria-hidden="true" tabindex="-1"></a>    i <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb4-693"><a href="#cb4-693" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> i <span class="op">&lt;</span> n:</span>
<span id="cb4-694"><a href="#cb4-694" aria-hidden="true" tabindex="-1"></a>        k <span class="op">=</span> target[i] <span class="op">+</span> <span class="dv">1</span></span>
<span id="cb4-695"><a href="#cb4-695" aria-hidden="true" tabindex="-1"></a>        y[i <span class="op">+</span> <span class="dv">1</span> : k] <span class="op">=</span> y[i]</span>
<span id="cb4-696"><a href="#cb4-696" aria-hidden="true" tabindex="-1"></a>        i <span class="op">=</span> k</span>
<span id="cb4-697"><a href="#cb4-697" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> y, targets, idx</span>
<span id="cb4-698"><a href="#cb4-698" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-699"><a href="#cb4-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-700"><a href="#cb4-700" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convergence</span></span>
<span id="cb4-701"><a href="#cb4-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-702"><a href="#cb4-702" aria-hidden="true" tabindex="-1"></a>::: {#thm-convergence}</span>
<span id="cb4-703"><a href="#cb4-703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-704"><a href="#cb4-704" aria-hidden="true" tabindex="-1"></a><span class="fu">## Convergence of the PAVA algorithm</span></span>
<span id="cb4-705"><a href="#cb4-705" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-706"><a href="#cb4-706" aria-hidden="true" tabindex="-1"></a>The PAVA algorithm converges in a finite number of iterations and output the primal solution of the isotonic regression problem.</span>
<span id="cb4-707"><a href="#cb4-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-708"><a href="#cb4-708" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-709"><a href="#cb4-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-710"><a href="#cb4-710" aria-hidden="true" tabindex="-1"></a>::: {.proof}</span>
<span id="cb4-711"><a href="#cb4-711" aria-hidden="true" tabindex="-1"></a>To show the convergence we will create a dual variable $\alpha$, show that it is dual feasible, and that at the end of the algorithm it satisfies KKT along with the output of the PAVA algorithm.</span>
<span id="cb4-712"><a href="#cb4-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-713"><a href="#cb4-713" aria-hidden="true" tabindex="-1"></a>For that let us first prove the following result:</span>
<span id="cb4-714"><a href="#cb4-714" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-715"><a href="#cb4-715" aria-hidden="true" tabindex="-1"></a>**Fact 1**. Let $B \in J$ be a block at some stage of the algorithm.</span>
<span id="cb4-716"><a href="#cb4-716" aria-hidden="true" tabindex="-1"></a>Then,</span>
<span id="cb4-717"><a href="#cb4-717" aria-hidden="true" tabindex="-1"></a>$$\forall i \in B, \overline{y}_{B \cap \llbracket 1, i \rrbracket} \geq \overline{y}_{B} \enspace.</span>
<span id="cb4-718"><a href="#cb4-718" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-719"><a href="#cb4-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-720"><a href="#cb4-720" aria-hidden="true" tabindex="-1"></a>To show this result, we will use induction and show that the merging process does maintain this condition.</span>
<span id="cb4-721"><a href="#cb4-721" aria-hidden="true" tabindex="-1"></a>First, at initialization, the condition is true as the blocks have all size 1.</span>
<span id="cb4-722"><a href="#cb4-722" aria-hidden="true" tabindex="-1"></a>Now, assume that the condition is true, and check what happen when we merge two consecutive groups $J_i$ and $J_{i-1}$ into $B=J_{i-1} \cup J_{i}$.</span>
<span id="cb4-723"><a href="#cb4-723" aria-hidden="true" tabindex="-1"></a>First the condition is true for $J_i$ and $J_{i-1}$, so $\overline{y}_{J_i \cap \llbracket 1, k \rrbracket} \geq \overline{y}_{J_i}$ and $\overline{y}_{J_{i-1} \cap \llbracket 1, k' \rrbracket} \geq \overline{y}_{J_{i-1}}$ for any $k \in J_i$ and $k' \in J_{i-1}$.</span>
<span id="cb4-724"><a href="#cb4-724" aria-hidden="true" tabindex="-1"></a>Then, the test $r_i &lt; r_{i-1}$ is equivalent to $\overline{y}_{J_i} &lt; \overline{y}_{J_{i-1}}$.</span>
<span id="cb4-725"><a href="#cb4-725" aria-hidden="true" tabindex="-1"></a>So for any $k \in J_{i-1}$, we have $\overline{y}_{J_i \cap \llbracket k, n \rrbracket} \geq \overline{y}_{J_i}$ using the induction hypothesis.</span>
<span id="cb4-726"><a href="#cb4-726" aria-hidden="true" tabindex="-1"></a>For $k'\in J_{i}$,  $\overline{y}_{B \cap \llbracket 1, k \rrbracket} = \overline{y}_{J_{i-1} \cap \llbracket 1, k \rrbracket} \geq \overline{y}_{J_{i-1}} \geq \overline{y}_{B}$ (where the last inequality is due to the test $r_i &lt; r_{i-1}$).</span>
<span id="cb4-727"><a href="#cb4-727" aria-hidden="true" tabindex="-1"></a>For the case $k' \in J_i$, we have</span>
<span id="cb4-728"><a href="#cb4-728" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-729"><a href="#cb4-729" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-730"><a href="#cb4-730" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-731"><a href="#cb4-731" aria-hidden="true" tabindex="-1"></a>\overline{y}_{B \cap \llbracket 1, k' \rrbracket}</span>
<span id="cb4-732"><a href="#cb4-732" aria-hidden="true" tabindex="-1"></a>&amp; = \overline{y}_{ J_{i-1} \cup (J_{i} \cap \llbracket 1, k' \rrbracket)} <span class="sc">\\</span></span>
<span id="cb4-733"><a href="#cb4-733" aria-hidden="true" tabindex="-1"></a>&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i} \cap \llbracket 1, k' \rrbracket}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i}<span class="sc">\\</span></span>
<span id="cb4-734"><a href="#cb4-734" aria-hidden="true" tabindex="-1"></a>&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i} \quad (\text{induction})<span class="sc">\\</span></span>
<span id="cb4-735"><a href="#cb4-735" aria-hidden="true" tabindex="-1"></a>&amp; \geq \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} \cap \llbracket 1, k' \rrbracket} w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i} \cap \llbracket 1, k' \rrbracket} w_i} \quad (\text{PAVA})<span class="sc">\\</span></span>
<span id="cb4-736"><a href="#cb4-736" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-737"><a href="#cb4-737" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-738"><a href="#cb4-738" aria-hidden="true" tabindex="-1"></a>Now, remember that $\overline{y}_{B} = \frac{\Big(\sum_{\ell \in J_{i-1}} w_{\ell} \Big) \cdot \overline{y}_{J_{i-1}} + \Big(\sum_{\ell \in J_{i} } w_{\ell} \Big) \cdot \overline{y}_{J_{i}}}{\sum_{J_{i-1}} w_i + \sum_{J_{i}} w_i}$ and that $\overline{y}_{J_{i-1}} \geq  \overline{y}_{B} \geq \overline{y}_{J_{i}}$ (since $\overline{y}_{B}$ is a convex combination of $\overline{y}_{J_{i-1}}$ and $\overline{y}_{J_i}$), so the last inequality is true. One can check that the weight of $J_{i}$ is larger in the definition of $\overline{y}_{B}$ than in the last inequality above, and so among the two convex combinations, the larger is the former.</span>
<span id="cb4-739"><a href="#cb4-739" aria-hidden="true" tabindex="-1"></a>Hence, the fact is proved by induction.</span>
<span id="cb4-740"><a href="#cb4-740" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-741"><a href="#cb4-741" aria-hidden="true" tabindex="-1"></a>**Fact 2.** If you update $\alpha$ recursively, starting from $\alpha = \mathbf{0}_{n-1}$ and for if for each updated block $B \in J$ you update $\alpha$ (as in @lem-lambda) by</span>
<span id="cb4-742"><a href="#cb4-742" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-743"><a href="#cb4-743" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-744"><a href="#cb4-744" aria-hidden="true" tabindex="-1"></a>\begin{align*}</span>
<span id="cb4-745"><a href="#cb4-745" aria-hidden="true" tabindex="-1"></a>\forall i \in B, \alpha_i &amp; = \Big(\sum_{j \in B \cap \llbracket 1, i \rrbracket} w_j \Big)\left( \bar{y}_{B \cap \llbracket 1, i \rrbracket} - \bar{y}_{B}\right) \enspace,</span>
<span id="cb4-746"><a href="#cb4-746" aria-hidden="true" tabindex="-1"></a>\end{align*}</span>
<span id="cb4-747"><a href="#cb4-747" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb4-748"><a href="#cb4-748" aria-hidden="true" tabindex="-1"></a>then $\alpha$ is dual feasible for all steps of the algorithm</span>
<span id="cb4-749"><a href="#cb4-749" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-750"><a href="#cb4-750" aria-hidden="true" tabindex="-1"></a>The proof is a direct consequence of Fact 1 and the fact that the weights $w_i$ are non-negative.</span>
<span id="cb4-751"><a href="#cb4-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-752"><a href="#cb4-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-753"><a href="#cb4-753" aria-hidden="true" tabindex="-1"></a>**Fact 3.**</span>
<span id="cb4-754"><a href="#cb4-754" aria-hidden="true" tabindex="-1"></a>$\forall i \in B, \alpha_i=\alpha_{i-1} +w_i(x_i - y_i)$ (where we assume that $x_i = \overline{y}_B$), which means that $\alpha$ and $x$ hence created satsfies.</span>
<span id="cb4-755"><a href="#cb4-755" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-756"><a href="#cb4-756" aria-hidden="true" tabindex="-1"></a>Again this result is simple to prove, by following the exact same line encountered in the proof of @lem-lambda.</span>
<span id="cb4-757"><a href="#cb4-757" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-758"><a href="#cb4-758" aria-hidden="true" tabindex="-1"></a>**Fact 4.** When you exit the while loop, the output of the PAVA algorithm is a primal feasible point.</span>
<span id="cb4-759"><a href="#cb4-759" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-760"><a href="#cb4-760" aria-hidden="true" tabindex="-1"></a>Indeed, the only way to exist is to have all blocks mean values ordered.</span>
<span id="cb4-761"><a href="#cb4-761" aria-hidden="true" tabindex="-1"></a>Hence, when the algorithm stops the primal point create (after the block averaging step) is primal feasible.</span>
<span id="cb4-762"><a href="#cb4-762" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-763"><a href="#cb4-763" aria-hidden="true" tabindex="-1"></a>Leveraging Fact 1. to 4. ensures that the KKT conditions are satisfied with the primal and dual points created. Hence, at the end of the algorithm, and the optimal solution is found.</span>
<span id="cb4-764"><a href="#cb4-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-765"><a href="#cb4-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-766"><a href="#cb4-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-767"><a href="#cb4-767" aria-hidden="true" tabindex="-1"></a><span class="fu">## Duality Gap</span></span>
<span id="cb4-768"><a href="#cb4-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-769"><a href="#cb4-769" aria-hidden="true" tabindex="-1"></a>Given a primal feasible point $x \in \mathcal{K}$ and a dual feasible point $\alpha \in \mathbb{R}_+^{n-1}$, we can obtain upper and lower bounds on the optimal value of the primal problem .</span>
<span id="cb4-770"><a href="#cb4-770" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-771"><a href="#cb4-771" aria-hidden="true" tabindex="-1"></a>Note that at optimality $W x^\star = W y - A^\top \alpha^\star$</span>
<span id="cb4-772"><a href="#cb4-772" aria-hidden="true" tabindex="-1"></a>Hence, using a value of $x$ at some stage of the algorithm (corresponding to a feasible $\alpha$), the dual reads $\frac{1}{2} y^\top W y - \frac{1}{2} x^\top W x$.</span>
<span id="cb4-773"><a href="#cb4-773" aria-hidden="true" tabindex="-1"></a>For creating a primal feasible point, one can simply take the ordered version of the output, making the last element constant to create a non-decreasing vector.</span>
<span id="cb4-774"><a href="#cb4-774" aria-hidden="true" tabindex="-1"></a>The later is coded in Python with the following function:</span>
<span id="cb4-775"><a href="#cb4-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-778"><a href="#cb4-778" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb4-779"><a href="#cb4-779" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb4-780"><a href="#cb4-780" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: false</span></span>
<span id="cb4-781"><a href="#cb4-781" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> replace_after_first_non_increasing(x, w<span class="op">=</span>w):</span>
<span id="cb4-782"><a href="#cb4-782" aria-hidden="true" tabindex="-1"></a>    n <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb4-783"><a href="#cb4-783" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n):</span>
<span id="cb4-784"><a href="#cb4-784" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> x[i] <span class="op">&lt;</span> x[i <span class="op">-</span> <span class="dv">1</span>]:</span>
<span id="cb4-785"><a href="#cb4-785" aria-hidden="true" tabindex="-1"></a>            mean_value <span class="op">=</span> np.<span class="bu">sum</span>(x[i:] <span class="op">*</span> w[i:]) <span class="op">/</span> np.<span class="bu">sum</span>(w[i:])</span>
<span id="cb4-786"><a href="#cb4-786" aria-hidden="true" tabindex="-1"></a>            x[i:] <span class="op">=</span> mean_value</span>
<span id="cb4-787"><a href="#cb4-787" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb4-788"><a href="#cb4-788" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> x</span>
<span id="cb4-789"><a href="#cb4-789" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb4-790"><a href="#cb4-790" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-791"><a href="#cb4-791" aria-hidden="true" tabindex="-1"></a>As can be seen in the preliminary animation, the primal and dual objectives converge to the same value, which is the optimal value of the primal problem.</span>
<span id="cb4-792"><a href="#cb4-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-793"><a href="#cb4-793" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb4-794"><a href="#cb4-794" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-795"><a href="#cb4-795" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-796"><a href="#cb4-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-797"><a href="#cb4-797" aria-hidden="true" tabindex="-1"></a><span class="fu"># {{&lt; fa link title="link" &gt;}} References</span></span>
<span id="cb4-798"><a href="#cb4-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-799"><a href="#cb4-799" aria-hidden="true" tabindex="-1"></a>::: {#refs}</span>
<span id="cb4-800"><a href="#cb4-800" aria-hidden="true" tabindex="-1"></a>:::</span>
</code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block"><i class="fa-brands fa-creative-commons" aria-label="creative-commons"></i> 2024 Joseph Salmon</span> <span class="faux-block"><a href="https://github.com/josephsalmon/MyWebsite"><i class="fa-brands fa-github" aria-label="github"></i> Source Code</a></span></p>
</div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block"> Designed with <i class="fa-solid fa-heart" aria-label="heart"></i></span> <span class="faux-block"> Built with <a href="https://quarto.org/">Quarto</a></span></p>
</div>
  </div>
</footer>
    <script type="text/javascript">
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let pseudocodeOptions = {
          indentSize: el.dataset.indentSize || "1.2em",
          commentDelimiter: el.dataset.commentDelimiter || "//",
          lineNumber: el.dataset.lineNumber === "true" ? true : false,
          lineNumberPunc: el.dataset.lineNumberPunc || ":",
          noEnd: el.dataset.noEnd === "true" ? true : false,
          titlePrefix: el.dataset.captionPrefix || "Algorithm"
        };
        pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
      });
    })(document);
    (function(d) {
      d.querySelectorAll(".pseudocode-container").forEach(function(el) {
        let captionSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
        if (captionSpan !== null) {
          let captionPrefix = el.dataset.captionPrefix + " ";
          let captionNumber = "";
          if (el.dataset.pseudocodeNumber) {
            captionNumber = el.dataset.pseudocodeNumber + " ";
            if (el.dataset.chapterLevel) {
              captionNumber = el.dataset.chapterLevel + "." + captionNumber;
            }
          }
          captionSpan.innerHTML = captionPrefix + captionNumber;
        }
      });
    })(document);
    </script>
  




</body></html>